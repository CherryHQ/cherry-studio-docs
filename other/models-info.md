# 常见模型参考信息



{% hint style="info" %}
* 以下信息仅供参考，如有错误可联系纠正，部分模型的服务商不同其上下文大小和模型信息可能也会有所不同；
* 在客户端输入数据时需要将“k”转换成实际数值（理论上1k=1024 tokens；1m=1024k tokens），如8k为8×1024=8192 tokens。建议在实际使用时×1000即可，防止报错，如8k为8×1000=8000，1m=1×1000000=1000000；
* 以下数据按照模型名称由a-z的顺序排序。
* 最大输出为“-”的为未从官方查询到该模型明确的最大输出信息。
{% endhint %}

<table><thead><tr><th width="313">模型名称</th><th width="158">最大输入</th><th width="72">最大输出</th><th width="95">函数调用</th><th width="142">模型能力</th><th width="540">服务商</th><th width="257">简介</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>不支持</td><td>对话</td><td>360AI_360gpt</td><td>360智脑系列效果最好的主力千亿级大模型，广泛适用于各领域复杂任务场景。</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>不支持</td><td>对话</td><td>360AI_360gpt</td><td>兼顾性能和效果的百亿级大模型，适合对性能/成本要求较高 的场景。</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>不支持</td><td>对话</td><td>360AI_360gpt</td><td>兼顾性能和效果的百亿级大模型，适合对性能/成本要求较高 的场景。</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>不支持</td><td>对话</td><td>360AI_360gpt</td><td>360智脑系列效果最好的主力千亿级大模型，广泛适用于各领域复杂任务场景。</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>不支持</td><td>对话,识图</td><td>Anthropic_claude</td><td>于2024年6月20日发布的快照版本,Claude 3.5 Sonnet是一个平衡了性能和速度的模型，在保持高速度的同时提供顶级性能，支持多模态输入。</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>不支持</td><td>对话</td><td>Anthropic_claude</td><td>于2024年10月22日发布的快照版本,Claude 3.5 Haiku在各项技能上都有所提升，包括编码、工具使用和推理。作为Anthropic系列中速度最快的模型，它提供快速响应时间，适用于需要高互动性和低延迟的应用，如面向用户的聊天机器人和即时代码补全。它在数据提取和实时内容审核等专业任务中也表现出色，使其成为各行业广泛应用的多功能工具。它不支持图像输入。</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>不支持</td><td>对话,识图</td><td>Anthropic_claude</td><td>于2024年10月22日发布的快照版本,Claude 3.5 Sonnet 提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务。</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Anthropic_claude</td><td>动态指向最新的Claude 3.5 Sonnet版本,Claude 3.5 Sonnet提供了超越 Opus 的能力和比 Sonnet 更快的速度，同时保持与 Sonnet 相同的价格。Sonnet 特别擅长编程、数据科学、视觉处理、代理任务，该模型指向最新的版本。</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>不支持</td><td>对话,识图</td><td>Anthropic_claude</td><td>Claude 3 Haiku 是 Anthropic 的最快且最紧凑的模型，旨在实现近乎即时的响应。它具有快速且准确的定向性能。</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>不支持</td><td>对话,识图</td><td>Anthropic_claude</td><td>Claude 3 Opus 是 Anthropic 用于处理高度复杂任务的最强大模型。它在性能、智能、流畅性和理解力方面表现卓越。</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Anthropic_claude</td><td>于2024年2月29日发布的快照版本,Sonnet 特别擅长于：<br><br>- 编码：能够自主编写、编辑和运行代码，并具备推理和故障排除能力<br>- 数据科学：增强人类的数据科学专业知识；在使用多种工具获取洞察时，能够处理非结构化数据<br>- 视觉处理：擅长解读图表、图形和图像，准确转录文本以获取超越文本本身的洞察<br>- 代理任务：工具使用出色，非常适合处理代理任务（即需要与其他系统交互的复杂多步骤问题解决任务）</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>不支持</td><td>对话</td><td>Google_gamma</td><td>Gemma 是由 Google 开发的轻量级、最先进的开放模型系列，采用与 Gemini 模型相同的研究和技术构建。这些模型是仅解码器的大型语言模型，支持英语，提供预训练和指令微调两种变体的开放权重。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>不支持</td><td>对话</td><td>Google_gamma</td><td>Gemma 是 Google 开发的轻量级、最先进的开放模型系列之一。它是一个仅解码器的大型语言模型，支持英语，提供开放权重、预训练变体和指令微调变体。Gemma 模型适用于各种文本生成任务，包括问答、摘要和推理。该 9B 模型是通过 8 万亿个 tokens 训练而成。</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>不支持</td><td>对话</td><td>Google_gemini</td><td>Gemini 1.5 Pro 的最新稳定版本。作为一个强大的多模态模型，它可以处理长达6 万行代码或 2,000 页文本。特别适合需要复杂推理的任务。</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>不支持</td><td>对话</td><td>Google_gemini</td><td>这是 Gemini 1.0 Pro 的稳定版本。作为一个 NLP 模型，它专门处理多轮文本和代码聊天以及代码生成等任务。该模型将于 2025 年 2 月 15 日停用，建议迁移到 1.5 系列模型。</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>不支持</td><td>对话</td><td>Google_gemini</td><td>这是 Gemini 1.0 Pro 的稳定版本。作为一个 NLP 模型，它专门处理多轮文本和代码聊天以及代码生成等任务。该模型将于 2025 年 2 月 15 日停用，建议迁移到 1.5 系列模型。</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>不支持</td><td>对话,已废弃或即将废弃</td><td>Google_gemini</td><td>这是 Gemini 1.0 Pro 的最新版本。作为一个 NLP 模型，它专门处理多轮文本和代码聊天以及代码生成等任务。该模型将于 2025 年 2 月 15 日停用，建议迁移到 1.5 系列模型。</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>不支持</td><td>对话</td><td>Google_gemini</td><td>这是 Gemini 1.0 Pro 的视觉版本。该模型将于 2025 年 2 月 15 日停用，建议迁移到 1.5 系列模型。</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>不支持</td><td>识图</td><td>Google_gemini</td><td>这是 Gemini 1.0 Pro 的视觉最新版本。该模型将于 2025 年 2 月 15 日停用，建议迁移到 1.5 系列模型。</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Flash 的最新稳定版本。作为一个平衡的多模态模型，它可以处理音频、图片、视频和文本输入。</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Flash 的稳定版本。它们提供与 gemini-1.5-flash 相同的基本功能，但版本固定，适合生产环境使用。</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Flash 的稳定版本。它们提供与 gemini-1.5-flash 相同的基本功能，但版本固定，适合生产环境使用。</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 1.5 Flash-8B是谷歌最新推出的一款多模态人工智能模型，专为高效处理大规模任务而设计。该模型具有80亿个参数，能够支持文本、图像、音频和视频的输入，适用于多种应用场景，如聊天、转录和翻译等。与其他Gemini模型相比，Flash-8B在速度和成本效益上进行了优化，特别适合对成本敏感的用户。其速率限制提高了一倍，使得开发者能够更高效地进行大规模任务处理。此外，Flash-8B还采用了“知识蒸馏”技术，从更大的模型中提炼出关键知识，确保在保持核心能力的同时实现轻量化和高效化</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Flash 的实验版本，会定期更新以包含最新的改进。适合探索性测试和原型开发，不建议用于生产环境。</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Flash 的尖端版本，会定期更新以包含最新的改进。适合探索性测试和原型开发，不建议用于生产环境。</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Pro 的稳定版本，提供固定的模型行为和性能特征。适合需要稳定性的生产环境使用。</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Pro 的稳定版本，提供固定的模型行为和性能特征。适合需要稳定性的生产环境使用。</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 1.5 Pro 的试验版本。作为一个强大的多模态模型，它可以处理长达6 万行代码或 2,000 页文本。特别适合需要复杂推理的任务。</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 1.5 Pro 的试验版本。作为一个强大的多模态模型，它可以处理长达6 万行代码或 2,000 页文本。特别适合需要复杂推理的任务。</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.5 Pro 的最新版本，动态指向最新的快照版本</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 2.0 Flash是谷歌最新推出的模型，相比1.5版本具有更快的首次生成速度(TTFT)，同时保持了与Gemini Pro 1.5相当的质量水平；该模型在多模态理解、代码能力、复杂指令执行和函数调用等方面都有显著提升，从而能够提供更流畅和强大的智能体验。</td></tr><tr><td>gemini-2.0-flash-exp</td><td>100k</td><td>8k</td><td>支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 2.0 Flash 引入多模态实时API、改进速度和性能、提升质量、增强代理能力，并增加图像生成和语音转换功能。</td></tr><tr><td>gemini-2.0-flash-lite-preview-02-05</td><td>1M</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 2.0 Flash-Lite是谷歌最新发布的高性价比AI模型，在保持与1.5 Flash相同速度的同时质量更好；支持100万tokens的上下文窗口，能够处理图像、音频和代码等多模态任务；作为目前谷歌成本效益最高的模型，采用简化的单一定价策略，特别适合需要控制成本的大规模应用场景。</td></tr><tr><td>gemini-2.0-flash-thinking-exp</td><td>40k</td><td>8k</td><td>不支持</td><td>对话,推理</td><td>Google_gemini</td><td>gemini-2.0-flash-thinking-exp是一个实验模型，它能生成在作出反应时所经历的 "思考过程"。因此，与基本的Gemini 2.0 Flash 模型相比，"思考模式 "的反应具有更强的推理能力。</td></tr><tr><td>gemini-2.0-flash-thinking-exp-01-21</td><td>1m</td><td>64k</td><td>不支持</td><td>对话,推理</td><td>Google_gemini</td><td>Gemini 2.0 Flash Thinking EXP-01-21 是谷歌最新推出的人工智能模型，专注于提升推理能力和用户交互体验。该模型具备强大的推理能力，尤其在数学和编程领域表现突出，并支持高达100万token的上下文窗口，适用于复杂任务和深入分析场景。其独特之处在于能够生成思考过程，提高AI思维的可理解性，同时支持原生代码执行，增强了交互的灵活性和实用性。通过优化算法，模型减少了逻辑矛盾，进一步提升了回答的准确性和一致性。</td></tr><tr><td>gemini-2.0-flash-thinking-exp-1219</td><td>40k</td><td>8k</td><td>不支持</td><td>对话,推理,识图</td><td>Google_gemini</td><td>gemini-2.0-flash-thinking-exp-1219是一个实验模型，它能生成在作出反应时所经历的 "思考过程"。因此，与基本的Gemini 2.0 Flash 模型相比，"思考模式 "的反应具有更强的推理能力。</td></tr><tr><td>gemini-2.0-pro-exp-01-28</td><td>2m</td><td>64k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>预加模型,还未上线</td></tr><tr><td>gemini-2.0-pro-exp-02-05</td><td>2m</td><td>8k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>Gemini 2.0 Pro Exp 02-05是谷歌2024年2月发布的最新实验性模型，在世界知识、代码生成和长文本理解方面表现突出；该模型支持200万tokens的超长上下文窗口，能处理2小时视频、22小时音频、6万多行代码和140万多单词的内容；作为Gemini 2.0系列的一部分，该模型采用了新的Flash Thinking训练策略，性能得到显著提升，在多个LLM评分榜单中名列前茅，展现了强大的综合能力。</td></tr><tr><td>gemini-exp-1114</td><td>8k</td><td>4k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是一个实验性模型，于 2024 年 11 月 14 日发布，主要关注质量改进。</td></tr><tr><td>gemini-exp-1121</td><td>8k</td><td>4k</td><td>不支持</td><td>对话,识图,代码</td><td>Google_gemini</td><td>这是一个实验性模型，于 2024 年 11 月 21 日发布，改进了编码、推理和视觉能力。</td></tr><tr><td>gemini-exp-1206</td><td>8k</td><td>4k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是一个实验性模型，于 2024 年 12 月 6 日发布，改进了编码、推理和视觉能力。</td></tr><tr><td>gemini-exp-latest</td><td>8k</td><td>4k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是一个实验性模型，动态指向最新版本</td></tr><tr><td>gemini-pro</td><td>33k</td><td>8k</td><td>不支持</td><td>对话</td><td>Google_gemini</td><td>同gemini-1.0-pro,是gemini-1.0-pro的别名</td></tr><tr><td>gemini-pro-vision</td><td>16k</td><td>2k</td><td>不支持</td><td>对话,识图</td><td>Google_gemini</td><td>这是 Gemini 1.0 Pro 的视觉版本。该模型将于 2025 年 2 月 15 日停用，建议迁移到 1.5 系列模型。</td></tr><tr><td>grok-2</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>Grok_grok</td><td>X.ai于2024.12.12发布的新版本grok模型.</td></tr><tr><td>grok-2-1212</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>Grok_grok</td><td>X.ai于2024.12.12发布的新版本grok模型.</td></tr><tr><td>grok-2-latest</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>Grok_grok</td><td>X.ai于2024.12.12发布的新版本grok模型.</td></tr><tr><td>grok-2-vision-1212</td><td>32k</td><td>-</td><td>不支持</td><td>对话,识图</td><td>Grok_grok</td><td>X.ai于2024.12.12发布的grok视觉版本模型.</td></tr><tr><td>grok-beta</td><td>100k</td><td>-</td><td>不支持</td><td>对话</td><td>Grok_grok</td><td>性能与 Grok 2 相当，但效率、速度和功能有所提高。</td></tr><tr><td>grok-vision-beta</td><td>8k</td><td>-</td><td>不支持</td><td>对话,识图</td><td>Grok_grok</td><td>最新的图像理解模型可以处理各种视觉信息，包括文档、图表、截图和照片。</td></tr><tr><td>internlm/internlm2_5-20b-chat</td><td>32k</td><td>-</td><td>支持</td><td>对话</td><td>internlm</td><td>InternLM2.5-20B-Chat 是一个开源的大规模对话模型，基于 InternLM2 架构开发。该模型拥有 200 亿参数，在数学推理方面表现出色，超越了同量级的 Llama3 和 Gemma2-27B 模型。InternLM2.5-20B-Chat 在工具调用能力方面有显著提升，支持从上百个网页收集信息进行分析推理，并具备更强的指令理解、工具选择和结果反思能力。</td></tr><tr><td>meta-llama/Llama-3.2-11B-Vision-Instruct</td><td>8k</td><td>-</td><td>不支持</td><td>对话,识图</td><td>Meta_llama</td><td>目前Llama系列模型不仅能够处理文本数据，还能够处理图像数据；Llama3.2的部分模型加入了视觉理解的功能，该模型支持同时输入文本和图像数据，对图像进行理解并输出文本信息。</td></tr><tr><td>meta-llama/Llama-3.2-3B-Instruct</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>Meta_llama</td><td>Meta Llama 3.2多语言大语言模型（LLM），其中1B、3B是可在边缘和移动设备上的运行的轻量级模型，本模型为3B版本。</td></tr><tr><td>meta-llama/Llama-3.2-90B-Vision-Instruct</td><td>8k</td><td>-</td><td>不支持</td><td>对话,识图</td><td>Meta_llama</td><td>目前Llama系列模型不仅能够处理文本数据，还能够处理图像数据；Llama3.2的部分模型加入了视觉理解的功能，该模型支持同时输入文本和图像数据，对图像进行理解并输出文本信息。</td></tr><tr><td>meta-llama/Llama-3.3-70B-Instruct</td><td>131k</td><td>-</td><td>不支持</td><td>对话</td><td>Meta_llama</td><td>Meta 的最新款 70B LLM，性能与 llama 3.1 405B 相当。</td></tr><tr><td>meta-llama/Meta-Llama-3.1-405B-Instruct</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>Meta_llama</td><td>Meta Llama 3.1多语言大语言模型（LLM）集合是8B、70B和405B尺寸的预训练和指令微调生成模型的集合，本模型为405B版本。Llama 3.1指令微调文本模型（8B、70B、405B）针对多语言对话进行了优化，在常见的行业基准上优于许多可用的开源和闭源聊天模型。</td></tr><tr><td>meta-llama/Meta-Llama-3.1-70B-Instruct</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>Meta_llama</td><td>Meta Llama 3.1 是由 Meta 开发的多语言大型语言模型家族，包括 8B、70B 和 405B 三种参数规模的预训练和指令微调变体。该 70B 指令微调模型针对多语言对话场景进行了优化，在多项行业基准测试中表现优异。模型训练使用了超过 15 万亿个 tokens 的公开数据，并采用了监督微调和人类反馈强化学习等技术来提升模型的有用性和安全性。</td></tr><tr><td>meta-llama/Meta-Llama-3.1-8B-Instruct</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>Meta_llama</td><td>Meta Llama 3.1多语言大语言模型（LLM）集合是8B、70B和405B尺寸的预训练和指令微调生成模型的集合，本模型为8B版本。Llama 3.1指令微调文本模型（8B、70B、405B）针对多语言对话进行了优化，在常见的行业基准上优于许多可用的开源和闭源聊天模型。</td></tr><tr><td>abab5.5-chat</td><td>16k</td><td>-</td><td>支持</td><td>对话</td><td>Minimax_abab</td><td>中文人设对话场景</td></tr><tr><td>abab5.5s-chat</td><td>8k</td><td>-</td><td>支持</td><td>对话</td><td>Minimax_abab</td><td>中文人设对话场景</td></tr><tr><td>abab6.5g-chat</td><td>8k</td><td>-</td><td>支持</td><td>对话</td><td>Minimax_abab</td><td>英文等多语种人设对话场景</td></tr><tr><td>abab6.5s-chat</td><td>245k</td><td>-</td><td>支持</td><td>对话</td><td>Minimax_abab</td><td>通用场景</td></tr><tr><td>abab6.5t-chat</td><td>8k</td><td>-</td><td>支持</td><td>对话</td><td>Minimax_abab</td><td>中文人设对话场景</td></tr><tr><td>chatgpt-4o-latest</td><td>128k</td><td>16k</td><td>不支持</td><td>对话,识图</td><td>OpenAI</td><td>chatgpt-4o-latest 模型版本持续指向 ChatGPT 中使用的 GPT-4o 版本，并在有重大变化时最快更新。</td></tr><tr><td>gpt-4o-2024-11-20</td><td>128k</td><td>16k</td><td>支持</td><td>对话</td><td>OpenAI</td><td>2024 年 11 月 20 日的最新 gpt-4o 快照版本。</td></tr><tr><td>gpt-4o-audio-preview</td><td>128k</td><td>16k</td><td>不支持</td><td>对话</td><td>OpenAI</td><td>OpenAI的实时语音对话模型</td></tr><tr><td>gpt-4o-audio-preview-2024-10-01</td><td>128k</td><td>16k</td><td>支持</td><td>对话</td><td>OpenAI</td><td>OpenAI的实时语音对话模型</td></tr><tr><td>o1</td><td>128k</td><td>32k</td><td>不支持</td><td>对话,推理,识图</td><td>OpenAI</td><td>ChatGPT Plus版o1，o1-pro 是OpenAI针对复杂任务的新推理模型，该任务需要广泛的常识。该模型具有 200k 上下文，目前全球最强模型，支持图片识别</td></tr><tr><td>o1-mini-2024-09-12</td><td>128k</td><td>64k</td><td>不支持</td><td>对话,推理</td><td>OpenAI</td><td>o1-mini的固定快照版本,比 o1-preview 更小、更快，成本低80%，在代码生成和小上下文操作方面表现良好。</td></tr><tr><td>o1-preview-2024-09-12</td><td>128k</td><td>32k</td><td>不支持</td><td>对话,推理</td><td>OpenAI</td><td>o1-preview的固定快照版本</td></tr><tr><td>gpt-3.5-turbo</td><td>16k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-3</td><td>基于 GPT-3.5： GPT-3.5 Turbo 是建立在 GPT-3.5 模型基础上的改进版本，由 OpenAI 开发。<br>性能目标： 设计目的是通过优化模型结构和算法，提高模型的推理速度、处理效率和资源利用率。<br>提升的推理速度： 相对于 GPT-3.5，GPT-3.5 Turbo 在相同硬件条件下通常能够提供更快的推理速度，这对于需要大规模文本处理的应用特别有益。<br>更高的吞吐量： 在处理大量请求或数据时，GPT-3.5 Turbo 可以实现更高的并发处理能力，从而提升整体的系统吞吐量。<br>优化的资源消耗： 在保持性能的同时，可能降低了对硬件资源（如内存和计算资源）的需求，这有助于降低运行成本和提高系统的可扩展性。<br>广泛的自然语言处理任务： GPT-3.5 Turbo 适用于多种自然语言处理任务，包括但不限于文本生成、语义理解、对话系统、机器翻译等。<br>开发者工具和API支持： 提供了便于开发者集成和使用的 API 接口，支持快速开发和部署应用程序。</td></tr><tr><td>gpt-3.5-turbo-0125</td><td>16k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-3</td><td>更新后的 GPT 3.5 Turbo，响应请求格式的准确性更高，并修复了一个导致非英语语言函数调用文本编码问题的错误。返回最多 4,096 个输出令牌。</td></tr><tr><td>gpt-3.5-turbo-0613</td><td>16k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-3</td><td>更新后的 GPT 3.5 Turbo固定快照版本。目前已弃用</td></tr><tr><td>gpt-3.5-turbo-1106</td><td>16k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-3</td><td>具有改进的指令跟随、JSON 模式、可重现输出、并行函数调用等。返回最多 4,096 个输出令牌。</td></tr><tr><td>gpt-3.5-turbo-16k</td><td>16k</td><td>4k</td><td>支持</td><td>对话,已废弃或即将废弃</td><td>OpenAI_gpt-3</td><td>（已弃用）</td></tr><tr><td>gpt-3.5-turbo-16k-0613</td><td>16k</td><td>4k</td><td>支持</td><td>对话,已废弃或即将废弃</td><td>OpenAI_gpt-3</td><td> gpt-3.5-turbo 于 2023年6月13日的快照。（已弃用）</td></tr><tr><td>gpt-3.5-turbo-instruct</td><td>4k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-3</td><td>与 GPT-3 时代模型类似的能力。与遗留 Completions 端点兼容，不适用于 Chat Completions。</td></tr><tr><td>gpt-3.5o</td><td>16k</td><td>4k</td><td>不支持</td><td>对话</td><td>OpenAI_gpt-3</td><td>同gpt-4o-lite</td></tr><tr><td>gpt-4</td><td>8k</td><td>8k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>目前指向 gpt-4-0613。</td></tr><tr><td>gpt-4-0125-preview</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>最新的 GPT-4 模型，旨在减少“懒惰”情况，即模型未完成任务。返回最多 4,096 个输出令牌。</td></tr><tr><td>gpt-4-0314</td><td>8k</td><td>8k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>gpt-4  2023年3月14日的快照</td></tr><tr><td>gpt-4-0613</td><td>8k</td><td>8k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>gpt-4  2023年6月13日的快照，增强了函数调用支持。</td></tr><tr><td>gpt-4-1106-preview</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>GPT-4 Turbo 模型，具有改进的指令跟随、JSON 模式、可再现输出、函数调用等。返回最多 4,096 个输出令牌。这是预览模型。</td></tr><tr><td>gpt-4-32k</td><td>32k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>gpt-4-32k将于2025-06-06弃用。</td></tr><tr><td>gpt-4-32k-0613</td><td>32k</td><td>4k</td><td>支持</td><td>对话,已废弃或即将废弃</td><td>OpenAI_gpt-4</td><td>将于2025-06-06弃用。</td></tr><tr><td>gpt-4-turbo</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>最新版的 GPT-4 Turbo 模型新增了视觉功能，支持通过 JSON 模式和函数调用来处理视觉请求。该模型当前版本为 gpt-4-turbo-2024-04-09。</td></tr><tr><td>gpt-4-turbo-2024-04-09</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>OpenAI_gpt-4</td><td>带视觉功能的 GPT-4 Turbo 模型。现在，视觉请求能够通过 JSON 模式和函数调用来实现。gpt-4-turbo 目前版本就是这一版。</td></tr><tr><td>gpt-4-turbo-preview</td><td>128k</td><td>4k</td><td>支持</td><td>对话,识图</td><td>OpenAI_gpt-4</td><td>目前指向 gpt-4-0125-preview。</td></tr><tr><td>gpt-4o</td><td>128k</td><td>16k</td><td>支持</td><td>对话,识图</td><td>OpenAI_gpt-4</td><td>OpenAI的高智能旗舰模型，适用于复杂的多步骤任务。GPT-4o 比 GPT-4 Turbo 更便宜、更快速。</td></tr><tr><td>gpt-4o-2024-05-13</td><td>128k</td><td>4k</td><td>支持</td><td>对话,识图</td><td>OpenAI_gpt-4</td><td>2024 年 5 月 13 日的原始 gpt-4o 快照。</td></tr><tr><td>gpt-4o-2024-08-06</td><td>128k</td><td>16k</td><td>支持</td><td>对话,识图</td><td>OpenAI_gpt-4</td><td>支持结构化输出的第一个快照。gpt-4o目前指向此版本。</td></tr><tr><td>gpt-4o-mini</td><td>128k</td><td>16k</td><td>支持</td><td>对话,识图</td><td>OpenAI_gpt-4</td><td>OpenAI经济实惠的gpt-4o版本，适用于快速、轻量级任务。GPT-4o mini 比 GPT-3.5 Turbo 更便宜，功能更强大。目前指向 gpt-4o-mini-2024-07-18。</td></tr><tr><td>gpt-4o-mini-2024-07-18</td><td>128k</td><td>16k</td><td>支持</td><td>对话,识图</td><td>OpenAI_gpt-4</td><td>gpt-4o-mini的固定快照版本。</td></tr><tr><td>gpt-4o-realtime-preview</td><td>128k</td><td>4k</td><td>支持</td><td>对话,实时语音</td><td>OpenAI_gpt-4</td><td>OpenAI的实时语音对话模型</td></tr><tr><td>gpt-4o-realtime-preview-2024-10-01</td><td>128k</td><td>4k</td><td>支持</td><td>对话,实时语音,识图</td><td>OpenAI_gpt-4</td><td>gpt-4o-realtime-preview当前指向这个快照版本</td></tr><tr><td>o1-mini</td><td>128k</td><td>64k</td><td>不支持</td><td>对话,推理</td><td>OpenAI_o1</td><td>比 o1-preview 更小、更快，成本低80%，在代码生成和小上下文操作方面表现良好。</td></tr><tr><td>o1-preview</td><td>128k</td><td>32k</td><td>不支持</td><td>对话,推理</td><td>OpenAI_o1</td><td>o1-preview 是针对需要广泛常识的复杂任务的新推理模型。该模型具有 128K 上下文和 2023 年 10 月的知识截止点。专注于高级推理和解决复杂问题，包括数学和科学任务。非常适合需要深度上下文理解和自主工作流程的应用。</td></tr><tr><td>o3-mini</td><td>200k</td><td>100k</td><td>支持</td><td>对话,推理</td><td>OpenAI_o1</td><td>o3-mini是OpenAI最新的小型推理模型，在保持与o1-mini相同成本和延迟的情况下提供高智能，专注于科学、数学和编码任务，支持结构化输出、函数调用、批量API等开发者功能，且知识库截止到2023年10月，展现了在推理能力和经济性方面的显著平衡。</td></tr><tr><td>o3-mini-2025-01-31</td><td>200k</td><td>100k</td><td>支持</td><td>对话,推理</td><td>OpenAI_o1</td><td>o3-mini当前指向该版本，o3-mini-2025-01-31是OpenAI最新的小型推理模型，在保持与o1-mini相同成本和延迟的情况下提供高智能，专注于科学、数学和编码任务，支持结构化输出、函数调用、批量API等开发者功能，且知识库截止到2023年10月，展现了在推理能力和经济性方面的显著平衡。</td></tr><tr><td>Baichuan2-Turbo</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>百川_baichuan</td><td>相对业界同等尺寸模型，模型效果在保持行业领先的同时，实现了价格的大幅度降低</td></tr><tr><td>Baichuan3-Turbo</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>百川_baichuan</td><td>相对业界同等尺寸模型，模型效果在保持行业领先的同时，实现了价格的大幅度降低</td></tr><tr><td>Baichuan3-Turbo-128k</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>百川_baichuan</td><td>百川模型通过128k超长上下文窗口处理复杂文本，针对金融等行业进行专门优化，同时在保持高性能的前提下大幅降低成本，为企业提供高性价比的解决方案。</td></tr><tr><td>Baichuan4</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>百川_baichuan</td><td>百川的MoE模型通过专门优化、降低成本和提升性能，在企业应用中提供了高效性价比的解决方案。</td></tr><tr><td>Baichuan4-Air</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>百川_baichuan</td><td>百川的MoE模型通过专门优化、降低成本和提升性能，在企业应用中提供了高效性价比的解决方案。</td></tr><tr><td>Baichuan4-Turbo</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>百川_baichuan</td><td>基于海量优质的场景数据训练，企业高频场景可用性相对Baichuan4提升10%+，信息摘要提升50%，多语言提升31%，内容生成提升13%<br>针对推理性能专项优化，首token响应速度相对Baichuan4提升51%，token流速提升73%</td></tr><tr><td>ERNIE-3.5-128K</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。</td></tr><tr><td>ERNIE-3.5-8K</td><td>8k</td><td>1k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。</td></tr><tr><td>ERNIE-3.5-8K-Preview</td><td>8k</td><td>1k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的旗舰级大规模⼤语⾔模型，覆盖海量中英文语料，具有强大的通用能力，可满足绝大部分对话问答、创作生成、插件应用场景要求；支持自动对接百度搜索插件，保障问答信息时效。</td></tr><tr><td>ERNIE-4.0-8K</td><td>8k</td><td>1k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。</td></tr><tr><td>ERNIE-4.0-8K-Latest</td><td>8k</td><td>2k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE-4.0-8K-Latest相比ERNIE-4.0-8K能力全面提升，其中角色扮演能力和指令遵循能力提升较大；相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效，支持5K tokens输入+2K tokens输出。本文介绍了ERNIE-4.0-8K-Latest接口调用方法。</td></tr><tr><td>ERNIE-4.0-8K-Preview</td><td>8k</td><td>1k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的旗舰级超大规模⼤语⾔模型，相较ERNIE 3.5实现了模型能力全面升级，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。</td></tr><tr><td>ERNIE-4.0-Turbo-128K</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE 4.0 Turbo是百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀。ERNIE-4.0-Turbo-128K是模型的一个版本，长文档整体效果优于ERNIE-3.5-128K。本文介绍了相关API及使用。</td></tr><tr><td>ERNIE-4.0-Turbo-8K</td><td>8k</td><td>2k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE 4.0 Turbo是百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀。ERNIE-4.0-Turbo-8K是模型的一个版本。本文介绍了相关API及使用。</td></tr><tr><td>ERNIE-4.0-Turbo-8K-Latest</td><td>8k</td><td>2k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE 4.0 Turbo是百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。相较于ERNIE 4.0在性能表现上更优秀。ERNIE-4.0-Turbo-8K是模型的一个版本。</td></tr><tr><td>ERNIE-4.0-Turbo-8K-Preview</td><td>8k</td><td>2k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE 4.0 Turbo是百度自研的旗舰级超大规模⼤语⾔模型，综合效果表现出色，广泛适用于各领域复杂任务场景；支持自动对接百度搜索插件，保障问答信息时效。ERNIE-4.0-Turbo-8K-Preview是模型的一个版本</td></tr><tr><td>ERNIE-Character-8K</td><td>8k</td><td>1k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的垂直场景大语言模型，适合游戏NPC、客服对话、对话角色扮演等应用场景，人设风格更为鲜明、一致，指令遵循能力更强，推理性能更优</td></tr><tr><td>ERNIE-Lite-8K</td><td>8k</td><td>4k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的轻量级大语言模型，兼顾优异的模型效果与推理性能，适合低算力AI加速卡推理使用。</td></tr><tr><td>ERNIE-Lite-Pro-128K</td><td>128k</td><td>2k</td><td>支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的轻量级大语言模型，效果比ERNIE Lite更优，兼顾优异的模型效果与推理性能，适合低算力AI加速卡推理使用。ERNIE-Lite-Pro-128K支持128K上下文长度，效果比ERNIE-Lite-128K更优。</td></tr><tr><td>ERNIE-Novel-8K</td><td>8k</td><td>2k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE-Novel-8K是百度自研通用大语言模型，在小说续写能力上有明显优势，也可用在短剧、电影等场景。</td></tr><tr><td>ERNIE-Speed-128K</td><td>128k</td><td>4k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>百度2024年最新发布的自研高性能大语言模型，通用能力优异，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。</td></tr><tr><td>ERNIE-Speed-8K</td><td>8k</td><td>1k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>百度2024年最新发布的自研高性能大语言模型，通用能力优异，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。</td></tr><tr><td>ERNIE-Speed-Pro-128K</td><td>128k</td><td>4k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>ERNIE Speed Pro是百度2024年最新发布的自研高性能大语言模型，通用能力优异，适合作为基座模型进行精调，更好地处理特定场景问题，同时具备极佳的推理性能。ERNIE-Speed-Pro-128K是2024年8月30日发布的初始版本，支持128K上下文长度，效果比ERNIE-Speed-128K更优。</td></tr><tr><td>ERNIE-Tiny-8K</td><td>8k</td><td>1k</td><td>不支持</td><td>对话</td><td>百度_ernie</td><td>百度自研的超高性能大语言模型，部署与精调成本在文心系列模型中最低。</td></tr><tr><td>Doubao-1.5-lite-32k</td><td>32k</td><td>12k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>Doubao1.5-lite在轻量版语言模型中也处于全球一流水平，在综合（MMLU_pro）、推理（BBH）、数学（MATH）、专业知识（GPQA）权威测评指标持平或超越GPT-4omini，Cluade 3.5 Haiku。<br></td></tr><tr><td>Doubao-1.5-pro-256k</td><td>256k</td><td>12k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>Doubao-1.5-Pro-256k，基于Doubao-1.5-Pro全面升级版。相比Doubao-pro-256k/241115，整体效果大幅提升10%。输出长度大幅提升，支持最大12k tokens。</td></tr><tr><td>Doubao-1.5-pro-32k</td><td>32k</td><td>12k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>Doubao-1.5-pro，全新一代主力模型，性能全面升级，在知识、代码、推理、等方面表现卓越。在多项公开测评基准上达到全球领先水平，特别在知识、代码、推理、中文权威测评基准上获得最佳成绩，综合得分优于GPT4o、Claude 3.5 Sonnet等业界一流模型。</td></tr><tr><td>Doubao-1.5-vision-pro</td><td>32k</td><td>12k</td><td>不支持</td><td>对话,识图</td><td>豆包_doubao</td><td>Doubao-1.5-vision-pro，全新升级的多模态大模型，支持任意分辨率和极端长宽比图像识别，增强视觉推理、文档识别、细节信息理解和指令遵循能力。</td></tr><tr><td>Doubao-embedding</td><td>4k</td><td>-</td><td>支持</td><td>嵌入</td><td>豆包_doubao</td><td>Doubao-embedding 是一款由字节跳动研发的语义向量化模型，主要面向向量检索的使用场景，支持中、英双语，最长 4K 上下文长度。目前提供以下版本：<br><br>text-240715：最高维度向量 2560，支持 512、1024、2048 降维使用。中英文 Retrieval效果较 text-240515 版本有较大提升，推荐使用该版本。<br>text-240515：最高维度向量 2048，支持 512、1024 降维使用。</td></tr><tr><td>Doubao-embedding-large</td><td>4k</td><td>-</td><td>不支持</td><td>嵌入</td><td>豆包_doubao</td><td><br>中英文Retrieval效果较Doubao-embedding/text-240715版本显著提升</td></tr><tr><td>Doubao-embedding-vision</td><td>8k</td><td>-</td><td>不支持</td><td>嵌入</td><td>豆包_doubao</td><td>Doubao-embedding-vision，全新升级图文多模态向量化模型，主要面向图文多模向量检索的使用场景，支持图片输入及中、英双语文本输入，最长 8K 上下文长度。</td></tr><tr><td>Doubao-lite-128k</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>Doubao-lite 拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持128k上下文窗口的推理和精调。</td></tr><tr><td>Doubao-lite-32k</td><td>32k</td><td>4k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>Doubao-lite拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持32k上下文窗口的推理和精调。</td></tr><tr><td>Doubao-lite-4k</td><td>4k</td><td>4k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>Doubao-lite拥有极致的响应速度，更好的性价比，为客户不同场景提供更灵活的选择。支持4k上下文窗口的推理和精调。</td></tr><tr><td>Doubao-pro-128k</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持128k上下文窗口的推理和精调。</td></tr><tr><td>Doubao-pro-32k</td><td>32k</td><td>4k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持32k上下文窗口的推理和精调。</td></tr><tr><td>Doubao-pro-4k</td><td>4k</td><td>4k</td><td>支持</td><td>对话</td><td>豆包_doubao</td><td>效果最好的主力模型，适合处理复杂任务，在参考问答、总结摘要、创作、文本分类、角色扮演等场景都有很好的效果。支持4k上下文窗口的推理和精调。</td></tr><tr><td>step-1-128k</td><td>128k</td><td>-</td><td>支持</td><td>对话</td><td>阶跃星辰</td><td>step-1-128k模型是一个超大规模的语言模型，能够处理高达128,000个token的输入。这种能力使其在生成长篇内容和进行复杂推理时具有显著优势，适合用于创作小说、剧本等需要丰富上下文的应用。</td></tr><tr><td>step-1-256k</td><td>256k</td><td>-</td><td>支持</td><td>对话</td><td>阶跃星辰</td><td>step-1-256k模型是目前最大的语言模型之一，支持256,000个token的输入。它的设计旨在满足极端复杂的任务需求，如大规模数据分析和多轮对话系统，能够在多种领域中提供高质量的输出。</td></tr><tr><td>step-1-32k</td><td>32k</td><td>-</td><td>支持</td><td>对话</td><td>阶跃星辰</td><td>step-1-32k模型扩展了上下文窗口，支持32,000个token的输入。这使得它在处理长篇文章和复杂对话时表现出色，适合需要深入理解和分析的任务，如法律文书和学术研究。</td></tr><tr><td>step-1-8k</td><td>8k</td><td>-</td><td>支持</td><td>对话</td><td>阶跃星辰</td><td>step-1-8k模型是一个高效的语言模型，专为处理较短文本而设计。它能够在8,000个token的上下文中进行推理，适合需要快速响应的应用场景，如聊天机器人和实时翻译。</td></tr><tr><td>step-1-flash</td><td>8k</td><td>-</td><td>支持</td><td>对话</td><td>阶跃星辰</td><td>step-1-flash模型专注于快速响应和高效处理，适合实时应用。它的设计使得在有限的计算资源下仍能提供优质的语言理解和生成能力，适合移动设备和边缘计算场景。</td></tr><tr><td>step-1.5v-mini</td><td>32k</td><td>-</td><td>支持</td><td>对话,识图</td><td>阶跃星辰</td><td>step-1.5v-mini模型是一个轻量级版本，旨在在资源受限的环境中运行。尽管体积小，但它仍然保留了良好的语言处理能力，适合嵌入式系统和低功耗设备。</td></tr><tr><td>step-1v-32k</td><td>32k</td><td>-</td><td>支持</td><td>对话,识图</td><td>阶跃星辰</td><td>step-1v-32k模型支持32,000个token的输入，适合需要更长上下文的应用。它在处理复杂对话和长文本时表现出色，适合客户服务和内容创作等领域。</td></tr><tr><td>step-1v-8k</td><td>8k</td><td>-</td><td>支持</td><td>对话,识图</td><td>阶跃星辰</td><td>step-1v-8k模型是一个优化的版本，专为8,000个token的输入设计，适合快速生成和处理短文本。它在速度和准确性之间取得了良好的平衡，适合实时应用。</td></tr><tr><td>step-2-16k</td><td>16k</td><td>-</td><td>支持</td><td>对话</td><td>阶跃星辰</td><td>step-2-16k模型是一个中等规模的语言模型，支持16,000个token的输入。它在多种任务中表现良好，适合教育、培训和知识管理等应用场景。<br></td></tr><tr><td>yi-lightning</td><td>16k</td><td>-</td><td>支持</td><td>对话</td><td>零一万物_yi</td><td>最新高性能模型，保证高质量输出同时，推理速度大幅提升。<br>适用于实时交互，高复杂推理场景，极高的性价比能够为商业产品提供极好的产品支撑。</td></tr><tr><td>yi-vision-v2</td><td>16K</td><td>-</td><td>支持</td><td>对话,识图</td><td>零一万物_yi</td><td>适合需要分析和解释图像、图表的场景，如图片问答、图表理解、OCR、视觉推理、教育、研究报告理解或多语种文档阅读等。</td></tr><tr><td>qwen-14b-chat</td><td>8k</td><td>2k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>阿里云官方的通义千问-开源版。</td></tr><tr><td>qwen-72b-chat</td><td>32k</td><td>2k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>阿里云官方的通义千问-开源版。</td></tr><tr><td>qwen-7b-chat</td><td>7.5k</td><td>1.5k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>阿里云官方的通义千问-开源版。</td></tr><tr><td>qwen-coder-plus</td><td>128k</td><td>8k</td><td>支持</td><td>对话,代码</td><td>千问_qwen</td><td>Qwen-Coder-Plus是Qwen系列中的一款编程专用模型，旨在提升代码生成和理解能力。该模型通过大规模的编程数据训练，能够处理多种编程语言，支持代码补全、错误检测和代码重构等功能。其设计目标是为开发者提供更高效的编程辅助，提升开发效率。</td></tr><tr><td>qwen-coder-plus-latest</td><td>128k</td><td>8k</td><td>支持</td><td>对话,代码</td><td>千问_qwen</td><td>Qwen-Coder-Plus-Latest是Qwen-Coder-Plus的最新版本，包含了最新的算法优化和数据集更新。该模型在性能上有显著提升，能够更准确地理解上下文，生成更符合开发者需求的代码。它还引入了更多的编程语言支持，增强了多语言编程的能力。</td></tr><tr><td>qwen-coder-turbo</td><td>128k</td><td>8k</td><td>支持</td><td>对话,代码</td><td>千问_qwen</td><td>通义千问系列代码及编程模型是专门用于编程和代码生成的语言模型，推理速度快，成本低。该版本始终指向最新稳定版快照</td></tr><tr><td>qwen-coder-turbo-latest</td><td>128k</td><td>8k</td><td>支持</td><td>对话,代码</td><td>千问_qwen</td><td>通义千问系列代码及编程模型是专门用于编程和代码生成的语言模型，推理速度快，成本低。该版本始终指向最新版快照</td></tr><tr><td>qwen-long</td><td>10m</td><td>6k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Long是在通义千问针对超长上下文处理场景的大语言模型，支持中文、英文等不同语言输入，支持最长1000万tokens(约1500万字或1.5万页文档)的超长上下文对话。配合同步上线的文档服务，可支持word、pdf、markdown、epub、mobi等多种文档格式的解析和对话。 说明：通过HTTP直接提交请求，支持1M tokens长度，超过此长度建议通过文件方式提交。</td></tr><tr><td>qwen-math-plus</td><td>4k</td><td>3k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Math-Plus是专注于数学问题解决的模型，旨在提供高效的数学推理和计算能力。该模型通过大量的数学题库进行训练，能够处理复杂的数学表达式和问题，支持从基础算术到高等数学的多种计算需求。其应用场景包括教育、科研和工程等领域。</td></tr><tr><td>qwen-math-plus-latest</td><td>4k</td><td>3k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Math-Plus-Latest是Qwen-Math-Plus的最新版本，集成了最新的数学推理技术和算法改进。该模型在处理复杂数学问题时表现更为出色，能够提供更准确的解答和推理过程。它还扩展了对数学符号和公式的理解能力，适用于更广泛的数学应用场景。</td></tr><tr><td>qwen-math-turbo</td><td>4k</td><td>3k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Math-Turbo是一个高性能的数学模型，专为快速计算和实时推理而设计。该模型优化了计算速度，能够在极短的时间内处理大量数学问题，适合需要快速反馈的应用场景，如在线教育和实时数据分析。其高效的算法使得用户能够在复杂计算中获得即时结果。</td></tr><tr><td>qwen-math-turbo-latest</td><td>4k</td><td>3k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Math-Turbo-Latest是Qwen-Math-Turbo的最新版本，进一步提升了计算效率和准确性。该模型在算法上进行了多项优化，能够处理更复杂的数学问题，并在实时推理中保持高效性。它适合用于需要快速响应的数学应用，如金融分析和科学计算。</td></tr><tr><td>qwen-max</td><td>32k</td><td>8k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>通义千问2.5系列千亿级别超大规模语言模型，支持中文、英文等不同语言输入。随着模型的升级，qwen-max将滚动更新升级。</td></tr><tr><td>qwen-max-latest</td><td>32k</td><td>8k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>通义千问系列效果最好的模型，本模型是动态更新版本，模型更新不会提前通知，适合复杂、多步骤的任务，模型中英文综合能力显著提升，模型人类偏好显著提升，模型推理能力和复杂指令理解能力显著增强，困难任务上的表现更优，数学、代码能力显著提升，提升对Table、JSON等结构化数据的理解和生成能力。</td></tr><tr><td>qwen-plus</td><td>128k</td><td>8k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>通义千问系列能力均衡的模型，推理效果和速度介于通义千问-Max和通义千问-Turbo之间，适合中等复杂任务。模型中英文综合能力显著提升，模型人类偏好显著提升，模型推理能力和复杂指令理解能力显著增强，困难任务上的表现更优，数学、代码能力显著提升。</td></tr><tr><td>qwen-plus-latest</td><td>128k</td><td>8k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Plus是通义千问系列中的增强版视觉语言模型，旨在提升细节识别能力和文字识别能力。该模型支持超百万像素分辨率和任意长宽比规格的图像，能够在多种视觉语言任务中表现出色，适合需要高精度图像理解的应用场景。</td></tr><tr><td>qwen-turbo</td><td>128k</td><td>8k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>通义千问系列速度最快、成本很低的模型，适合简单任务。模型中英文综合能力显著提升，模型人类偏好显著提升，模型推理能力和复杂指令理解能力显著增强，困难任务上的表现更优，数学、代码能力显著提升。</td></tr><tr><td>qwen-turbo-latest</td><td>1m</td><td>8k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>Qwen-Turbo是为简单任务设计的高效模型，强调速度和成本效益。它在处理基本的视觉语言任务时表现出色，适合对响应时间有严格要求的应用，如实时图像识别和简单的问答系统。</td></tr><tr><td>qwen-vl-max</td><td>32k</td><td>2k</td><td>支持</td><td>对话</td><td>千问_qwen</td><td>通义千问VL-Max（qwen-vl-max），即通义千问超大规模视觉语言模型。相比增强版，再次提升视觉推理能力和指令遵循能力，提供更高的视觉感知和认知水平。在更多复杂任务上提供最佳的性能。</td></tr><tr><td>qwen-vl-max-latest</td><td>32k</td><td>2k</td><td>支持</td><td>对话,识图</td><td>千问_qwen</td><td>Qwen-VL-Max是Qwen-VL系列中的最高级版本，专为解决复杂的多模态任务而设计。它结合了先进的视觉和语言处理技术，能够理解和分析高分辨率图像，推理能力极强，适合需要深度理解和复杂推理的应用场景。</td></tr><tr><td>qwen-vl-ocr</td><td>34k</td><td>4k</td><td>支持</td><td>对话,识图</td><td>千问_qwen</td><td>只支持ocr,不支持对话。</td></tr><tr><td>qwen-vl-ocr-latest</td><td>34k</td><td>4k</td><td>支持</td><td>对话,识图</td><td>千问_qwen</td><td>只支持ocr,不支持对话。</td></tr><tr><td>qwen-vl-plus</td><td>8k</td><td>2k</td><td>支持</td><td>对话,识图</td><td>千问_qwen</td><td>通义千问VL-Plus（qwen-vl-plus），即通义千问大规模视觉语言模型增强版。大幅提升细节识别能力和文字识别能力，支持超百万像素分辨率和任意长宽比规格的图像。在广泛的视觉任务上提供卓越的性能。</td></tr><tr><td>qwen-vl-plus-latest</td><td>32k</td><td>2k</td><td>支持</td><td>对话,识图</td><td>千问_qwen</td><td>Qwen-VL-Plus-Latest是Qwen-VL-Plus的最新版本，增强了模型的多模态理解能力。它在图像和文本的结合处理上表现出色，适合需要高效处理多种输入格式的应用，如智能客服和内容生成。</td></tr><tr><td>Qwen/Qwen2-1.5B-Instruct</td><td>32k</td><td>6k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2-1.5B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 1.5B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型。</td></tr><tr><td>Qwen/Qwen2-72B-Instruct</td><td>128k</td><td>6k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2-72B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 72B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型</td></tr><tr><td>Qwen/Qwen2-7B-Instruct</td><td>128k</td><td>6k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2-7B-Instruct 是 Qwen2 系列中的指令微调大语言模型，参数规模为 7B。该模型基于 Transformer 架构，采用了 SwiGLU 激活函数、注意力 QKV 偏置和组查询注意力等技术。它能够处理大规模输入。该模型在语言理解、生成、多语言能力、编码、数学和推理等多个基准测试中表现出色，超越了大多数开源模型</td></tr><tr><td>Qwen/Qwen2-VL-72B-Instruct</td><td>32k</td><td>2k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2-VL 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够理解超过 20 分钟的视频，用于高质量的基于视频的问答、对话和内容创作。它还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。</td></tr><tr><td>Qwen/Qwen2-VL-7B-Instruct</td><td>32k</td><td>-</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2-VL-7B-Instruct 是 Qwen-VL 模型的最新迭代版本，在视觉理解基准测试中达到了最先进的性能，包括 MathVista、DocVQA、RealWorldQA 和 MTVQA 等。Qwen2-VL 能够用于高质量的基于视频的问答、对话和内容创作，还具备复杂推理和决策能力，可以与移动设备、机器人等集成，基于视觉环境和文本指令进行自动操作。</td></tr><tr><td>Qwen/Qwen2.5-72B-Instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的输入，可以生成超过 8K tokens 的长文本。</td></tr><tr><td>Qwen/Qwen2.5-72B-Instruct-128K</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2.5-72B-Instruct 是阿里云发布的最新大语言模型系列之一。该 72B 模型在编码和数学等领域具有显著改进的能力。它支持长达 128K tokens 的输入，可以生成超过 8K tokens 的长文本。</td></tr><tr><td>Qwen/Qwen2.5-7B-Instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升</td></tr><tr><td>Qwen/Qwen2.5-Coder-32B-Instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话,代码</td><td>千问_qwen</td><td>Qwen2.5-32B-Instruct 是阿里云发布的最新大语言模型系列之一。该 32B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升</td></tr><tr><td>Qwen/Qwen2.5-Coder-7B-Instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>Qwen2.5-7B-Instruct 是阿里云发布的最新大语言模型系列之一。该 7B 模型在编码和数学等领域具有显著改进的能力。该模型还提供了多语言支持，覆盖超过 29 种语言，包括中文、英文等。模型在指令跟随、理解结构化数据以及生成结构化输出（尤其是 JSON）方面都有显著提升</td></tr><tr><td>Qwen/QwQ-32B-Preview</td><td>32k</td><td>16k</td><td>不支持</td><td>对话,推理</td><td>千问_qwen</td><td>QwQ-32B-Preview 是由 Qwen 团队开发的实验性研究模型，旨在提升人工智能的推理能力。作为预览版本，它展示了出色的分析能力，但也存在一些重要的限制：<br>1. 语言混合和代码切换：模型可能会混合使用语言或在语言之间意外切换，影响响应的清晰度。<br>2. 递归推理循环：模型可能会进入循环推理模式，导致冗长的回答而没有明确的结论。<br>3. 安全和伦理考量：模型需要加强安全措施以确保可靠和安全的性能，用户在使用时应谨慎。<br>4. 性能和基准限制：模型在数学和编程方面表现出色，但在常识推理和细微语言理解等其他领域仍有改进空间。</td></tr><tr><td>qwen1.5-110b-chat</td><td>32k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen1.5-14b-chat</td><td>8k</td><td>2k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen1.5-32b-chat</td><td>32k</td><td>2k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen1.5-72b-chat</td><td>32k</td><td>2k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen1.5-7b-chat</td><td>8k</td><td>2k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2-57b-a14b-instruct</td><td>65k</td><td>6k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>Qwen2-72B-Instruct</td><td>-</td><td>-</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2-7b-instruct</td><td>128k</td><td>6k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2-math-72b-instruct</td><td>4k</td><td>3k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2-math-7b-instruct</td><td>4k</td><td>3k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-14b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-32b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-72b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-7b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-coder-14b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话,代码</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-coder-32b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话,代码</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-coder-7b-instruct</td><td>128k</td><td>8k</td><td>不支持</td><td>对话,代码</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-math-72b-instruct</td><td>4k</td><td>3k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>qwen2.5-math-7b-instruct</td><td>4k</td><td>3k</td><td>不支持</td><td>对话</td><td>千问_qwen</td><td>-</td></tr><tr><td>deepseek-ai/DeepSeek-R1</td><td>64k</td><td>-</td><td>不支持</td><td>对话,推理</td><td>深度求索_deepseek</td><td>DeepSeek-R1模型是一款基于纯强化学习的开源推理模型，其在数学、代码和自然语言推理等任务上表现出色，性能可与OpenAI的o1模型相媲美，且在多个基准测试中取得了优异的成绩。</td></tr><tr><td>deepseek-ai/DeepSeek-V2-Chat</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>深度求索_deepseek</td><td>DeepSeek-V2 是一个强大、经济高效的混合专家（MoE）语言模型。它在 8.1 万亿个 token 的高质量语料库上进行了预训练，并通过监督微调（SFT）和强化学习（RL）进一步提升了模型能力。与 DeepSeek 67B 相比， DeepSeek-V2 在性能更强的同时，节省了 42.5% 的训练成本，减少了 93.3% 的 KV 缓存，并将最大生成吞吐量提高到了 5.76 倍。</td></tr><tr><td>deepseek-ai/DeepSeek-V2.5</td><td>32k</td><td>-</td><td>支持</td><td>对话</td><td>深度求索_deepseek</td><td>DeepSeek-V2.5 是 DeepSeek-V2-Chat 和 DeepSeek-Coder-V2-Instruct 的升级版本，集成了两个先前版本的通用和编码能力。该模型在多个方面进行了优化，包括写作和指令跟随能力，更好地与人类偏好保持一致。</td></tr><tr><td>deepseek-ai/DeepSeek-V3</td><td>128k</td><td>4k</td><td>不支持</td><td>对话</td><td>深度求索_deepseek</td><td>deepseek开源版本，相对官方版上下文更长，无敏感词拒答等问题。</td></tr><tr><td>deepseek-chat</td><td>64k</td><td>8k</td><td>支持</td><td>对话</td><td>深度求索_deepseek</td><td>236B 参数量,64K 上下文（API）,中文综合能力（AlignBench）位列开源榜首,与 GPT-4-Turbo，文心 4.0 等闭源模型在评测中处于同一梯队</td></tr><tr><td>deepseek-coder</td><td>64k</td><td>8k</td><td>支持</td><td>对话,代码</td><td>深度求索_deepseek</td><td>236B 参数量,64K 上下文（API）,中文综合能力（AlignBench）位列开源榜首,与 GPT-4-Turbo，文心 4.0 等闭源模型在评测中处于同一梯队</td></tr><tr><td>deepseek-reasoner</td><td>64k</td><td>8k</td><td>支持</td><td>对话,推理</td><td>深度求索_deepseek</td><td>DeepSeek-Reasoner（DeepSeek-R1）是DeepSeek最新推出的推理模型，旨在通过强化学习训练来提升推理能力。该模型的推理过程包含大量的反思和验证，能够处理复杂的逻辑推理任务，其思维链长度可达数万字。DeepSeek-R1在数学、代码及其他复杂问题的解答上表现出色，已被广泛应用于多种场景，显示出其强大的推理能力和灵活性。与其他模型相比，DeepSeek-R1在推理性能上接近顶尖的闭源模型，展现了开源模型在推理领域的潜力和竞争力。</td></tr><tr><td>hunyuan-code</td><td>4k</td><td>4k</td><td>不支持</td><td>对话,代码</td><td>腾讯_hunyuan</td><td>混元最新代码生成模型，经过 200B 高质量代码数据增训基座模型，迭代半年高质量 SFT 数据训练，上下文长窗口长度增大到 8K，五大语言代码生成自动评测指标上位居前列；五大语言10项考量各方面综合代码任务人工高质量评测上，性能处于第一梯队。</td></tr><tr><td>hunyuan-functioncall</td><td>28k</td><td>4k</td><td>支持</td><td>对话</td><td>腾讯_hunyuan</td><td>混元最新 MOE 架构 FunctionCall 模型，经过高质量的 FunctionCall 数据训练，上下文窗口达 32K，在多个维度的评测指标上处于领先。</td></tr><tr><td>hunyuan-large</td><td>28k</td><td>4k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>Hunyuan-large 模型总参数量约 389B，激活参数量约 52B，是当前业界参数规模最大、效果最好的 Transformer 架构的开源 MoE 模型。</td></tr><tr><td>hunyuan-large-longcontext</td><td>128k</td><td>6k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>擅长处理长文任务如文档摘要和文档问答等，同时也具备处理通用文本生成任务的能力。在长文本的分析和生成上表现优异，能有效应对复杂和详尽的长文内容处理需求。</td></tr><tr><td>hunyuan-lite</td><td>250k</td><td>6k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>升级为 MOE 结构，上下文窗口为 256k ，在 NLP，代码，数学，行业等多项评测集上领先众多开源模型。</td></tr><tr><td>hunyuan-pro</td><td>28k</td><td>4k</td><td>支持</td><td>对话</td><td>腾讯_hunyuan</td><td>万亿级参数规模 MOE-32K 长文模型。在各种 benchmark 上达到绝对领先的水平，复杂指令和推理，具备复杂数学能力，支持 functioncall，在多语言翻译、金融法律医疗等领域应用重点优化。</td></tr><tr><td>hunyuan-role</td><td>28k</td><td>4k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>混元最新版角色扮演模型，混元官方精调训练推出的角色扮演模型，基于混元模型结合角色扮演场景数据集进行增训，在角色扮演场景具有更好的基础效果。</td></tr><tr><td>hunyuan-standard</td><td>30k</td><td>2k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。<br>MOE-32K 性价比相对更高，在平衡效果、价格的同时，可对实现对长文本输入的处理。</td></tr><tr><td>hunyuan-standard-256K</td><td>250k</td><td>6k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>采用更优的路由策略，同时缓解了负载均衡和专家趋同的问题。长文方面，大海捞针指标达到99.9%。 MOE-256K 在长度和效果上进一步突破，极大的扩展了可输入长度。</td></tr><tr><td>hunyuan-translation-lite</td><td>4k</td><td>4k</td><td>不支持</td><td>对话</td><td>腾讯_hunyuan</td><td>混元翻译模型支持自然语言对话式翻译；支持中文和英语、日语、法语、葡萄牙语、西班牙语、土耳其语、俄语、阿拉伯语、韩语、意大利语、德语、越南语、马来语、印尼语15种语言互译。</td></tr><tr><td>hunyuan-turbo</td><td>28k</td><td>4k</td><td>支持</td><td>对话</td><td>腾讯_hunyuan</td><td>Hunyuan-turbo 模型默认版本，采用全新的混合专家模型（MoE）结构，相比hunyuan-pro推理效率更快，效果表现更强。</td></tr><tr><td>hunyuan-turbo-latest</td><td>28k</td><td>4k</td><td>支持</td><td>对话</td><td>腾讯_hunyuan</td><td>Hunyuan-turbo 模型动态更新版本，是混元模型系列效果最好的版本，与C端（腾讯元宝）保持一致。</td></tr><tr><td>hunyuan-turbo-vision</td><td>8k</td><td>2k</td><td>支持</td><td>识图,对话</td><td>腾讯_hunyuan</td><td>混元新一代视觉语言旗舰大模型，采用全新的混合专家模型（MoE）结构，在图文理解相关的基础识别、内容创作、知识问答、分析推理等能力上相比前一代模型全面提升。最大输入6k,最大输出2k</td></tr><tr><td>hunyuan-vision</td><td>8k</td><td>2k</td><td>支持</td><td>对话,识图</td><td>腾讯_hunyuan</td><td>混元最新多模态模型，支持图片+文本输入生成文本内容。<br>图片基础识别：对图片中主体、元素、场景等进行识别<br>图片内容创作：对图片进行概述、创作广告文案、朋友圈、诗词等<br>图片多轮对话：输出单张图片进行多轮交互问答<br>图片分析推理：对图片中逻辑关系、数学题、代码、图表进行统计分析<br>图片知识问答：对图片包含的知识点进行问答，例如历史事件、电影海报<br>图片 OCR：对自然生活场景、非自然场景的图片识别文字。</td></tr><tr><td>SparkDesk-Lite</td><td>4k</td><td>-</td><td>不支持</td><td>对话</td><td>星火_SparkDesk</td><td>支持在线联网搜索功能，响应快速、便捷，适用于低算力推理与模型精调等定制化场景</td></tr><tr><td>SparkDesk-Max</td><td>128k</td><td>-</td><td>支持</td><td>对话</td><td>星火_SparkDesk</td><td>基于最新版星火大模型引擎4.0 Turbo 量化而来，支持联网搜索、天气、日期等多个内置插件，核心能力全面升级，各场景应用效果普遍提升，支持System角色人设与FunctionCall函数调用</td></tr><tr><td>SparkDesk-Max-32k</td><td>32k</td><td>-</td><td>支持</td><td>对话</td><td>星火_SparkDesk</td><td>推理更强：更强的上下文理解和逻辑推理能力，输入更长：支持32K tokens的文本输入，适用于长文档阅读、私有知识问答等场景</td></tr><tr><td>SparkDesk-Pro</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>星火_SparkDesk</td><td>数学、代码、医疗、教育等场景专项优化，支持联网搜索、天气、日期等多个内置插件，覆盖大部分知识问答、语言理解、文本创作等多个场景</td></tr><tr><td>SparkDesk-Pro-128K</td><td>128k</td><td>-</td><td>不支持</td><td>对话</td><td>星火_SparkDesk</td><td>专业级大语言模型，具有百亿级参数，在医疗、教育和代码等场景进行了专项优化，搜索场景延时更低。适用于文本、智能问答等对性能和响应速度有更高要求的业务场景。</td></tr><tr><td>moonshot-v1-128k</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>月之暗面_moonshot</td><td>长度为 8k 的模型，适用于生成短文本。</td></tr><tr><td>moonshot-v1-32k</td><td>32k</td><td>4k</td><td>支持</td><td>对话</td><td>月之暗面_moonshot</td><td>长度为 32k 的模型，适用于生成长文本。</td></tr><tr><td>moonshot-v1-8k</td><td>8k</td><td>4k</td><td>支持</td><td>对话</td><td>月之暗面_moonshot</td><td>长度为 128k 的模型，适用于生成超长文本。</td></tr><tr><td>codegeex-4</td><td>128k</td><td>4k</td><td>不支持</td><td>对话,代码</td><td>智谱_codegeex</td><td>智谱的代码模型：适用于代码自动补全任务</td></tr><tr><td>charglm-3</td><td>4k</td><td>2k</td><td>不支持</td><td>对话</td><td>智谱_glm</td><td>拟人模型</td></tr><tr><td>emohaa</td><td>8k</td><td>4k</td><td>不支持</td><td>对话</td><td>智谱_glm</td><td>心理模型：具备专业咨询能力，帮助用户理解情感并应对情绪问题 </td></tr><tr><td>glm-3-turbo</td><td>128k</td><td>4k</td><td>不支持</td><td>对话</td><td>智谱_glm</td><td>即将弃用(2025年6月30日)</td></tr><tr><td>glm-4</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>旧版旗舰：发布于2024年1月16日，目前已被GLM-4-0520取代</td></tr><tr><td>glm-4-0520</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>高智能模型：适用于处理高度复杂和多样化的任务</td></tr><tr><td>glm-4-air</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>高性价比：推理能力和价格之间最平衡的模型</td></tr><tr><td>glm-4-airx</td><td>8k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>极速推理：具有超快的推理速度和强大的推理效果</td></tr><tr><td>glm-4-flash</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>高速低价：超快推理速度</td></tr><tr><td>glm-4-flashx</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>高速低价：Flash增强版本，超快推理速度</td></tr><tr><td>glm-4-long</td><td>1m</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>超长输入：专为处理超长文本和记忆型任务设计</td></tr><tr><td>glm-4-plus</td><td>128k</td><td>4k</td><td>支持</td><td>对话</td><td>智谱_glm</td><td>高智能旗舰: 性能全面提升，长文本和复杂任务能力显著增强</td></tr><tr><td>glm-4v</td><td>2k</td><td>-</td><td>不支持</td><td>对话,识图</td><td>智谱_glm</td><td> 图像理解：具备图像理解能力和推理能力</td></tr><tr><td>glm-4v-flash</td><td>2k</td><td>1k</td><td>不支持</td><td>对话,识图</td><td>智谱_glm</td><td>免费模型：具备强大的图片理解能力</td></tr><tr><td>glm-4v-plus</td><td>8k</td><td>-</td><td>不支持</td><td>对话,识图</td><td>智谱_glm</td><td>视频和图像理解：具备视频内容和多图片的理解能力<br>说明:图片理解预计增加 2000 tokens消耗</td></tr></tbody></table>
