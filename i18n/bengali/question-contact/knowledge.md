---
icon: book-bookmark
---

{% hint style="warning" %}
এই নথিটি এআই দ্বারা চীনা থেকে অনুবাদ করা হয়েছে এবং এখনও পর্যালোচনা করা হয়নি।
{% endhint %}

# জ্ঞান বিজ্ঞান

## টোকেন (Tokens) কি?

টোকেনস হল AI মডেল টেক্সট প্রক্রিয়াকরণের মৌলিক ইউনিট। একে মডেলের "চিন্তা করার" ক্ষুদ্রতম একক হিসেবে বোঝা যায়। এটি আমাদের বোঝা অক্ষর বা শব্দের সাথে পুরোপুরি সমতুল্য নয়, বরং মডেলের নিজস্ব এক বিশেষ ধরনের টেক্সট বিভাজন পদ্ধতি।

#### 1. চীনা টেক্সট বিভাজন

* একটি চীনা অক্ষর সাধারণত ১-২টি টোকেনে এনকোড হয়
* উদাহরণ: `"你好"` ≈ ২-৪ টোকেন

#### 2. ইংরেজি টেক্সট বিভাজন

* সাধারণ শব্দগুলো সাধারণত ১টি টোকেন
* দীর্ঘ বা অস্বাভাবিক শব্দগুলি একাধিক টোকেনে বিভক্ত হয়
* উদাহরণ:
  * `"hello"` = ১ টোকেন
  * `"indescribable"` = ৪ টোকেন

#### 3. বিশেষ ক্যারেক্টার

* স্পেস, যতি-চিহ্ন ইত্যাদিও টোকেন ব্যবহার করে
* নিউলাইন সাধারণত ১টি টোকেন

{% hint style="info" %}
বিভিন্ন সার্ভিস প্রোভাইডারের টোকেনাইজার (Tokenizer) আলাদা হয়ে থাকে, এমনকি একই প্রোভাইডারের বিভিন্ন মডেলের টোকেনাইজারেও পার্থক্য থাকে। এই জ্ঞানটি শুধুমাত্র টোকেন ধারণাটি পরিষ্কার করার জন্য।
{% endhint %}

***

## টোকেনাইজার (Tokenizer) কি?

টোকেনাইজার (Tokenizer) হল AI মডেলের টেক্সটকে টোকেনে রূপান্তরের সরঞ্জাম। এটি নির্ধারণ করে কিভাবে ইনপুট টেক্সটকে মডেলের বোঝার উপযোগী ক্ষুদ্রতম এককে বিভক্ত করা হয়।

### কেন বিভিন্ন মডেলের টোকেনাইজার আলাদা?

#### 1. ট্রেনিং ডেটা আলাদা

* ভিন্ন ভিন্ন কর্পাসের কারণে অপ্টিমাইজেশন দিক পরিবর্তিত
* বহুভাষা সাপোর্টের স্তরে পার্থক্য
* বিশেষায়িত ক্ষেত্রের জন্য অপ্টিমাইজেশন (ঔষধ, আইন ইত্যাদি)

#### 2. বিভাজন অ্যালগোরিদম আলাদা

* BPE (Byte Pair Encoding) - OpenAI GPT সিরিজ
* WordPiece - Google BERT
* SentencePiece - বহুভাষিক পরিস্থিতির জন্য উপযুক্ত

#### 3. অপ্টিমাইজেশন লক্ষ্য আলাদা

* কেউ কম্প্রেশন ইফিসিয়েন্সিতে ফোকাস করে
* কেউ সিম্যান্টিক সংরক্ষণে ফোকাস করে
* কেউ প্রসেসিং স্পিডে ফোকাস করে

### ব্যবহারিক প্রভাব

একই টেক্সট বিভিন্ন মডেলে ভিন্ন টোকেন সংখ্যা দেখাতে পারে:

```
ইনপুট: "Hello, world!"
GPT-3: 4 টোকেন
BERT: 3 টোকেন
Claude: 3 টোকেন
```

***



## এম্বেডিং মডেল (Embedding Model) কি?

**মৌলিক ধারণা:** এম্বেডিং মডেল হল একটি প্রযুক্তি যা উচ্চ-ডাইমেনশনাল ডিসক্রিট ডেটা (টেক্সট, ইমেজ ইত্যাদি) নিম্ন-ডাইমেনশনাল কন্টিনিউয়াস ভেক্টরে রূপান্তর করে। এই রূপান্তরের ফলে মেশিন জটিল ডেটা আরও ভালভাবে বুঝতে ও প্রসেস করতে পারে। এটা এমন - জটিল একটা পাজলকে একটি সহজ স্থানাঙ্ক বিন্দুতে সরলীকরণ, যেখানে বিন্দুটি পাজলের মূল বৈশিষ্ট্যগুলো ধরে রাখে। বৃহত্তর মডেল ইকোসিস্টেমে, এটি একজন "দোভাষী" হিসেবে কাজ করে, মানুষের বোধগম্য তথ্যকে AI-এর হিসাবযোগ্য ডিজিটাল ফর্মে রূপান্তর করে।

**কর্মপদ্ধতি:** প্রাকৃতিক ভাষা প্রসেসিং উদাহরণ হিসাবে, এম্বেডিং মডেল শব্দগুলিকে ভেক্টর স্পেসের নির্দিষ্ট অবস্থানে ম্যাপ করতে পারে। এই স্পেসে, শব্দার্থগতভাবে সম্পর্কিত শব্দগুলি স্বয়ংক্রিয়ভাবে একত্রিত হয়। যেমন:
* "রাজা" এবং "রাণী" এর ভেক্টর কাছাকাছি হবে
* "বিড়াল" এবং "কুকুর" এর মত পোষা প্রাণীর শব্দও কাছাকাছি দূরত্বে থাকবে
* অপরদিকে "গাড়ি" এবং "রুটি" এর মত সম্পর্কহীন শব্দ বেশি দূরত্বে থাকবে

**প্রধান ব্যবহারিক ক্ষেত্র:**
* টেক্সট অ্যানালাইসিস: ডকুমেন্ট শ্রেণিবিভাগ, সেন্টিমেন্ট অ্যানালাইসিস
* রিকমেন্ডেশন সিস্টেম: ব্যক্তিগতকৃত কন্টেন্ট সুপারিশ
* ইমেজ প্রসেসিং: সদৃশ ইমেজ সার্চ
* সার্চ ইঞ্জিন: শব্দার্থিক খোঁজা অপ্টিমাইজেশন

**মূল সুবিধা:**
1. ডাইমেনশন রিডাকশন: জটিল ডেটাকে প্রসেস করার উপযোগী ভেক্টর ফর্মে সরলীকরণ
2. সিম্যান্টিক সংরক্ষণ: মূল ডেটার মূল সিম্যান্টিক তথ্য ধরে রাখে
3. ক্যালকুলেশন ইফিসিয়েন্সি: মেশিন লার্নিং মডেলের ট্রেনিং ও ইনফারেন্সের দক্ষতা উল্লেখযোগ্যভাবে বাড়ায়

**প্রযুক্তিগত মূল্য:** এম্বেডিং মডেল আধুনিক AI সিস্টেমের ভিত্তি উপাদান, যা মেশিন লার্নিং টাস্কের জন্য উচ্চমানের ডেটা রিপ্রেজেন্টেশন সরবরাহ করে। এটি প্রাকৃতিক ভাষা প্রসেসিং, কম্পিউটার ভিশন ইত্যাদি ক্ষেত্রে অগ্রগতির মূল চালিকাশক্তি।

***



## জ্ঞান পুনরুদ্ধারে এম্বেডিং মডেলের কর্মপদ্ধতি

**মৌলিক কাজের ধাপ:**
1. **জ্ঞানভান্ডার প্রিপ্রসেসিং ধাপ**
   * ডকুমেন্টকে উপযুক্ত আকারের অংশে (chunk) বিভক্ত করা
   * প্রতিটি অংশকে এম্বেডিং মডেল ব্যবহার করে ভেক্টরে রূপান্তর
   * ভেক্টর ও মূল টেক্সট ভেক্টর ডেটাবেজে সংরক্ষণ

2. **কোয়েরি প্রসেসিং ধাপ**
   * ইউজারের প্রশ্নকে ভেক্টরে রূপান্তর
   * ভেক্টর ডেটাবেজে সদৃশ কন্টেন্ট খোঁজা
   * খুঁজে পাওয়া রিলেভ্যান্ট কন্টেন্টকে LLM-এর জন্য কনটেক্সট হিসেবে প্রদান

***

## **MCP (Model Context Protocol) কি?**

MCP হল একটি ওপেন-সোর্স প্রোটোকল, যার লক্ষ্য স্ট্যান্ডার্ড উপায়ে বড় ভাষা মডেলকে (LLM) কনটেক্সট তথ্য সরবরাহ করা।

* **উপমাহীন বোঝা:** MCP-কে AI ফিল্ডের একটি "USB ড্রাইভ" এর সাথে তুলনা করা যায়। আমরা জানি USB ড্রাইভে নানা ফাইল রাখা যায়, যেটি কম্পিউটারে সংযুক্ত করলেই ব্যবহার করা যায়। একইভাবে, MCP সার্ভারে আপনি "প্লাগইন" হিসাবে নানা ধরনের কনটেক্সট সরবরাহকারী সংযুক্ত করতে পারেন। LLM প্রয়োজনের সময় MCP সার্ভার থেকে সেই প্লাগইন রিকোয়েস্ট করতে পারে, যার মাধ্যমে আরও সমৃদ্ধ কনটেক্সট পায় এবং নিজের ক্ষমতা বাড়ায়।
* **ফাংশন টুল-এর সাথে তুলনা:** প্রচলিত ফাংশন টুলও (Function Tool) LLM-কে বাহ্যিক ফাংশনালিটি দিতে পারে, কিন্তু MCP তার চেয়ে উচ্চতর একটি অ্যাবস্ট্রাকশন। ফাংশন টুল মূলত নির্দিষ্ট টাস্কের জন্য ব্যবহৃত হয়, অন্যদিকে MCP একটি ইউনিভার্সাল, মড্যুলার কনটেক্সট আনা পদ্ধতি দেয়।

### **MCP-এর মূল সুবিধাসমূহ**
1. **স্ট্যান্ডার্ডাইজেশন:** MCP ইউনিফায়েড ইন্টারফেস ও ডেটা ফরম্যাট দেয়, যার ফলে বিভিন্ন LLM ও কনটেক্সট প্রদানকারী নির্বিঘ্নে কাজ করতে পারে।
2. **মড্যুলারিটি:** MCP ডেভেলপারদের কনটেক্সট তথ্যগুলো স্বতন্ত্র মড্যুলে (প্লাগইন) বিভক্ত করার সুযোগ দেয়, যার ফলে ম্যানেজ ও রিইউজ করা সহজ হয়।
3. **নমনীয়তা:** LLM নিজের প্রয়োজন অনুযায়ী ডায়নামিকভাবে কনটেক্সট প্লাগইন নির্বাচন করতে পারে, যার ফলে আরও স্মার্ট ও পার্সোনালাইজড ইন্টার্যাকশন সম্ভব।
4. **এক্সটেনসিবিলিটি:** MCP-এর ডিজাইন ভবিষ্যতে আরও ধরনের কনটেক্সট প্লাগইন সংযোজনের সুযোগ রাখে, যা LLM-এর ক্ষমতা বাড়ানোর অসীম সম্ভাবনা তৈরি করে।

***