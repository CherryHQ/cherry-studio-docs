
{% hint style="warning" %}
এই নথিটি এআই দ্বারা চীনা থেকে অনুবাদ করা হয়েছে এবং এখনও পর্যালোচনা করা হয়নি।
{% endhint %}

# কাস্টম প্রোভাইডার

Cherry Studio কেবল প্রধান AI মডেল সার্ভিসগুলোর সাথে ইন্টিগ্রেট করে না, বরং আপনাকে শক্তিশালী কাস্টমাইজেশন ক্ষমতাও প্রদান করে। **কাস্টম AI প্রোভাইডার** ফিচারের মাধ্যমে, আপনি যেকোন প্রয়োজনীয় AI মডেল সহজেই সংযুক্ত করতে পারবেন।

## কাস্টম AI প্রোভাইডারের প্রয়োজনীয়তা কেন?

* **নমনীয়তা:** প্রিডিফাইন্ড প্রোভাইডার তালিকার সীমাবদ্ধতা থেকে মুক্ত থাকুন, আপনার প্রয়োজন অনুযায়ী সেরা AI মডেল বেছে নিন।
* **বৈচিত্র্য:** বিভিন্ন প্ল্যাটফর্মের AI মডেল পরীক্ষা করুন এবং তাদের স্বতন্ত্র সুবিধাগুলো আবিষ্কার করুন।
* **নিয়ন্ত্রণযোগ্যতা:** আপনার API কী এবং অ্যাক্সেস ঠিকানা সরাসরি পরিচালনা করুন, নিরাপত্তা এবং গোপনীয়তা নিশ্চিত করুন।
* **কাস্টমাইজেশান:** প্রাইভেটলি ডেপ্লয় করা মডেল সংযুক্ত করুন, নির্দিষ্ট ব্যবসায়িক চাহিদা পূরণ করুন।

## কিভাবে কাস্টম AI প্রোভাইডার যোগ করবেন?

Cherry Studio-এ আপনার কাস্টম AI প্রোভাইডার যোগ করতে মাত্র কয়েকটি সহজ ধাপ অনুসরণ করুন:

<figure><img src="../../.gitbook/assets/image (2) (5).png" alt=""><figcaption></figcaption></figure>

1. **সেটিংস খুলুন:** Cherry Studio ইন্টারফেসের বাম নেভিগেশন বার থেকে "সেটিংস" (গিয়ার আইকন) ক্লিক করুন।
2. **মডেল সার্ভিসে যান:** সেটিংস পেজে "মডেল সার্ভিস" ট্যাবে যান।
3. **প্রোভাইডার যোগ করুন:** "মডেল সার্ভিস" পেজে প্রোভাইডারদের তালিকা দেখবেন। নিচের "+ যোগ করুন" বাটনে ক্লিক করে "প্রোভাইডার যোগ করুন" পপআপ খুলুন।
4. **তথ্য পূরণ করুন:** পপআপে নিম্নলিখিত তথ্য পূরণ করুন:
   * **প্রোভাইডারের নাম:** আপনার কাস্টম প্রোভাইডারের জন্য একটি সহজে চেনা যায় নাম দিন (যেমন: MyCustomOpenAI)।
   * **প্রোভাইডারের ধরণ:** ড্রপডাউন তালিকা থেকে আপনার প্রোভাইডারের ধরণ নির্বাচন করুন। বর্তমানে সমর্থিত:
     * OpenAI
     * Gemini
     * Anthropic
     * Azure OpenAI
5. **কনফিগারেশন সেভ করুন:** তথ্য পূরণ শেষে "যোগ করুন" বাটনে ক্লিক করে কনফিগারেশন সেভ করুন।

## কাস্টম AI প্রোভাইডার কনফিগার করা

<figure><img src="../../.gitbook/assets/image (3) (5) (1).png" alt=""><figcaption></figcaption></figure>

যোগ করার পর, আপনি তালিকায় নতুন যোগ করা প্রোভাইডার খুঁজে বিস্তারিত কনফিগারেশন করুন:

1. **এনাবল স্ট্যাটাস:** কাস্টম প্রোভাইডার তালিকার ডানপাশে একটি এনাবল সুইচ আছে, এটি চালু করলে সার্ভিস সক্রিয় হয়।
2. **API কী:**
   * আপনার AI প্রোভাইডারের দেওয়া API কী (API Key) লিখুন।
   * ডানপাশের "পরীক্ষা" বাটনে ক্লিক করে কীটির বৈধতা যাচাই করুন।
3. **API ঠিকানা:**
   * AI সার্ভিসের API অ্যাক্সেস ঠিকানা (Base URL) লিখুন।
   * সঠিক API ঠিকানা পেতে অবশ্যই আপনার AI প্রোভাইডারের অফিসিয়াল ডকুমেন্টেশন দেখুন।
4. **মডেল ম্যানেজমেন্ট:**
   * "+ যোগ করুন" বাটনে ক্লিক করে এই প্রোভাইডারের অধীনে আপনি ব্যবহার করতে চাইছেন এমন মডেল আইডি ম্যানুয়ালি যোগ করুন। যেমন `gpt-3.5-turbo`, `gemini-pro` ইত্যাদি।

    <figure><img src="../../.gitbook/assets/image (4) (5).png" alt=""><figcaption></figcaption></figure>
   * নির্দিষ্ট মডেলের নাম নিশ্চিত না হলে, আপনার AI প্রোভাইডারের অফিসিয়াল ডকুমেন্টেশন দেখুন।
   * "ম্যানেজ" বাটনে ক্লিক করে যোগ করা মডেলগুলো সম্পাদনা বা মুছে ফেলতে পারেন।

## ব্যবহার শুরু করুন

উপরের কনফিগারেশনগুলি সম্পন্ন করার পর, আপনি Cherry Studio-এর চ্যাট ইন্টারফেসে আপনার কাস্টম AI প্রোভাইডার এবং মডেল নির্বাচন করে AI-এর সাথে চ্যাট শুরু করতে পারবেন!

## কাস্টম AI প্রোভাইডার হিসেবে vLLM ব্যবহার করা

vLLM হল Ollama-এর মতো একটি দ্রুত এবং সহজে ব্যবহারযোগ্য LLM ইনফারেন্স লাইব্রেরি। কিভাবে vLLM কে Cherry Studio-এর সাথে সংযুক্ত করবেন তার ধাপগুলো:

1. **vLLM ইনস্টল করুন:** vLLM অফিসিয়াল ডকুমেন্টেশন ([https://docs.vllm.ai/en/latest/getting_started/quickstart.html](https://docs.vllm.ai/en/latest/getting_started/quickstart.html)) অনুযায়ী ইনস্টল করুন।

    ```sh
    pip install vllm # pip ব্যবহার করলে
    uv pip install vllm # uv ব্যবহার করলে
    ```
2. **vLLM সার্ভিস চালু করুন:** vLLM-এর প্রদান করা OpenAI-সামঞ্জস্যপূর্ণ ইন্টারফেস ব্যবহার করে সার্ভিস চালু করুন। প্রধান দুটি উপায় আছে:

    * `vllm.entrypoints.openai.api_server` ব্যবহার করে চালু করুন

    ```sh
    python -m vllm.entrypoints.openai.api_server --model gpt2
    ```

    * `uvicorn` ব্যবহার করে চালু করুন

    ```sh
    vllm --model gpt2 --served-model-name gpt2
    ```

সার্ভিসটি সফলভাবে চালু হয়েছে এবং ডিফল্ট পোর্ট `8000`-এ শুনছে কিনা নিশ্চিত করুন। আপনি চাইলে `--port` প্যারামিটার ব্যবহার করে vLLM সার্ভিসের পোর্ট নম্বর স্পেসিফাই করতে পারেন।

3. **Cherry Studio-এ vLLM প্রোভাইডার যোগ করুন:**
   * আগের বর্ণিত ধাপ অনুসরণ করে Cherry Studio-এ নতুন কাস্টম AI প্রোভাইডার যোগ করুন।
   * **প্রোভাইডারের নাম:** `vLLM`
   * **প্রোভাইডারের ধরণ:** `OpenAI` নির্বাচন করুন।
4. **vLLM প্রোভাইডার কনফিগার করুন:**
   * **API কী:** vLLM-এ API কী প্রয়োজন হয় না, তাই এই ফিল্ড খালি রাখুন বা যেকোনো কনটেন্ট দিন।
   * **API ঠিকানা:** vLLM সার্ভিসের API ঠিকানা দিন। ডিফল্ট ঠিকানা: `http://localhost:8000/` (বিভিন্ন পোর্ট ব্যবহার করলে সেইমত পরিবর্তন করুন)।
   * **মডেল ম্যানেজমেন্ট:** vLLM-এ লোড করা মডেলের নাম যোগ করুন। উপরে `python -m vllm.entrypoints.openai.api_server --model gpt2` চালানোর উদাহরণে, এখানে `gpt2` লিখতে হবে।
5. **কথোপকথন শুরু করুন:** এখন আপনি Cherry Studio-এ vLLM প্রোভাইডার এবং `gpt2` মডেল নির্বাচন করে vLLM-চালিত LLM-এর সাথে চ্যাট শুরু করতে পারেন!

## টিপস এবং ট্রিকস

* **ডকুমেন্টেশন মনোযোগ সহকারে পড়ুন:** কাস্টম প্রোভাইডার যোগ করার আগে, অবশ্যই আপনার AI প্রোভাইডারের অফিসিয়াল ডকুমেন্টেশন মনোযোগ সহকারে পড়ুন, API কী, অ্যাক্সেস ঠিকানা, মডেল নাম ইত্যাদি জরুরি তথ্য জেনে নিন।
* **API কী পরীক্ষা করুন:** "পরীক্ষা" বাটন ব্যবহার করে API কী-এর বৈধতা দ্রুতই যাচাই করে নিন, যেন ভুল কী এর কারণে ব্যবহার না করতে পারার সমস্যা না হয়।
* **API ঠিকানার দিকে খেয়াল রাখুন:** বিভিন্ন AI প্রোভাইডার এবং মডেলের API ঠিকানা আলাদা হতে পারে, তাই অবশ্যই সঠিক ঠিকানা লিখুন।
* **প্রয়োজনমত মডেল যোগ করুন:** শুধুমাত্র আপনি ব্যবহার করবেন এমন মডেল যোগ করুন, অপ্রয়োজনীয় মডেল যোগ এড়িয়ে চলুন।