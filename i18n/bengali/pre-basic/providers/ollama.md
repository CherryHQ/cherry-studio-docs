
{% hint style="warning" %}
এই নথিটি এআই দ্বারা চীনা থেকে অনুবাদ করা হয়েছে এবং এখনও পর্যালোচনা করা হয়নি।
{% endhint %}

# Ollama

Ollama হলো একটি উৎকৃষ্ট ওপেন সোর্স টুল যা আপনাকে স্থানীয়ভাবে বিভিন্ন বৃহৎ ভাষা মডেল (LLMs) চালনা ও পরিচালনা করতে সক্ষম করে। Cherry Studio এখন Ollama ইন্টিগ্রেশন সমর্থন করে, ফলে আপনি পরিচিত ইন্টারফেসে সরাসরি স্থানীয়ভাবে ডেপ্লয় করা LLM এর সাথে যোগাযোগ করতে পারবেন, ক্লাউড পরিষেবার উপর নির্ভরশীল না হয়েই!

## Ollama কী?

Ollama হলো এমন একটি সরঞ্জাম যা বৃহৎ ভাষা মডেল (LLM) ডেপ্লয়মেন্ট ও ব্যবহার সহজ করে। এটির বৈশিষ্ট্যগুলো হলো:

* **স্থানীয়ভাবে চালনা:** মডেল সম্পূর্ণরূপে আপনার স্থানীয় কম্পিউটারে চলে, ইন্টারনেট সংযোগের প্রয়োজন হয় না, আপনার গোপনীয়তা ও ডেটা নিরাপত্তা রক্ষা করে।
* **সহজ ব্যবহার:** সরল কমান্ড লাইন নির্দেশের মাধ্যমে বিভিন্ন LLM ডাউনলোড, চালনা ও পরিচালনা করা যায়।
* **সমৃদ্ধ মডেল সমর্থন:** Llama 2, Deepseek, Mistral, Gemma সহ বহু জনপ্রিয় ওপেন সোর্স মডেল সমর্থন করে।
* **ক্রস-প্ল্যাটফর্ম:** macOS, Windows এবং Linux সিস্টেম সমর্থন করে।
* **ওপেন API:** OpenAI-সামঞ্জস্যপূর্ণ ইন্টারফেস সমর্থন করে, অন্যান্য সরঞ্জামের সাথে ইন্টিগ্রেশন করা যায়।

## Cherry Studio-তে Ollama ব্যবহারের সুবিধা

* **ক্লাউড পরিষেবার প্রয়োজন নেই:** ক্লাউড API-র কোটা ও খরচের সীমাবদ্ধতা থেকে মুক্ত হয়ে স্থানীয় LLM এর শক্তিশালী ক্ষমতা উপভোগ করুন।
* **ডেটা গোপনীয়তা:** আপনার সমস্ত কথোপকথন ডেটা স্থানীয়ভাবে সংরক্ষিত থাকে, গোপনীয়তা ফাঁসের দুশ্চিন্তা করা লাগে না।
* **অফলাইন ব্যবহারযোগ্য:** নেটওয়ার্ক সংযোগ ছাড়াই LLM এর সাথে যোগাযোগ চালিয়ে যেতে পারেন।
* **কাস্টমাইজেশন:** আপনার প্রয়োজন অনুযায়ী সবচেয়ে উপযুক্ত LLM নির্বাচন ও কনফিগার করা যায়।

## Cherry Studio-তে Ollama কনফিগার করা

### **1. Ollama ইনস্টল এবং চালানো**

প্রথমে আপনার কম্পিউটারে Ollama ইনস্টল ও চালু করতে হবে:

*   **Ollama ডাউনলোড:** Ollama অফিসিয়াল ওয়েবসাইটে ([https://ollama.com/](https://ollama.com/)) যান এবং আপনার অপারেটিং সিস্টেম অনুযায়ী ইনস্টলার ডাউনলোড করুন।\
    Linux-এ, সরাসরি কমান্ড রান করে ollama ইনস্টল করুন:

    ```sh
    curl -fsSL https://ollama.com/install.sh | sh
    ```
* **Ollama ইনস্টল:** ইনস্টলার নির্দেশনা অনুসরণ করুন।
*   **মডেল ডাউনলোড:** টার্মিনাল খুলে `ollama run` কমান্ড ব্যবহার করে প্রয়োজনীয় মডেল ডাউনলোড করুন। উদাহরণস্বরূপ, Llama 2 মডেল ডাউনলোড করতে চালান:

    ```sh
    ollama run llama3.2
    ```

    Ollama স্বয়ংক্রিয়ভাবে মডেল ডাউনলোড ও চালাবে।
* **Ollama সচল রাখুন:** Cherry Studio-তে Ollama মডেল ব্যবহারের সময় Ollama চালু রাখুন।

### **2. Cherry Studio-তে Ollama সার্ভিস প্রোভাইডার যোগ**

এরপর, Cherry Studio-তে Ollama-কে কাস্টম AI সার্ভিস প্রোভাইডার হিসেবে যোগ করুন:

* **সেটিংস খুলুন:** Cherry Studio ইন্টারফেসে বাম প্যানেলের "সেটিংস" (গিয়ার আইকন) ক্লিক করুন।
* **মডেল সার্ভিসে যান:** সেটিংস পেজে "মডেল সার্ভিস" ট্যাবে যান।
* **প্রোভাইডার যোগ করুন:** লিস্টে থাকা Ollama ক্লিক করুন।

<figure><img src="../../.gitbook/assets/image (5) (3).png" alt=""><figcaption></figcaption></figure>

### **3. Ollama সার্ভিস প্রোভাইডার কনফিগার**

প্রোভাইডার লিস্টে Ollama খুঁজে বিস্তারিত কনফিগার করুন:

1. **এনাবল স্ট্যাটাস:**
   * ডানপাশের সুইচ চালু (ON) নিশ্চিত করুন।
2. **API কী:**
   * Ollama-তে সাধারণত API কী প্রয়োজন হয় না। ফিল্ডটি খালি রাখতে পারেন বা যেকোনো মান দিতে পারেন।
3. **API ঠিকানা:**
   * Ollama স্থানীয় API ঠিকানা দিন। সাধারণত ঠিকানা হবে:

     ```
     http://localhost:11434/
     ```

     পোর্ট পরিবর্তন করলে সেইমত ঠিকানা দিন।
4. **সংযোগ স্থায়িত্ব সময়:** (মিনিটে) নির্ধারণ করুন। নির্ধারিত সময়ে কোনও কথোপকথন না হলে Cherry Studio স্বয়ংক্রিয়ভাবে Ollama সংযোগ বিচ্ছিন্ন করবে।
5. **মডেল ব্যবস্থাপনা:**
   * "+ যোগ করুন" বোতামে ক্লিক করে Ollama-তে ডাউনলোড করা মডেল নাম ম্যানুয়ালি লিখুন।
   * উদাহরণ: `ollama run llama3.2` দিয়ে ডাউনলোড করা মডেলের নাম `llama3.2` দিন।
   * "ব্যবস্থাপনা" বোতামে ক্লিক করে যোগ করা মডেল এডিট বা মুছতে পারেন।

## ব্যবহার শুরু

কনফিগারেশন সম্পন্ন হলে, Cherry Studio-র চ্যাট ইন্টারফেসে Ollama সার্ভিস এবং আপনার মডেল নির্বাচন করে স্থানীয় LLM এর সাথে কথা বলা শুরু করুন!

## টিপস

* **প্রথমবার মডেল চালানোর সময়:** Ollama মডেল ফাইল ডাউনলোড করায় সময় লাগতে পারে, ধৈর্য ধরে অপেক্ষা করুন।
* **ডাউনলোডকৃত মডেল দেখা:** টার্মিনালে `ollama list` কমান্ড চালান।
* **হার্ডওয়্যার প্রয়োজন:** LLM চালনার জন্য পর্যাপ্ত কম্পিউটিং রিসোর্স (CPU, RAM, GPU) প্রয়োজন।
* **Ollama ডকুমেন্টেশন:** কনফিগারেশন পেজের `Ollama ডকুমেন্টেশন ও মডেল দেখুন` লিংকে ক্লিক করে Ollama অফিসিয়াল ডকুমেন্টেশনে যান।