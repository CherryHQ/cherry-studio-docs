# Classement LLM Arena (mise à jour en temps réel)


{% hint style="warning" %}
Ce document a été traducido del chino por IA y aún no ha sido revisado.
{% endhint %}




Ce classement est généré automatiquement à partir des données de Chatbot Arena (lmarena.ai).

> **Dernière mise à jour des données** : 2025-08-04 11:44:51 UTC / 2025-08-04 19:44:51 CST (Heure de Beijing)

{% hint style="info" %}
Cliquez sur le **nom du modèle** dans le classement pour accéder à ses informations détaillées ou à une page d'essai.
{% endhint %}

## Classement

| Rang(UB) | Rang(StyleCtrl) | Nom du modèle                                                                                                                         | Score | Intervalle de confiance | Votes    | Fournisseur                    | Licence                    | Date de fin de connaissances |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|        1 |               1 | [Gemini-2.5-Pro](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro)                                      | 1474 | +5/-4   | 19,209  | Google                 | Proprietary             | Aucune donnée     |
|        2 |               2 | [Gemini-2.5-Pro-Preview-05-06](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro-preview-05-06)          | 1446 | +4/-5   | 13,692  | Google                 | Proprietary             | Aucune donnée     |
|        2 |               3 | [Grok-4-0709](https://docs.x.ai/docs/models/grok-4-0709)                                                                    | 1443 | +7/-8   | 5,725   | xAI                    | Proprietary             | Aucune donnée     |
|        4 |               3 | [ChatGPT-4o-latest (2025-03-26)](https://x.com/OpenAI/status/1905331956856050135)                                           | 1429 | +4/-4   | 26,230  | OpenAI                 | Proprietary             | Aucune donnée     |
|        4 |               2 | [o3-2025-04-16](https://openai.com/index/introducing-o3-and-o4-mini/)                                                       | 1428 | +5/-3   | 25,442  | OpenAI                 | Proprietary             | Aucune donnée     |
|        4 |               7 | [DeepSeek-R1-0528](https://api-docs.deepseek.com/news/news250528)                                                           | 1424 | +5/-5   | 14,514  | DeepSeek               | MIT                     | Aucune donnée     |
|        4 |               9 | [Grok-3-Preview-02-24](https://x.ai/blog/grok-3)                                                                            | 1423 | +4/-3   | 27,643  | xAI                    | Proprietary             | Aucune donnée     |
|        6 |               7 | [Gemini-2.5-Flash](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-flash)                                  | 1417 | +4/-3   | 24,656  | Google                 | Proprietary             | Aucune donnée     |
|        8 |               3 | [GPT-4.5-Preview](https://openai.com/index/introducing-gpt-4-5/)                                                            | 1413 | +5/-5   | 15,271  | OpenAI                 | Proprietary             | Aucune donnée     |
|       10 |              11 | [Gemini-2.5-Flash-Preview-04-17](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-flash-preview-04-17)      | 1397 | +5/-4   | 18,607  | Google                 | Proprietary             | Aucune donnée     |
|       10 |              14 | [Qwen3-235B-A22B-no-thinking](https://qwenlm.github.io/blog/qwen3/)                                                         | 1392 | +5/-4   | 19,352  | Alibaba                | Apache 2.0              | Aucune donnée     |
|       11 |               7 | [GPT-4.1-2025-04-14](https://openai.com/index/gpt-4-1/)                                                                     | 1384 | +5/-4   | 20,325  | OpenAI                 | Proprietary             | Aucune donnée     |
|       12 |              14 | [DeepSeek-V3-0324](https://api-docs.deepseek.com/news/news250325)                                                           | 1382 | +5/-4   | 23,031  | DeepSeek               | MIT                     | Aucune donnée     |
|       12 |              22 | [Hunyuan-Turbos-20250416](https://cloud.tencent.com/document/product/1729/104753)                                           | 1378 | +5/-5   | 8,950   | Tencent                | Proprietary             | Aucune donnée     |
|       12 |               6 | [kimi-k2-0711-preview](https://moonshotai.github.io/Kimi-K2/)                                                               | 1374 | +12/-11 | 3,166   | Moonshot               | Modified MIT            | Aucune donnée     |
|       14 |              15 | [DeepSeek-R1](https://api-docs.deepseek.com/news/news250120)                                                                | 1373 | +3/-5   | 19,430  | DeepSeek               | MIT                     | Aucune donnée     |
|       14 |              21 | [Mistral Medium 3](https://mistral.ai/news/mistral-medium-3)                                                                | 1372 | +4/-3   | 23,574  | Mistral                | Proprietary             | Aucune donnée     |
|       14 |               7 | [Claude Opus 4 (thinking-16k)](https://www.anthropic.com/news/claude-4)                                                     | 1371 | +6/-5   | 13,582  | Anthropic              | Proprietary             | Aucune donnée     |
|       15 |               7 | [Claude Opus 4 (20250514)](https://www.anthropic.com/news/claude-4)                                                         | 1368 | +4/-3   | 21,663  | Anthropic              | Proprietary             | Aucune donnée     |
|       15 |              26 | [Qwen3-235B-A22B](https://qwenlm.github.io/blog/qwen3/)                                                                     | 1367 | +5/-4   | 16,482  | Alibaba                | Apache 2.0              | Aucune donnée     |
|       15 |              21 | [Minimax-M1](https://www.minimax.io/news/minimaxm1)                                                                         | 1364 | +6/-4   | 11,524  | MiniMax                | Apache 2.0              | Aucune donnée     |
|       17 |              14 | [o1-2024-12-17](https://openai.com/index/o1-and-new-tools-for-developers/)                                                  | 1365 | +3/-3   | 29,038  | OpenAI                 | Proprietary             | Aucune donnée     |
|       17 |              14 | [o4-mini-2025-04-16](https://openai.com/index/introducing-o3-and-o4-mini/)                                                  | 1363 | +5/-4   | 20,096  | OpenAI                 | Proprietary             | Aucune donnée     |
|       17 |              27 | [Qwen2.5-Max](https://qwenlm.github.io/blog/qwen2.5-max/)                                                                   | 1363 | +3/-3   | 32,937  | Alibaba                | Proprietary             | Aucune donnée     |
|       17 |              32 | [Grok-3-mini-high](https://docs.x.ai/docs/models)                                                                           | 1361 | +7/-6   | 6,020   | xAI                    | Proprietary             | Aucune donnée     |
|       18 |              31 | [Gemini-2.0-Flash-001](https://aistudio.google.com/app/prompts/new_chat?instructions=lmsys-1121&model=gemini-2.0-flash-001) | 1361 | +3/-2   | 37,796  | Google                 | Proprietary             | Aucune donnée     |
|       20 |              35 | [Grok-3-Mini-beta](https://docs.x.ai/docs/models)                                                                           | 1357 | +6/-5   | 12,522  | xAI                    | Proprietary             | Aucune donnée     |
|       21 |              29 | [Gemma-3-27B-it](http://aistudio.google.com/app/prompts/new_chat?model=gemma-3-27b-it)                                      | 1359 | +3/-3   | 28,099  | Google                 | Gemma                   | Aucune donnée     |
|       26 |              12 | [Claude Sonnet 4 (thinking-32k)](https://www.anthropic.com/news/claude-4)                                                   | 1351 | +7/-5   | 12,534  | Anthropic              | Proprietary             | Aucune donnée     |
|       28 |              22 | [o1-preview](https://platform.openai.com/docs/models/o1)                                                                    | 1350 | +4/-3   | 33,177  | OpenAI                 | Proprietary             | 2023/10  |
|       29 |              35 | [Qwen3-32B](https://qwenlm.github.io/blog/qwen3/)                                                                           | 1344 | +8/-8   | 4,074   | Alibaba                | Apache 2.0              | Aucune donnée     |
|       31 |              15 | [Claude Sonnet 4 (20250514)](https://www.anthropic.com/news/claude-4)                                                       | 1341 | +5/-4   | 17,996  | Anthropic              | Proprietary             | Aucune donnée     |
|       31 |              28 | [o3-mini-high](https://platform.openai.com/docs/guides/reasoning#reasoning-effort)                                          | 1340 | +5/-3   | 19,404  | OpenAI                 | Proprietary             | Aucune donnée     |
|       31 |              25 | [GPT-4.1-mini-2025-04-14](https://openai.com/index/gpt-4-1/)                                                                | 1337 | +4/-4   | 19,404  | OpenAI                 | Proprietary             | Aucune donnée     |
|       31 |              36 | [Gemma-3-12B-it](http://aistudio.google.com/app/prompts/new_chat?model=gemma-3-12b-it)                                      | 1337 | +8/-8   | 3,976   | Google                 | Gemma                   | Aucune donnée     |
|       31 |              35 | [Mistral-Small-2506](https://huggingface.co/mistralai/Mistral-Small-3.2-24B-Instruct-2506)                                  | 1335 | +9/-7   | 4,940   | Mistral                | Apache 2.0              | Aucune donnée     |
|       31 |              34 | [DeepSeek-V3](https://huggingface.co/deepseek-ai/DeepSeek-V3)                                                               | 1334 | +3/-4   | 22,841  | DeepSeek               | DeepSeek                | Aucune donnée     |
|       31 |              44 | [QwQ-32B](https://huggingface.co/Qwen/QwQ-32B)                                                                              | 1332 | +5/-3   | 19,232  | Alibaba                | Apache 2.0              | Aucune donnée     |
|       34 |              37 | [Qwen-Plus-0125](https://www.alibabacloud.com/help/en/model-studio/developer-reference/what-is-qwen-llm)                    | 1325 | +8/-7   | 6,055   | Alibaba                | Proprietary             | Aucune donnée     |
|       35 |              35 | [Gemini-2.0-Flash-Lite](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-lite)                           | 1328 | +3/-3   | 26,104  | Google                 | Proprietary             | Aucune donnée     |
|       35 |              36 | [Command A (03-2025)](https://cohere.com/blog/command-a)                                                                    | 1327 | +4/-4   | 26,540  | Cohere                 | CC-BY-NC-4.0            | Aucune donnée     |
|       35 |              42 | [GLM-4-Plus-0111](https://bigmodel.cn/dev/howuse/glm-4)                                                                     | 1326 | +7/-7   | 6,028   | Zhipu                  | Proprietary             | Aucune donnée     |
|       35 |              62 | [Amazon-Nova-Experimental-Chat-05-14](https://nova.amazon.com/faqs)                                                         | 1325 | +6/-5   | 9,753   | Amazon                 | Proprietary             | Aucune donnée     |
|       35 |              35 | [Llama-3.1-Nemotron-Ultra-253B-v1](https://huggingface.co/nvidia/Llama-3_1-Nemotron-Ultra-253B-v1)                          | 1321 | +11/-10 | 2,656   | Nvidia                 | Nvidia Open Model       | Aucune donnée     |
|       39 |              51 | [Qwen3-30B-A3B](https://qwenlm.github.io/blog/qwen3/)                                                                       | 1321 | +6/-5   | 16,285  | Alibaba                | Apache 2.0              | Aucune donnée     |
|       39 |              44 | [Step-2-16K-Exp](https://platform.stepfun.com/docs/llm/text)                                                                | 1320 | +8/-7   | 5,126   | StepFun                | Proprietary             | Aucune donnée     |
|       39 |              35 | [Hunyuan-TurboS-20250226](https://cloud.tencent.com/document/product/1729/104753)                                           | 1318 | +8/-10  | 2,452   | Tencent                | Proprietary             | Aucune donnée     |
|       40 |              46 | [Llama-3.3-Nemotron-Super-49B-v1](https://huggingface.co/nvidia/Llama-3_3-Nemotron-Super-49B-v1)                            | 1312 | +13/-9  | 2,371   | Nvidia                 | Nvidia                  | Aucune donnée     |
|       41 |              46 | [o1-mini](https://platform.openai.com/docs/models/o1)                                                                       | 1319 | +3/-3   | 54,951  | OpenAI                 | Proprietary             | 2023/10  |
|       41 |              37 | [o3-mini](https://openai.com/index/openai-o3-mini/)                                                                         | 1318 | +4/-3   | 38,885  | OpenAI                 | Proprietary             | Aucune donnée     |
|       42 |              36 | [Gemini-1.5-Pro-002](https://aistudio.google.com/app/prompts/new_chat?instructions=lmsys&model=gemini-1.5-pro-002)          | 1317 | +3/-2   | 58,645  | Google                 | Proprietary             | Aucune donnée     |
|       42 |              37 | [Hunyuan-Turbo-0110](https://cloud.tencent.com/document/product/1729/104753)                                                | 1311 | +8/-11  | 2,510   | Tencent                | Proprietary             | Aucune donnée     |
|       46 |              21 | [Claude 3.7 Sonnet (thinking-32k)](https://www.anthropic.com/news/claude-3-7-sonnet)                                        | 1312 | +4/-3   | 28,145  | Anthropic              | Proprietary             | Aucune donnée     |
|       49 |              64 | [Gemma-3n-e4b-it](http://aistudio.google.com/app/prompts/new_chat?model=gemma-3n-e4b-it)                                    | 1305 | +6/-6   | 9,350   | Google                 | Gemma                   | Aucune donnée     |
|       50 |              25 | [Claude 3.7 Sonnet](https://www.anthropic.com/news/claude-3-7-sonnet)                                                       | 1305 | +5/-4   | 32,904  | Anthropic              | Proprietary             | Aucune donnée     |
|       52 |              52 | [Grok-2-08-13](https://x.ai/blog/grok-2)                                                                                    | 1303 | +2/-2   | 67,084  | xAI                    | Proprietary             | 2024/3   |
|       52 |              56 | [Yi-Lightning](https://platform.lingyiwanwu.com/docs#%E6%A8%A1%E5%9E%8B%E4%B8%8E%E8%AE%A1%E8%B4%B9)                         | 1302 | +3/-3   | 28,968  | 01 AI                  | Proprietary             | Aucune donnée     |
|       53 |              40 | [GPT-4o-2024-05-13](https://openai.com/index/hello-gpt-4o/)                                                                 | 1300 | +1/-2   | 117,747 | OpenAI                 | Proprietary             | 2023/10  |
|       53 |              66 | [Qwen2.5-plus-1127](https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction)                                | 1297 | +5/-5   | 10,715  | Alibaba                | Proprietary             | Aucune donnée     |
|       54 |              76 | [Gemma-3-4B-it](http://aistudio.google.com/app/prompts/new_chat?model=gemma-3-4b-it)                                        | 1291 | +10/-7  | 4,321   | Google                 | Gemma                   | Aucune donnée     |
|       55 |              29 | [Claude 3.5 Sonnet (20241022)](https://www.anthropic.com/news/3-5-models-and-computer-use)                                  | 1298 | +2/-2   | 79,949  | Anthropic              | Proprietary             | 2024/4   |
|       55 |              60 | [Deepseek-v2.5-1210](https://huggingface.co/deepseek-ai/DeepSeek-V2.5-1210)                                                 | 1294 | +6/-6   | 7,243   | DeepSeek               | DeepSeek                | Aucune donnée     |
|       59 |              48 | [Llama-4-Maverick-17B-128E-Instruct](https://huggingface.co/meta-llama/Llama-4-Maverick-17B-128E-Instruct)                  | 1292 | +5/-4   | 20,106  | Meta                   | Llama 4                 | Aucune donnée     |
|       59 |              57 | [Hunyuan-Large-2025-02-10](https://cloud.tencent.com/document/product/1729/104753)                                          | 1287 | +10/-12 | 3,856   | Tencent                | Proprietary             | Aucune donnée     |
|       60 |              69 | [Athene-v2-Chat-72B](https://huggingface.co/Nexusflow/Athene-V2-Chat)                                                       | 1290 | +3/-3   | 26,074  | NexusFlow              | NexusFlow               | Aucune donnée     |
|       60 |              60 | [GPT-4.1-nano-2025-04-14](https://openai.com/index/gpt-4-1/)                                                                | 1287 | +8/-6   | 6,302   | OpenAI                 | Proprietary             | Aucune donnée     |
|       61 |              65 | [GLM-4-Plus](https://bigmodel.cn/dev/howuse/glm-4)                                                                          | 1289 | +3/-3   | 27,788  | Zhipu AI               | Proprietary             | Aucune donnée     |
|       61 |              66 | [GPT-4o-mini-2024-07-18](https://openai.com/index/gpt-4o-mini-advancing-cost-efficient-intelligence/)                       | 1287 | +2/-2   | 72,423  | OpenAI                 | Proprietary             | 2023/10  |
|       61 |              75 | [Gemini-1.5-Flash-002](https://aistudio.google.com/app/prompts/new_chat?instructions=lmsys&model=gemini-1.5-flash-002)      | 1287 | +3/-3   | 37,021  | Google                 | Proprietary             | Aucune donnée     |
|       61 |              84 | [Llama-3.1-Nemotron-70B-Instruct](https://huggingface.co/mistralai/Mistral-Large-Instruct-2411)                                          | 1284 | +6/-7   | 7,577   | Mistral                | MRL                     | Aucune donnée     |
|       64 |              46 | [Meta-Llama-3.1-405B-Instruct-bf16](https://ai.meta.com/blog/meta-llama-3-1/)                                               | 1284 | +2/-3   | 43,788  | Meta                   | Llama 3.1 Community     | 2023/12  |
|       65 |              48 | [Meta-Llama-3.1-405B-Instruct-fp8](https://ai.meta.com/blog/meta-llama-3-1/)                                                | 1283 | +2/-3   | 63,038  | Meta                   | Llama 3.1 Community     | 2023/12  |
|       66 |              42 | [Claude 3.5 Sonnet (20240620)](https://www.anthropic.com/news/claude-3-5-sonnet)                                            | 1283 | +1/-2   | 86,159  | Anthropic              | Proprietary             | 2024/4   |
|       66 |              46 | [Gemini Advanced App (2024-05-14)](https://gemini.google.com/advanced)                                                      | 1282 | +3/-3   | 52,144  | Google                 | Proprietary             | Online   |
|       66 |              58 | [Llama-4-Scout-17B-16E-Instruct](https://huggingface.co/meta-llama/Llama-4-Scout-17B-16E-Instruct)                          | 1279 | +6/-6   | 9,771   | Meta                   | Llama                   | Aucune donnée     |
|       67 |              81 | [Grok-2-Mini-08-13](https://x.ai/blog/grok-2)                                                                               | 1281 | +2/-3   | 55,442  | xAI                    | Proprietary             | 2024/3   |
|       67 |              65 | [Hunyuan-Standard-2025-02-10](https://cloud.tencent.com/document/product/1729/104753)                                       | 1276 | +8/-8   | 4,014   | Tencent                | Proprietary             | Aucune donnée     |
|       68 |              50 | [GPT-4o-2024-08-06](https://platform.openai.com/docs/models/gpt-4o)                                                         | 1280 | +2/-3   | 47,973  | OpenAI                 | Proprietary             | 2023/10  |
|       68 |              68 | [Qwen-Max-0919](https://help.aliyun.com/zh/dashscope/developer-reference/model-introduction)                                | 1278 | +4/-3   | 17,432  | Alibaba                | Qwen                    | Aucune donnée     |
|       75 |              63 | [Gemini-1.5-Pro-001](https://aistudio.google.com/app/prompts/new_chat?model=gemini-1.5-pro)                                 | 1275 | +2/-2   | 82,435  | Google                 | Proprietary             | 2023/11  |
|       76 |              80 | [Deepseek-v2.5](https://huggingface.co/deepseek-ai/DeepSeek-V2.5)                                                           | 1273 | +3/-3   | 26,344  | DeepSeek               | DeepSeek                | Aucune donnée     |
|       78 |              66 | [Llama-3.3-70B-Instruct](https://huggingface.co/meta-llama/Llama-3.3-70B-Instruct)                                          | 1273 | +2/-2   | 48,583  | Meta                   | Llama-3.3               | Aucune donnée     |
|       78 |              84 | [Qwen2.5-72B-Instruct](https://qwenlm.github.io/blog/qwen2.5/)                                                              | 1272 | +3/-3   | 41,519  | Alibaba                | Qwen                    | 2024/9   |
|       78 |              61 | [GPT-4-Turbo-2024-04-09](https://platform.openai.com/docs/models/gpt-4-turbo-and-gpt-4)                                     | 1271 | +2/-2   | 102,133 | OpenAI                 | Proprietary             | 2023/12  |
|       78 |              88 | [Mistral-Small-3.1-24B-Instruct-2503](https://huggingface.co/mistralai/Mistral-Small-3.1-24B-Instruct-2503)                 | 1268 | +6/-6   | 9,738   | Mistral                | Apache 2.0              | Aucune donnée     |
|       84 |              69 | [Mistral-Large-2407](https://mistral.ai/news/mistral-large-2407/)                                                           | 1267 | +2/-3   | 48,217  | Mistral                | Mistral Research        | 2024/7   |
|       84 |              82 | [Athene-70B](https://huggingface.co/Nexusflow/Athene-70B)                                                                   | 1265 | +4/-4   | 20,580  | NexusFlow              | CC-BY-NC-4.0            | 2024/7   |
|       84 |              88 | [Llama-3.1-Tulu-3-70B](https://huggingface.co/allenai/Llama-3.1-Tulu-3-70B)                                                 | 1259 | +8/-11  | 3,010   | Ai2                    | Llama 3.1               | Aucune donnée     |
|       85 |              66 | [GPT-4-1106-preview](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)                         | 1265 | +2/-2   | 103,748 | OpenAI                 | Proprietary             | 2023/4   |
|       85 |              84 | [Mistral-Large-2411](https://huggingface.co/mistralai/Mistral-Large-Instruct-2411)                                          | 1264 | +3/-3   | 29,633  | Mistral                | MRL                     | Aucune donnée     |
|       85 |              91 | [Meta-Llama-3.1-70B-Instruct](https://ai.meta.com/blog/meta-llama-3-1/)                                                     | 1263 | +2/-3   | 58,637  | Meta                   | Llama 3.1 Community     | 2023/12  |
|       85 |              63 | [Claude 3 Opus](https://www.anthropic.com/news/claude-3-family)                                                             | 1262 | +1/-2   | 202,641 | Anthropic              | Proprietary             | 2023/8   |
|       86 |              92 | [Amazon Nova Pro 1.0](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html)                                  | 1260 | +3/-4   | 26,371  | Amazon                 | Proprietary             | Aucune donnée     |
|       88 |              70 | [GPT-4-0125-p preview](https://openai.com/blog/new-models-and-developer-products-announced-at-devday)                         | 1260 | +2/-2   | 97,079  | OpenAI                 | Proprietary             | 2023/12  |
|       88 |              91 | [Hunyuan-Large-Vision](https://cloud.tencent.com/document/product/1729/104753#d6cb04da-053d-4bed-b187-191514feb972)         | 1255 | +7/-9   | 4,995   | Tencent                | Proprietary             | Aucune donnée     |
|       88 |              74 | [magistral-medium-2506](https://mistral.ai/news/magistral)                                                                  | 1253 | +8/-7   | 5,732   | Mistral                | Proprietary             | Aucune donnée     |
|       94 |              65 | [Claude 3.5 Haiku (20241022)](https://www.anthropic.com/news/3-5-models and-computer-use)                                   | 1254 | +3/-3   | 51,504  | Anthropic              | Propretary              | Aucune donnée     |
|       94 |              91 | [Reka-Core-20240904](https://docs.reka.ai/available-models)                                                                 | 1250 | +5/-7   | 7,948   | Reka AI                | Proprietary             | Aucune donnée     |
|       98 |              95 | [Gemini-1.5-Flash-001](https://aistudio.google.com/app/prompts/new_chat?model=gemini-1.5-flash)                             | 1242 | +2/-2   | 65,661  | Google                 | Proprietary             | 2023/11  |
|       99 |              92 | [Jamba-1.5-Large](https://www.ai21.com/jamba)                                                                               | 1237 | +5/-6   | 9,125   | AI21 Labs              | Jamba Open              | 2024/3   |
|      100 |              94 | [Gemma-2-27B-it](https://aistudio.google.com/app/prompts/new_chat?model=gemma-2-27b-it)                                     | 1235 | +2/-2   | 79,538  | Google                 | Gemma license           | 2024/6   |
|      100 |             104 | [Mistral-Small-24B-Instruct-2501](https://huggingface.co/mistralai/Mistral-Small-24B-Instruct-2501)                         | 1233 | +5/-4   | 15,321  | Mistral                | Apache 2.0              | Aucune donnée     |
|      100 |             103 | [Qwen2.5-Coder-32B-Instruct](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct)                                        | 1232 | +6/-6   | 5,730   | Alibaba                | Apache 2.0              | Aucune donnée     |
|      100 |             111 | [Amazon Nova Lite 1.0](https://docs.aws.amazon.com/nova/latest/userguide/what-is-nova.html)                                 | 1232 | +3/-5   | 20,646  | Amazon                 | Proprietary             | Aucune donnée     |
|      100 |              97 | [Gemma-2-9B-it-SimPO](https://huggingface.co/princeton-nlp/gemma-2-9b-it-SimPO)                                             | 1231 | +4/-7   | 10,548  | Princeton              | MIT                     | 
# Classement LLM Arena (mise à jour en temps réel)

Ce classement est généré automatiquement à partir des données de Chatbot Arena (lmarena.ai) via un processus automatisé.

> **Date de mise à jour des données**: 2025-08-04 11:44:51 UTC / 2025-08-04 19:44:51 CST (Heure de Pékin)

{% hint style="info" %}
Cliquez sur le **nom du modèle** dans le classement pour accéder à sa page de détails ou d'essai.
{% endhint %}

## Classement

| Rang (UB) | Rang (StyleCtrl) | Nom du modèle                                                                                                                         | Score | Intervalle de confiance | Votes    | Fournisseur                    | Licence                    | Date de fin des connaissances |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
| Identique à l'original pour toutes les lignes du tableau |
| ... | ... | ... | ... | ... | ... | ... | ... | ... |

## Explications

- **Rang (UB)** : Classement calculé sur le modèle Bradley-Terry. Il reflète la performance globale des modèles dans l'arène et fournit une estimation de la **borne supérieure** de leur score Elo, permettant d'évaluer leur compétitivité potentielle.
- **Rang (StyleCtrl)** : Classement après contrôle du style conversationnel. Il vise à réduire les biais de préférence liés au style des réponses (ex: verbosité, concision) pour évaluer plus précisément les capacités fondamentales des modèles.
- **Nom du modèle** : Nom du modèle de langage (LLM). Cette colonne contient des liens vers des ressources associées (clique pour accéder).
- **Score** : Évaluation Elo du modèle basée sur les votes des utilisateurs dans l'arène. Un score plus élevé indique de meilleures performances. Ce score évolue dynamiquement en fonction de l'environnement compétitif actuel.
- **Intervalle de confiance** : Intervalle de confiance à 95% du score Elo (ex: `+6/-6`). Un intervalle réduit indique une évaluation plus stable et fiable ; un intervalle large peut indiquer un manque de données ou des variations de performance.
- **Votes** : Nombre total de votes reçus par le modèle dans l'arène. Plus le nombre de votes est élevé, plus la fiabilité statistique est grande.
- **Fournisseur** : Organisation ou entreprise fournissant le modèle.
- **Licence** : Type de licence (ex: Propriétaire, Apache 2.0, MIT, etc.).
- **Date de fin des connaissances** : Date de clôture des connaissances utilisées pour entraîner le modèle. **Données non disponibles** indique une information manquante ou inconnue.

## Source des données et fréquence de mise à jour

Ce classement est généré et fourni automatiquement par le projet [fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv) qui collecte et traite les données depuis [lmarena.ai](https://lmarena.ai/). Le classement est mis à jour quotidiennement par GitHub Actions.

## Clause de non-responsabilité

Ce rapport est fourni à titre informatif uniquement. Les données du classement sont dynamiques et basées sur les votes de préférence des utilisateurs dans Chatbot Arena durant des périodes spécifiques. L'exhaustivité et l'exactitude des données dépendent de la source en amont et du traitement par le projet `fboulnois/llm-leaderboard-csv`. Les modèles peuvent utiliser différentes licences - veuillez consulter les informations officielles des fournisseurs avant utilisation.