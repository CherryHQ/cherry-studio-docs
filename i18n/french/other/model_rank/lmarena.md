# Classement LLM Arena (Mise à jour en temps réel)


{% hint style="warning" %}
Ce document a été traducido del chino por IA y aún no ha sido revisado.
{% endhint %}




{% hint style="info" %}
Ce classement est généré automatiquement à partir des données de Chatbot Arena (lmarena.ai).

> **Date de mise à jour des données**: 2025-08-08 11:44:43 UTC / 2025-08-08 19:44:43 CST (Heure de Pékin)
{% endhint %}

{% hint style="warning" %}
Cliquez sur le **nom du modèle** dans le classement pour accéder à sa page de détails ou d'essai.
{% endhint %}

## Classement

| R(UB) | R(StyleCtrl) | Modèle                                                                                                                                 | Score | Intervalle   | Votes    | Fournisseur             | Licence                 | Date limite |
|:------|:-------------|:---------------------------------------------------------------------------------------------------------------------------------------|:------|:-------------|:---------|:------------------------|:------------------------|:------------|
|     1 |            1 | [Gemini-2.5-Pro](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro)                                                 |  1470 | +5/-5        | 26,019   | Google                  | Proprietary             | nan         |
| ...   | ...          | ...                                                                                                                                   | ...   | ...          | ...      | ...                     | ...                     | ...         |

## Explications

- **R(UB)** : Classement calculé avec le modèle Bradley-Terry. Ce classement reflète la performance globale du modèle dans l'arène et fournit une estimation **supérieure** de son score Elo, aidant à comprendre son potentiel compétitif.
- **R(StyleCtrl)** : Classement après contrôle du style de conversation. Cette méthodologie vise à réduire les biais de préférence liés au style de réponse (ex. verbosité, concision), évaluant plus précisément les capacités fondamentales du modèle.
- **Modèle** : Nom du modèle de langage (LLM). Cette colonne contient des liens cliquables vers les ressources associées.
- **Score** : Évaluation Elo du modèle basée sur les votes des utilisateurs. Un score plus élevé indique de meilleures performances. Cette valeur évolue dynamiquement, reflétant la performance relative du modèle dans l'environnement compétitif actuel.
- **Intervalle** : Intervalle de confiance à 95% du score Elo (ex. `+6/-6`). Un intervalle réduit indique une évaluation plus stable et fiable ; inversement, un intervalle large peut suggérer un manque de données ou une performance inconstante. Cet indicateur quantifie la précision du score.
- **Votes** : Nombre total de votes reçus par le modèle dans l'arène. Un nombre élevé de votes augmente généralement la fiabilité statistique du score.
- **Fournisseur** : Organisation ou entreprise proposant le modèle.
- **Licence** : Type de licence appliquée au modèle (ex. Propriétaire, Apache 2.0, MIT).
- **Date limite** : Date de fin des connaissances du jeu d'entraînement. **Données indisponibles** indique une information non fournie ou inconnue.

## Source et fréquence de mise à jour

Ce classement est généré et fourni automatiquement par le projet [fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv), qui collecte et traite les données depuis [lmarena.ai](https://lmarena.ai/). Le classement est mis à jour quotidiennement via GitHub Actions.

## Clause de non-responsabilité

Ce rapport est fourni à titre informatif. Les données du classement sont dynamiques et basées sur les préférences des utilisateurs exprimées via Chatbot Arena durant une période spécifique. L'exactitude et l'exhaustivité des données dépendent des sources amont et des traitements du projet `fboulnois/llm-leaderboard-csv`. Différents modèles peuvent utiliser diverses licences d'utilisation - veuillez consulter les documents officiels des fournisseurs avant toute utilisation.