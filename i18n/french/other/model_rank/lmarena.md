# Classement LLM Arena (mise à jour en temps réel)


{% hint style="warning" %}
Ce document a été traducido del chino por IA y aún no ha sido revisado.
{% endhint %}




Il s'agit d'un classement généré automatiquement à partir des données de Chatbot Arena (lmarena.ai).

> **Dernière mise à jour des données** : 2025-06-26 11:42:56 UTC / 2025-06-26 19:42:56 CST (heure de Pékin)

{% hint style="info" %}
Cliquez sur le **nom du modèle** dans le classement pour accéder à sa page de détails ou d'essai.
{% endhint %}

## Classement

| Classement (UB) | Classement (StyleCtrl) | Nom du modèle                                                                                                                         | Score | Intervalle de confiance | Votes     | Fournisseur                    | Licence                    | Date de fin de connaissances |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|        ... (les données du tableau restent inchangées) ... |
|        1 |               1 | [Gemini-2.5-Pro](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro)                                      | 1477 | +5/-5   | 12,327  | Google                 | Propriétaire             | Pas de données     |
|        ... (les données du tableau restent inchangées) ... |
|      208 |             207 | [LLaMA-13B](https://arxiv.org/abs/2302.13971)                                                                               |  817 | +11/-12 | 2,446   | Meta                   | Non commercial          | 2023/2   |

## Explications

- **Classement (UB)** : Classement calculé avec le modèle Bradley-Terry. Il reflète la performance globale d'un modèle dans l'arène et fournit une estimation de la **borne supérieure** de son score Elo, aidant à comprendre son potentiel compétitif.
- **Classement (StyleCtrl)** : Classement après contrôle du style conversationnel. Il vise à réduire les biais de préférence dus au style des réponses (par exemple longues vs concises), évaluant plus purement les capacités fondamentales des modèles.
- **Nom du modèle** : Nom des grands modèles de langage (LLM). Cette colonne contient des liens vers les modèles.
- **Score** : Score Elo obtenu par les votes des utilisateurs dans l'arène. Plus le score est élevé, meilleure est la performance. Ce score évolue dynamiquement selon l'environnement compétitif.
- **Intervalle de confiance** : Intervalle de confiance à 95% du score Elo (ex: `+6/-6`). Plus l'intervalle est petit, plus le score est fiable ; plus grand, il indique des données insuffisantes ou une performance instable.
- **Votes** : Nombre total de votes reçus par le modèle. Plus il y a de votes, plus la fiabilité statistique est élevée.
- **Fournisseur** : Organisation ou entreprise fournissant le modèle.
- **Licence** : Type de licence du modèle (ex: propriétaire, Apache 2.0, MIT).
- **Date de fin de connaissances** : Date de clôture des données d'entraînement. **Pas de données** indique une information non disponible.

## Source des données et fréquence de mise à jour

Ces données sont générées automatiquement par le projet [fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv), qui collecte et traite les données de [lmarena.ai](https://lmarena.ai/). Ce classement est mis à jour quotidiennement par GitHub Actions.

## Clause de non-responsabilité

Ce rapport est fourni à titre informatif. Les données du classement évoluent dynamiquement et sont basées sur les préférences des utilisateurs dans Chatbot Arena durant une période spécifique. L'exhaustivité et l'exactitude des données dépendent des sources amont et des traitements du projet `fboulnois/llm-leaderboard-csv`. Différents modèles peuvent avoir différentes licences - référez-vous toujours aux conditions d'utilisation officielles des fournisseurs.