
{% hint style="warning" %}
Ce document a été traducido del chino por IA y aún no ha sido revisado.
{% endhint %}

# Informations de référence courantes sur les modèles

{% hint style="info" %}
* Les informations suivantes sont fournies à titre indicatif. En cas d'erreur, veuillez nous contacter pour correction. La taille de contexte et les informations sur les modèles peuvent varier selon les fournisseurs.
* Lors de la saisie côté client, convertissez "k" en valeur réelle (1k = 1024 tokens théoriques ; 1m = 1024k tokens). Par exemple, 8k = 8×1024=8192 tokens. En pratique, multipliez par 1000 pour éviter les erreurs : 8k=8000, 1m=1000000.
* Le symbole "-" pour la sortie maximale indique que cette information n'est pas officiellement documentée.
{% endhint %}

<table><thead><tr><th width="313">Nom du modèle</th><th width="158">Entrée maximale</th><th width="72">Sortie maximale</th><th width="95">Appel de fonction</th><th width="142">Capacités du modèle</th><th width="540">Fournisseur</th><th width="257">Description</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>Non pris en charge</td><td>Dialogue</td><td>360AI_360gpt</td><td>Modèle phare à dix milliards de paramètres de la série 360 Brain, adapté à des scénarios complexes dans divers domaines.</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>Non pris en charge</td><td>Dialogue</td><td>360AI_360gpt</td><td>Modèle à milliard de paramètres équilibrant performance et efficacité, adapté aux scénarios sensibles au rapport performances/coût.</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>Non pris en charge</td><td>Dialogue</td><td>360AI_360gpt</td><td>Modèle à milliard de paramètres équilibrant performance et efficacité, adapté aux scénarios sensibles au rapport performances/coût.</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>Non pris en charge</td><td>Dialogue</td><td>360AI_360gpt</td><td>Modèle phare à dix milliards de paramètres de la série 360 Brain, adapté à des scénarios complexes dans divers domaines.</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Anthropic_claude</td><td>Version snapshot publiée le 20 juin 2024. Claude 3.5 Sonnet offre une performance de pointe tout en maintenant une vitesse élevée, avec entrées multimodales.</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>Non pris en charge</td><td>Dialogue</td><td>Anthropic_claude</td><td>Snapshot du 22 octobre 2024. Claude 3.5 Haiku améliore toutes les compétences dont le codage, l'utilisation d'outils et le raisonnement. Modèle le plus rapide d'Anthropic, adapté aux chatbots interactifs et à la complétion de code. Excellent pour l'extraction de données et la modération de contenu. Ne prend pas en charge les images.</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Anthropic_claude</td><td>Snapshot du 22 octobre 2024. Claude 3.5 Sonnet dépasse Opus en capacité et est plus rapide que Sonnet, tout en conservant le même prix. Excellent en programmation, science des données, traitement visuel et tâches d'agents.</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Anthropic_claude</td><td>Version dynamique pointant vers le dernier Claude 3.5 Sonnet. Dépasse Opus en capacité et est plus rapide que Sonnet. Idéal pour la programmation, science des données, traitement visuel et tâches d'agents.</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Anthropic_claude</td><td>Claude 3 Haiku est le modèle le plus rapide et compact d'Anthropic, conçu pour des réponses quasi instantanées avec une précision directionnelle.</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Anthropic_claude</td><td>Claude 3 Opus est le modèle le plus puissant d'Anthropic pour les tâches complexes, avec une performance, intelligence, fluidité et compréhension exceptionnelles.</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Anthropic_claude</td><td>Snapshot du 29 février 2024. Excellentes capacités en :<br><br>- Codage : écriture, édition et exécution autonome de code<br>- Science des données : travail avec données non structurées<br>- Traitement visuel : interprétation de diagrammes, graphiques et images<br>- Tâches d'agents : excellente utilisation des outils pour résoudre des problèmes complexes.</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>Non pris en charge</td><td>Dialogue</td><td>Google_gamma</td><td>Modèle Gemma de Google : léger et de pointe. Modèles de langage de type décodeur uniquement en anglais, adaptés aux tâches de génération de texte.</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>Non pris en charge</td><td>Dialogue</td><td>Google_gamma</td><td>Modèle Gemma 9B de Google, entraîné sur 8 billions de tokens, adapté aux tâches de génération de texte.</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue</td><td>Google_gemini</td><td>Stable Gemini 1.5 Pro. Modèle multimodal puissant traitant jusqu'à 6 000 lignes de code ou 2 000 pages de texte. Idéal pour les tâches nécessitant un raisonnement complexe.</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>Non pris en charge</td><td>Dialogue</td><td>Google_gemini</td><td>Stable Gemini 1.0 Pro. Modèle NLP pour dialogues multilocuteurs et génération de code. Dépréciation prévue le 15 février 2025.</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>Non pris en charge</td><td>Dialogue</td><td>Google_gemini</td><td>Stable Gemini 1.0 Pro. Modèle NLP pour dialogues multilocuteurs et génération de code. Dépréciation prévue le 15 février 2025.</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, déprécié ou prochainement déprécié</td><td>Google_gemini</td><td>Dernière version Gemini 1.0 Pro. Modèle NLP pour dialogues multilocuteurs et génération de code. Dépréciation prévue le 15 février 2025.</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>Non pris en charge</td><td>Dialogue</td><td>Google_gemini</td><td>Version vision de Gemini 1.0 Pro. Dépréciation prévue le 15 février 2025.</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>Non pris en charge</td><td>Reconnaissance d'image</td><td>Google_gemini</td><td>Dernière version vision de Gemini 1.0 Pro. Dépréciation prévue le 15 février 2025.</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Dernière version stable Gemini 1.5 Flash. Modèle multimodal équilibré traitant l'audio, les images, la vidéo et le texte.</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version stable Gemini 1.5 Flash. Fonctionnalités de base identiques à gemini-1.5-flash, version fixe adaptée à la production.</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version stable Gemini 1.5 Flash. Fonctionnalités de base identiques à gemini-1.5-flash, version fixe adaptée à la production.</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Gemini 1.5 Flash-8B : modèle multimodal IA optimisé pour efficacité, vitesses et coûts. Traite texte, images, audio, vidéo. Distillation de connaissances et limite de débit doublée.</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version expérimentale Gemini 1.5 Flash mise à jour régulièrement. Pour tests exploratoires, non recommandé en production.</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version de pointe Gemini 1.5 Flash mise à jour régulièrement. Pour tests exploratoires, non recommandé en production.</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version stable Gemini 1.5 Pro avec comportement fixe, adapté à la production.</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version stable Gemini 1.5 Pro avec comportement fixe, adapté à la production.</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version expérimentale Gemini 1.5 Pro. Modèle multimodal puissant traitant jusqu'à 6 000 lignes de code ou 2 000 pages de texte. Idéal pour raisonnement complexe.</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Version expérimentale Gemini 1.5 Pro. Modèle multimodal puissant traitant jusqu'à 6 000 lignes de code ou 2 000 pages de texte. Idéal pour raisonnement complexe.</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Dernière version Gemini 1.5 Pro pointant vers la dernière snapshot.</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Gemini 2.0 Flash : vitesse de génération initiale plus rapide, qualité équivalente à Gemini Pro 1.5. Capacités améliorées en compréhension multimodale, code, exécution d'instructions et appels de fonctions.</td></tr><tr><td>gemini-2.0-flash-exp</td><td>100k</td><td>8k</td><td>Pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Gemini 2.0 Flash introduit une API multimodale temps réel, améliore vitesse/performance, qualité, capacités d'agents, et ajoute génération d'images et conversion vocale.</td></tr><tr><td>gemini-2.0-flash-lite-preview-02-05</td><td>1M</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, reconnaissance d'image</td><td>Google_gemini</td><td>Gemini 2.0 Flash-Lite : rapport qualité-prix optimal de Google. Vitesse équivalente à 1.5 Flash, fenêtre de contexte 1 million tokens, traite images, audio, code. Tarification simplifiée, idéal pour applications à grande échelle.</td></tr><tr><td>gemini-2.0-flash-thinking-exp</td><td>40k</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, raisonnement</td><td>Google_gemini</td><td>Version expérimentale générant le "processus de réflexion" durant la réponse. Capacités de raisonnement supérieures au modèle Gemini 2.0 Flash de base.</td></tr><tr><td>gemini-2.0-flash-thinking-exp-01-21</td><td>1m</td><td>64k</td><td>Non pris en charge</td><td>Dialogue, raisonnement</td><td>Google_gemini</td><td>Gemini 2.0 Flash Thinking EXP-01-21 : capacités avancées en raisonnement (maths, programmation). Supporte 1 million tokens, génère le processus de réflexion, exécution native de code, réduit les contradictions logiques.</td></tr><tr><td>gemini-2.0-flash-thinking-exp-1219</td><td>40k</td><td>8k</td><td>Non pris en charge</td><td>Dialogue, raisonnement, reconnaissance d'image</td><td>Google_gemini</td