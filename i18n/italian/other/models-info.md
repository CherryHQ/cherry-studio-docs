
{% hint style="warning" %}
Questo documento è stato tradotto dal cinese tramite IA e non è ancora stato revisionato.
{% endhint %}

# Informazioni di Riferimento sui Modelli Comuni

{% hint style="info" %}
* Le seguenti informazioni sono solo a scopo di riferimento. In caso di errori, contattateci per correggerli. A seconda del fornitore del modello, la dimensione del contesto e le informazioni sul modello potrebbero variare.
* Durante l'immissione dei dati nel client, convertire "k" in valori effettivi (teoricamente 1k = 1024 token; 1m = 1024k token). Ad esempio, 8k equivale a 8×1024=8192 token. Si consiglia di moltiplicare per 1000 nell'uso effettivo per evitare errori, ad esempio 8k → 8×1000=8000, 1m → 1×1000000=1000000.
* I modelli con "Uscita massima" indicata come "-" non hanno informazioni ufficiali chiare sul valore massimo.
{% endhint %}

<table><thead><tr><th width="313">Nome modello</th><th width="158">Ingresso massimo</th><th width="72">Uscita massima</th><th width="95">Chiamata di funzione</th><th width="142">Capacità del modello</th><th width="540">Fornitore</th><th width="257">Descrizione</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>Non supportato</td><td>dialogo</td><td>360AI_360gpt</td><td>Il modello principale più performante della serie 360 Brain, con migliaia di miliardi di parametri, ampiamente applicabile in scenari complessi in vari campi.</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>Non supportato</td><td>dialogo</td><td>360AI_360gpt</td><td>Modello da decine di miliardi di parametri che bilancia prestazioni ed efficacia, adatto a scenari con requisiti elevati di prestazioni/costi.</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>Non supportato</td><td>dialogo</td><td>360AI_360gpt</td><td>Modello da decine di miliardi di parametri che bilancia prestazioni ed efficacia, adatto a scenari con requisiti elevati di prestazioni/costi.</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>Non supportato</td><td>dialogo</td><td>360AI_360gpt</td><td>Il modello principale più performante della serie 360 Brain, con migliaia di miliardi di parametri, ampiamente applicabile in scenari complessi in vari campi.</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Anthropic_claude</td><td>Versione snapshot rilasciata il 20 giugno 2024. Claude 3.5 Sonnet è un modello bilanciato che combina prestazioni e velocità, supportando input multimodale.</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>Non supportato</td><td>dialogo</td><td>Anthropic_claude</td><td>Versione snapshot rilasciata il 22 ottobre 2024. Claude 3.5 Haiku mostra miglioramenti in codifica, utilizzo di strumenti e ragionamento. È il modello più veloce della serie Anthropic, ideale per chatbot interattivi e completamento codice in tempo reale.</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Anthropic_claude</td><td>Versione snapshot rilasciata il 22 ottobre 2024. Supera Opus in capacità con la stessa velocità di Sonnet, eccellendo in programmazione, scienza dei dati ed elaborazione visiva.</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Anthropic_claude</td><td>Punta dinamicamente all'ultima versione di Claude 3.5 Sonnet, eccellendo in programmazione, scienza dei dati ed elaborazione visiva.</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Anthropic_claude</td><td>Modello più veloce e compatto di Anthropic, progettato per risposte quasi istantanee con prestazioni mirate.</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Anthropic_claude</td><td>Modello più potente di Anthropic per compiti altamente complessi, eccellente in prestazioni, intelligenza, fluidità e comprensione.</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Anthropic_claude</td><td>Versione snapshot del 29 febbraio 2024. Eccelle in: codifica (scrittura, modifica ed esecuzione codice), scienza dei dati (elaborazione dati non strutturati), elaborazione visiva (interpretazione grafici/tabelle) e attività di agenti.</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>Non supportato</td><td>dialogo</td><td>Google_gamma</td><td>Serie di modelli open leggeri e all'avanguardia sviluppata da Google, basata sulla stessa tecnologia Gemini. Modelli decoder-only per generazione testo.</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>Non supportato</td><td>dialogo</td><td>Google_gamma</td><td>Modello da 9B addestrato su 8 trilioni di token, adatto a QA, riassunto e ragionamento.</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo</td><td>Google_gemini</td><td>Ultima versione stabile di Gemini 1.5 Pro. Modello multimodale potente che gestisce 60k righe di codice o 2k pagine di testo, ideale per ragionamenti complessi.</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>Non supportato</td><td>dialogo</td><td>Google_gemini</td><td>Versione stabile di Gemini 1.0 Pro per chatbot multiline e generazione codice. Da ritirare il 15/2/2025.</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>Non supportato</td><td>dialogo</td><td>Google_gemini</td><td>Versione stabile di Gemini 1.0 Pro per chatbot multiline e generazione codice. Da ritirare il 15/2/2025.</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>Non supportato</td><td>dialogo, obsoleto o prossimo all'obsolescenza</td><td>Google_gemini</td><td>Ultima versione di Gemini 1.0 Pro. Da ritirare il 15/2/2025.</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>Non supportato</td><td>dialogo</td><td>Google_gemini</td><td>Versione visiva di Gemini 1.0 Pro. Da ritirare il 15/2/2025.</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>Non supportato</td><td>riconoscimento immagini</td><td>Google_gemini</td><td>Ultima versione visiva di Gemini 1.0 Pro. Da ritirare il 15/2/2025.</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Ultima versione stabile di Gemini 1.5 Flash. Modello multimodale bilanciato che elabora audio, immagini, video e testo.</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione stabile con funzionalità identiche a gemini-1.5-flash, adatta a produzione.</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione stabile con funzionalità identiche a gemini-1.5-flash, adatta a produzione.</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Modello multimodale con 8B parametri ottimizzato per efficienza e velocità. Supporta input multipli e offre prestazioni migliorate grazie a "knowledge distillation".</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione sperimentale aggiornata periodicamente, ideale per test esplorativi ma non produzione.</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione all'avanguardia aggiornata periodicamente per test esplorativi.</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione stabile per ambienti di produzione.</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione stabile per ambienti di produzione.</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione sperimentale di Gemini 1.5 Pro per compiti complessi.</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione sperimentale di Gemini 1.5 Pro per compiti complessi.</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Punta dinamicamente all'ultima snapshot.</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Modello più rapido di Gemini 1.5 con qualità comparabile, migliorato in comprensione multimodale e chiamate di funzione.</td></tr><tr><td>gemini-2.0-flash-exp</td><td>100k</td><td>8k</td><td>Supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Introduce API multimodali real-time, velocità e prestazioni migliorate, e funzionalità avanzate come generazione immagini.</td></tr><tr><td>gemini-2.0-flash-lite-preview-02-05</td><td>1M</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Modello ad alta efficienza che bilancia velocità e qualità, supporta input multimodale e contesto fino a 1M token.</td></tr><tr><td>gemini-2.0-flash-thinking-exp</td><td>40k</td><td>8k</td><td>Non supportato</td><td>dialogo, ragionamento</td><td>Google_gemini</td><td>Modello sperimentale che mostra il "processo di pensiero" durante la generazione, migliorando le capacità di ragionamento.</td></tr><tr><td>gemini-2.0-flash-thinking-exp-01-21</td><td>1m</td><td>64k</td><td>Non supportato</td><td>dialogo, ragionamento</td><td>Google_gemini</td><td>Migliorato in matematica e programmazione, supporta contesto fino a 1M token e genera processi di pensiero. Esegue codice nativo per interazioni avanzate.</td></tr><tr><td>gemini-2.0-flash-thinking-exp-1219</td><td>40k</td><td>8k</td><td>Non supportato</td><td>dialogo, ragionamento, riconoscimento immagini</td><td>Google_gemini</td><td>Modello sperimentale che mostra il "processo di pensiero" durante la generazione.</td></tr><tr><td>gemini-2.0-pro-exp-01-28</td><td>2m</td><td>64k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Modello pre-rilascio, non ancora disponibile</td></tr><tr><td>gemini-2.0-pro-exp-02-05</td><td>2m</td><td>8k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Versione sperimentale con prestazioni avanzate in conoscenza mondiale, generazione codice e comprensione testi lunghi (supporto a 2M token).</td></tr><tr><td>gemini-exp-1114</td><td>8k</td><td>4k</td><td>Non supportato</td><td>dialogo, riconoscimento immagini</td><td>Google_gemini</td><td>Modello sperimentale rilasciato il 14/11/2024, focalizzato su miglioramenti qualitativi.</td></tr><tr><td>gemini-exp-1121</td><td>8k</td><td>4k</td><td>Non supportato</td><td