
{% hint style="warning" %}
このドキュメントはAIによって中国語から翻訳されており、まだレビューされていません。
{% endhint %}

# 共通モデル参照情報

{% hint style="info" %}
* 以下の情報は参考用です。誤りがある場合は修正依頼可能ですが、一部モデルはサービスプロバイダによりコンテキストサイズや仕様が異なる場合があります
* クライアント入力時には「k」を実際の値に変換する必要があります（理論上 1k=1024 tokens; 1m=1024k tokens）。例：8k は 8×1024=8192 tokens。実際の使用時にはエラー防止のため×1000とすることを推奨します（例：8k→8×1000=8000, 1m→1×1000000=1000000）
* 最大出力が「-」のモデルは公式から明確な最大出力情報が確認できなかったものです
{% endhint %}

<table><thead><tr><th width="313">モデル名</th><th width="158">最大入力</th><th width="72">最大出力</th><th width="95">関数呼び出し</th><th width="142">モデル能力</th><th width="540">サービス提供元</th><th width="257">概要</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>非対応</td><td>対話</td><td>360AI_360gpt</td><td>360智脳シリーズで最高性能の主力千億パラメータ大規模モデル。各分野の複雑タスクに広く適用</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>非対応</td><td>対話</td><td>360AI_360gpt</td><td>性能と効果を両立した百億パラメータモデル。性能/コスト要件が高い場面に適する</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>非対応</td><td>対話</td><td>360AI_360gpt</td><td>性能と効果を両立した百億パラメータモデル。性能/コスト要件が高い場面に適する</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>非対応</td><td>対話</td><td>360AI_360gpt</td><td>360智脳シリーズで最高性能の主力千億パラメータ大規模モデル。各分野の複雑タスクに広く適用</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>非対応</td><td>対話,画像認識</td><td>Anthropic_claude</td><td>2024年6月20日リリースのスナップショット版。Claude 3.5 Sonnetは性能と速度のバランスを実現し、高速性を保ちつつトップクラスの性能を提供。マルチモーダル入力対応</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>非対応</td><td>対話</td><td>Anthropic_claude</td><td>2024年10月22日リリースのスナップショット版。Claude 3.5 Haikuはコーディング、ツール使用、推論など全技能を向上。Anthropicシリーズ最速モデルとして高速応答を実現し、ユーザー向けチャットボットやリアルタイムコード補完など高インタラクティブ性・低遅延が求められるアプリケーションに最適。データ抽出やリアルタイムコンテンツ審査でも優れた性能を示す汎用ツール。画像入力非対応</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>非対応</td><td>対話,画像認識</td><td>Anthropic_claude</td><td>2024年10月22日リリースのスナップショット版。Claude 3.5 SonnetはOpusを超える能力を提供しながらSonnetより高速で同じ価格帯を維持。特にプログラミング、データサイエンス、ビジュアル処理、エージェントタスクに優れる</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Anthropic_claude</td><td>最新版Claude 3.5 Sonnetを動的に指すモデル。プログラミング、データサイエンス、ビジュアル処理、エージェントタスクに特に優れ、常に最新バージョンを指す</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>非対応</td><td>対話,画像認識</td><td>Anthropic_claude</td><td>Anthropic最速・最コンパクトモデル。即時応答を実現。高速かつ正確な指向性性能を持つ</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>非対応</td><td>対話,画像認識</td><td>Anthropic_claude</td><td>Anthropicの高度複雑タスク処理用最強モデル。性能、知能、流暢さ、理解力で卓越</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Anthropic_claude</td><td>2024年2月29日スナップショット版。Sonnetは特に以下に優れる：<br><br>- コーディング：自律的なコード記述・編集・実行、推論とトラブルシューティング能力<br>- データサイエンス：人間の専門知識強化。多様なツールによる洞察取得時に非構造化データを処理可能<br>- ビジュアル処理：チャート・グラフ・画像の解釈に優れ、洞察を得るための正確なテキスト転記が可能<br>- エージェントタスク：優れたツール使用能力（他システムとの連携が必要な複数ステップの問題解決タスク）</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>非対応</td><td>対話</td><td>Google_gamma</td><td>Google開発の軽量最先端オープンモデルファミリー。Geminiモデルと同じ研究技術を採用。英語対応デコーダー型大規模言語モデル。プレトレーニング・指示チューニング変種をオープンウェイト提供。質問応答、要約、推論など多様なテキスト生成タスクに適用</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>非対応</td><td>対話</td><td>Google_gamma</td><td>Google開発の軽量最先端オープンモデルシリーズ。英語対応デコーダー型大規模言語モデル。オープンウェイト、プレトレーン変種と指示チューニング変種を提供。質問応答、要約、推論など多様なテキスト生成タスクに適用。8兆tokensで学習</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>非対応</td><td>対話</td><td>Google_gemini</td><td>Gemini 1.5 Pro 最新安定版。強力なマルチモーダルモデル。6万行コードまたは2,000ページテキストを処理可能。複雑な推論タスクに特に適する</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>非対応</td><td>対話</td><td>Google_gemini</td><td>Gemini 1.0 Pro 安定版。NLPモデルとして多輪テキスト/コードチャット・コード生成タスクを専門処理。2025年2月15日廃止予定（1.5シリーズ移行推奨）</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>非対応</td><td>対話</td><td>Google_gemini</td><td>Gemini 1.0 Pro 安定版。NLPモデルとして多輪テキスト/コードチャット・コード生成タスクを専門処理。2025年2月15日廃止予定（1.5シリーズ移行推奨）</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>非対応</td><td>対話,廃止予定</td><td>Google_gemini</td><td>Gemini 1.0 Pro 最新版。NLPモデルとして多輪テキスト/コードチャット・コード生成タスクを専門処理。2025年2月15日廃止予定（1.5シリーズ移行推奨）</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>非対応</td><td>対話</td><td>Google_gemini</td><td>Gemini 1.0 Pro 画像版。2025年2月15日廃止予定（1.5シリーズ移行推奨）</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>非対応</td><td>画像認識</td><td>Google_gemini</td><td>Gemini 1.0 Pro 画像最新版。2025年2月15日廃止予定（1.5シリーズ移行推奨）</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Flash 最新安定版。バランス型マルチモーダルモデル。音声、画像、動画、テキスト入力を処理可能</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Flash 安定版。gemini-1.5-flashと同等の基本機能を提供するがバージョン固定で本番環境に適す</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Flash 安定版。gemini-1.5-flashと同等の基本機能を提供するがバージョン固定で本番環境に適す</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Flash-8BはGoogle最新のマルチモーダルAIモデル。大規模タスク効率的処理向け設計。80億パラメータでテキスト、画像、音声、動画入力対応。チャット、文字起こし、翻訳など多様なシナリオ適用可能。他のGeminiモデル比で速度とコスト効率を最適化しコスト重視ユーザーに最適。レート制限2倍化により大規模タスク効率処理実現。「知識蒸留(ナレッジディスティレーション)」技術でより大規模モデルから核心知識を抽出し、中核能力維持・軽量化・効率化を両立</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Flash 試験版。最新改良を定期的に反映。探索的テスト・プロトタイプ開発向け（本番環境非推奨）</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Flash 最先端版。最新改良を定期的に反映。探索的テスト・プロトタイプ開発向け（本番環境非推奨）</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Pro 安定版。固定モデル動作・性能特性を提供。安定性が必要な本番環境に適す</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Pro 安定版。固定モデル動作・性能特性を提供。安定性が必要な本番環境に適す</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Pro 試験版。強力なマルチモーダルモデル。6万行コードまたは2,000ページテキストを処理可能。複雑な推論タスクに特に適する</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Pro 試験版。強力なマルチモーダルモデル。6万行コードまたは2,000ページテキストを処理可能。複雑な推論タスクに特に適する</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 1.5 Pro 最新版。最新スナップショットを動的に指す</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>非対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 2.0 FlashはGoogle最新モデル。1.5版に比べ初回応答時間（TTFT）短縮し、Gemini Pro 1.5相当品質を維持。マルチモーダル理解、コード能力、複雑指令実行、関数呼び出しを向上させ、より滑潤で強力な知能体験を提供</td></tr><tr><td>gemini-2.0-flash-exp</td><td>100k</td><td>8k</td><td>対応</td><td>対話,画像認識</td><td>Google_gemini</td><td>Gemini 2.0 Flash はマルチモーダルリアルタイムAPI導入、速度・性能向上、品質向上、エージェント能力強化、画像生成と音声変換機能追加</td></tr><tr><td>gemini-2.0-flash-l