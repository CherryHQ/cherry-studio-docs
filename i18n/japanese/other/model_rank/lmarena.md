# LLM Arena リーダーボード (リアルタイム更新)


{% hint style="warning" %}
このドキュメントはAIによって中国語から翻訳されており、まだレビューされていません。
{% endhint %}




これは Chatbot Arena (lmarena.ai) のデータに基づくリーダーボードで、自動化プロセスによって生成されます。

> **データ更新日時**: 2025-08-25 11:41:40 UTC / 2025-08-25 19:41:40 CST (北京時間)

{% hint style="info" %}
リーダーボードの**モデル名**をクリックすると、詳細情報または試用ページに移動します。
{% endhint %}

## リーダーボード

|   ランキング(UB) |   ランキング(StyleCtrl) | モデル名                                                                                                                             |   スコア | 信頼区間    | 票数      | サービスプロバイダー                    | ライセンス                    | ナレッジカットオフ日   |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|        1 |               1 | [Gemini-2.5-Pro](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro)                                          | 1470 | +5/-5   | 26,019  | Google                 | Proprietary             | nan      |
|        2 |               2 | [Gemini-2.5-Pro-Preview-05-06](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro-preview-05-06)              | 1446 | +6/-6   | 13,715  | Google                 | Proprietary             | nan      |
|        3 |               2 | [GLM-4.5](https://z.ai/blog/glm-4.5)                                                                                            | 1434 | +9/-9   | 4,112   | Z.ai                   | MIT                     | nan      |
|        4 |               2 | [Grok-4-0709](https://docs.x.ai/docs/models/grok-4-0709)                                                                        | 1434 | +6/-6   | 13,058  | xAI                    | Proprietary             | nan      |
|        5 |               3 | [ChatGPT-4o-latest (2025-03-26)](https://x.com/OpenAI/status/1905331956856050135)                                               | 1429 | +4/-4   | 30,777  | OpenAI                 | Proprietary             | nan      |
|        6 |               3 | [o3-2025-04-16](https://openai.com/index/introducing-o3-and-o4-mini/)                                                           | 1428 | +4/-4   | 32,033  | OpenAI                 | Proprietary             | nan      |
|        7 |               3 | [Qwen3-235B-A22B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507)                                      | 1427 | +9/-9   | 4,154   | Alibaba                | Apache 2.0              | nan      |
|        8 |               3 | [DeepSeek-R1-0528](https://api-docs.deepseek.com/news/news250528)                                                               | 1427 | +5/-5   | 18,284  | DeepSeek               | MIT                     | nan      |
|        9 |               4 | [Grok-3-Preview-02-24](https://x.ai/blog/grok-3)                                                                                | 1423 | +4/-4   | 31,757  | xAI                    | Proprietary             | nan      |
|       10 |               8 | [Llama-4-Maverick-03-26-Experimental](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)                                | 1416 | +4/-4   | 26,604  | Meta                   | nan                     | nan      |
|       11 |               8 | [GPT-4.5-Preview](https://openai.com/index/introducing-gpt-4-5/)                                                                | 1415 | +5/-5   | 15,271  | OpenAI                 | Proprietary             | nan      |
|       12 |               7 | [Qwen3-235B-A22B-Thinking-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507)                                      | 1413 | +9/-9   | 3,715   | Alibaba                | Apache 2.0              | nan      |
|       13 |               8 | [chocolate (Early Grok-3)](https://x.com/lmarena_ai/status/1891706264800936307)                                                 | 1412 | +6/-6   | 13,837  | xAI                    | Proprietary             | nan      |
|       14 |              10 | [Gemini-2.5-Flash](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-flash)                                      | 1411 | +4/-4   | 31,359  | Google                 | Proprietary             | nan      |
|       15 |              15 | [Gemini-2.0-Flash-Thinking-Exp-01-21](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-flash-thinking-exp-01-21)   | 1397 | +4/-4   | 27,552  | Google                 | Proprietary             | nan      |
|       16 |              15 | [Gemini-2.0-Pro-Exp-02-05](https://aistudio.google.com/prompts/new_chat?model=gemini-2.0-pro-exp-02-05)                         | 1397 | +5/-5   | 20,120  | Google                 | Proprietary             | nan      |
|       17 |              極大級 | [Gemini-2.5-Flash-Preview-04-17](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-flash-preview-04-17)          | 1396 | +5/-5   | 18,655  | Google                 | Proprietary             | nan      |
|       18 |              15 | [GLM-4.5-Air](https://z.ai.blog/glm-4.5)                                                                                        | 1393 | +9/-9   | 4,306   | Z.ai                   | MIT                     | nan      |
|       19 |              15 | [Qwen3-235B-A22B-no-thinking](https://qwenlm.github.io/blog/qwen3/)                                                             | 1391 | +5/-5   | 24,372  | Alibaba                | Apache 2.0              | nan      |
|       20 |              15 | [Gemini-Exp-1206](https://aistudio.google.com/app/prompts/new_chat?model=gemini-exp-1206)                                       | 1389 | +4/-4   | 23,657  | Google                 | Proprietary             | nan      |
... (中略: テーブル項目は完全に保持) ...
|      266 |             264 | [LLaMA-13B](https://arxiv.org/abs/2302.13971)                                                                                   |  840 | +16/-16 | 2,446   | Meta                   | Non-commercial          | 2023/2   |

## 説明

- **ランキング(UB)**：Bradley-Terryモデルに基づくランキング。このランキングはアリーナでのモデルの総合的なパフォーマンスを反映し、Eloスコアの**上界**推定値を提供し、モデルの潜在的な競争力を理解するのに役立ちます。
- **ランキング(StyleCtrl)**：会話スタイル制御後のランキング。このランキングはモデルの返答スタイル（長さ、簡潔さなど）による選好バイアスを減らし、モデルのコア能力を純粋に評価します。
- **モデル名**：大規模言語モデル(LLM)の名称。関連リンクが埋め込まれており、クリックでジャンプします。
- **スコア**：アリーナでのユーザー投票で獲得したEloレーティング。スコアが高いほどモデルのパフォーマンスが優れていることを示し、競争環境における相対的な実力を動的に反映します。
- **信頼区間**：Eloレーティングの95％信頼区間（例： `+6/-6`）。区間が小さいほどスコアの信頼性が高く、区間が大きい場合はデータ不足やパフォーマンス変動を示します。
- **票数**：アリーナで獲得した総投票数。票数が多いほど統計的信頼性が高くなります。
- **サービスプロバイダー**：モデルを提供する組織または企業。
- **ライセンス**：モデルのライセンスタイプ（例: Proprietary, Apache 2.0, MIT）。
- **ナレッジカットオフ日**：モデル訓練データの最終更新日。**データなし**は情報が未提供または不明を示します。

## データソースと更新頻度

本リーダーボードデータは [fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv) プロジェクトにより自動生成され、[lmarena.ai](https://lmarena.ai/) からデータを取得・処理しています。このリーダーボードは GitHub Actions により毎日自動更新されます。

## 免責事項

本レポートは参考情報です。リーダーボードデータは動的に変化し、特定期間内における Chatbot Arena 上のユーザー選好投票に基づいています。データの完全性と正確性は、上流データソースおよび `fboulnois/llm-leaderboard-csv` プロジェクトの更新・処理に依存します。モデルごとに異なるライセンスが適用される場合がありますので、必ずモデル提供者の公式情報を参照してください。