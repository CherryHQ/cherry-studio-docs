
{% hint style="warning" %}
このドキュメントはAIによって中国語から翻訳されており、まだレビューされていません。
{% endhint %}

# LLMアリーナランキング (リアルタイム更新)

これはChatbot Arena（lmarena.ai）のデータに基づく自動生成されたランキングです。

> **データ更新日時**: 2025-06-23 11:42:38 UTC / 2025-06-23 19:42:38 CST (北京時間)

{% hint style="info" %}
ランキング内の **モデル名** をクリックすると、詳細情報または試用ページへ移動します。
{% endhint %}

## ランキング

| 順位(UB) | 順位(StyleCtrl) | モデル名                                                                                                                                       | スコア | 信頼区間    | 票数      | プロバイダー                    | ライセンス                    | ナレッジカットオフ   |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
| 1 | 1 | [Gemini-2.5-Pro-Preview-06-05](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro-preview-06-05)                        | 1480 | +6/-6   | 8,825   | Google                 | Proprietary             | データなし     |
| 2 | 2 | [Gemini-2.5-Pro-Preview-05-06](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro-preview-05-06)                        | 1446 | +5/-5   | 13,025  | Google                 | Proprietary             | データなし     |
| 3 | 2 | [o3-2025-04-16](https://openai.com/index/introducing-o3-and-o4-mini/)                                                                     | 1427 | +4/-4   | 16,019  | OpenAI                 | Proprietary             | データなし     |
| ... (表は原文構造を保持) ... |
| 204 | 202 | [LLaMA-13B](https://arxiv.org/abs/2302.13971)                                                                                             | 815 | +12/-10 | 2,446   | Meta                   | Non-commercial          | 2023/2   |

## 説明

- **順位(UB)**：Bradley-Terryモデルに基づく順位。この順位はアリーナにおけるモデルの総合的な性能を反映し、Eloスコアの**上限**推定値を提供します。モデルの潜在的な競争力を理解するのに役立ちます。
- **順位(StyleCtrl)**：会話スタイル制御後の順位。モデルの返答スタイル（例: 冗長性、簡潔さ）による選好バイアスを減らすことを目的としており、モデルのコア能力をより純粋に評価します。
- **モデル名**：大規模言語モデル(LLM)の名称。この列にはモデル関連リンクが埋め込まれており、クリックするとジャンプします。
- **スコア**：アリーナでユーザー投票により獲得したEloスコア。Eloスコアは相対的なランキングシステムであり、スコアが高いほどモデルの性能が優れていることを示します。このスコアは変動し、現在の競争環境におけるモデルの相対的な実力を反映します。
- **信頼区間**：モデルのEloスコアの95%信頼区間（例: `+6/-6`）。この区間が小さいほど、モデルのスコアの信頼性が高く安定していることを示します。逆に区間が大きい場合はデータ量不足やパフォーマンスの変動が大きい可能性を示唆します。スコアの精度を数量化して評価します。
- **票数**：アリーナでそのモデルが受けた総投票数。票数が多いほど、通常スコアの統計的信頼性が高くなります。
- **プロバイダー**：モデルを提供する組織または企業。
- **ライセンス**：モデルのライセンスタイプ（例: プロプライエタリ(Proprietary)、Apache 2.0、MITなど）。
- **ナレッジカットオフ**：モデル学習データの知識期限。**データなし**は関連情報が提供されていないか不明であることを示します。

## データソースと更新頻度

このランキングデータは[fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv)プロジェクトにより自動生成・提供されています。同プロジェクトは[lmarena.ai](https://lmarena.ai/)からデータを取得・処理しています。このランキングはGitHub Actionsにより毎日自動更新されます。

## 免責事項

本レポートは参考情報です。ランキングデータは動的に変化し、特定の期間内にChatbot Arena上でユーザーが行った選好投票に基づいています。データの完全性と正確性は上流データソース及び`fboulnois/llm-leaderboard-csv`プロジェクトの更新・処理に依存します。各モデルは異なるライセンスを採用している可能性があるため、利用時には必ずモデルプロバイダーの公式説明を参照してください。