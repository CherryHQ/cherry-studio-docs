---
icon: book-bookmark
---

{% hint style="warning" %}
이 문서는 AI에 의해 중국어에서 번역되었으며 아직 검토되지 않았습니다。
{% endhint %}

# 지식 기초

## 토큰(Tokens)이란 무엇인가?

토큰은 AI 모델이 텍스트를 처리하는 기본 단위로, 모델이 "사고"하는 최소 단위로 이해할 수 있습니다. 문자나 단어와 완전히 동일하지 않으며, 모델만의 특별한 텍스트 분할 방식입니다.

#### 1. 중국어 분할
* 한 개의 한자는 일반적으로 1-2개의 토큰으로 인코딩됨
* 예시: `"你好"` ≈ 2-4 tokens

#### 2. 영어 분할
* 일반 단어는 보통 1개 토큰
* 길거나 드문 단어는 여러 토큰으로 분해됨
* 예시:
  * `"hello"` = 1 token
  * `"indescribable"` = 4 tokens

#### 3. 특수 문자
* 공백, 문장 부호 등도 토큰 차지
* 줄바꿈 문자는 일반적으로 1개 토큰

{% hint style="info" %}
각 서비스 제공사의 토크나이저는 서로 다르며, 동일한 제공사 내 모델 간에도 차이가 있을 수 있습니다. 이 설명은 토큰 개념 이해를 위한 것입니다.
{% endhint %}

***

## 토크나이저(Tokenizer)란 무엇인가?

토크나이저는 텍스트를 토큰으로 변환하는 AI 모델의 도구로, 입력 텍스트를 모델이 이해할 수 있는 최소 단위로 분할하는 방식을 결정합니다.

### 왜 모델마다 토크나이저가 다를까?

#### 1. 훈련 데이터 차이
* 다른 코퍼스(말뭉치)에 따른 최적화 방향 차이
* 다국어 지원 수준 차이
* 의료/법률 등 특정 분야 최적화

#### 2. 분할 알고리즘 차이
* BPE (Byte Pair Encoding) - OpenAI GPT 시리즈
* WordPiece - Google BERT
* SentencePiece - 다국어 시나리오 적합

#### 3. 최적화 목표 차이
* 압축 효율성 중점 모델
* 의미 보존 중점 모델
* 처리 속도 중점 모델

### 실제 영향
동일한 텍스트도 모델별로 토큰 수가 다를 수 있습니다:

```
输入："Hello, world!"
GPT-3: 4 tokens
BERT: 3 tokens
Claude: 3 tokens
```

***

## 임베딩 모델(Embedding Model)이란 무엇인가?

**기본 개념:** 고차원 이산 데이터(텍스트/이미지 등)를 저차원 연속 벡터로 변환하는 기술로, 기계가 복잡한 데이터를 이해·처리하도록 돕습니다. 마치 복잡한 퍼즐을 핵심 특징을 보존한 단순 좌표점으로 변환하는 것과 같으며, AI 생태계에서는 인간의 정보를 AI가 계산 가능한 숫자 형태로 번역하는 "통역사" 역할을 합니다.

**작동 원리:** 자연어 처리 예시로, 단어를 벡터 공간의 특정 위치에 매핑하며 의미론적으로 유사한 단어끼리 자동으로 묶입니다:
* "国王"-"王后" 벡터 근접
* "猫"-"狗" 같은 반려동물 단어 근접
* "汽车"-"面包" 같은 무관계 단어는 원거리

**주요 적용 분야:**
* 텍스트 분석: 문서 분류, 감정 분석
* 추천 시스템: 개인화 콘텐츠 추천
* 이미지 처리: 유사 이미지 검색
* 검색 엔진: 의미 기반 검색 최적화

**핵심 이점:**
1. 차원 축소 효과: 복잡 데이터를 처리 가능한 벡터 형태로 단순화
2. 의미 보존: 원본 데이터의 핵심 의미 정보 보유
3. 계산 효율성: 기계학습 모델 훈련·추론 효율성 향상

**기술적 가치:** 현대 AI 시스템의 기초 구성 요소로, 자연어 처리·컴퓨터 비전 등 분야 발전을 위한 핵심 기술입니다.

***

## 지식 검색에서 임베딩 모델 작동 원리

**기본 작업 흐름:**

1. **지식 베이스 전처리 단계**
* 문서를 적절한 크기의 덩어리(Chunk)로 분할
* 임베딩 모델로 각 덩어리를 벡터로 변환
* 벡터와 원본 텍스트를 벡터 데이터베이스에 저장

2. **질의 처리 단계**
* 사용자 질문을 벡터로 변환
* 벡터 데이터베이스에서 유사 콘텐츠 검색
* 검색된 관련 콘텐츠를 LLM에 컨텍스트 제공

***

## MCP(Model Context Protocol)이란 무엇인가?

MCP는 대규모 언어 모델(LLM)에 표준화된 방식으로 컨텍스트 정보를 제공하는 오픈소스 프로토콜입니다.

* **비유적 이해:** AI 분야의 "USB 드라이브"로 상상할 수 있습니다. USB에 파일을 저장 후 컴퓨터 연결 시 바로 사용하듯, MCP 서버에 컨텍스트 제공 "플러그인"을 연결하면 LLM이 필요 시 해당 플러그인을 요청해 풍부한 컨텍스트를 획득합니다.
* **함수 도구와의 차이점:** 기존 함수 도구(Function Tool)도 외부 기능을 제공하지만, MCP는 더 높은 차원의 추상화입니다. 함수 도구는 특정 작업에 집중하고, MCP는 일반화된 모듈식 컨텍스트 획득 메커니즘을 제공합니다.

### **MCP의 핵심 이점**
1. **표준화:** 통일된 인터페이스·데이터 형식으로 다양한 LLM과 컨텍스트 제공자 간 원활한 협업 가능
2. **모듈화:** 컨텍스트 정보를 독립적 모듈(플러그인)로 분해해 관리·재사용 용이
3. **유연성:** LLM이 필요에 따라 동적으로 컨텍스트 플러그인을 선택해 더 스마트한 상호작용 가능
4. **확장성:** 향후 다양한 컨텍스트 플러그인 타입 추가 지원으로 LLM 역량 확장의 무한한 가능성 제공