---
icon: book-bookmark
---

{% hint style="warning" %}
यह दस्तावेज़ AI द्वारा चीनी से अनुवादित किया गया है और अभी तक इसकी समीक्षा नहीं की गई है।
{% endhint %}

# ज्ञान विज्ञान

## टोकन क्या हैं?

टोकन AI मॉडल द्वारा टेक्स्ट संसाधन की मूल इकाई हैं, जिन्हें मॉडल की "सोच" की सबसे छोटी इकाई समझा जा सकता है। यह हमारी समझ के अक्षर या शब्द के बिल्कुल बराबर नहीं है, बल्कि मॉडल द्वारा टेक्स्ट विभाजन की एक विशेष पद्धति है।

#### 1. चीनी टोकनाइजेशन
* एक चीनी वर्ण आमतौर पर 1-2 टोकन में एन्कोड होता है
* उदाहरण: `"你好"` ≈ 2-4 टोकन

#### 2. अंग्रेजी टोकनाइजेशन
* सामान्य शब्द आमतौर पर 1 टोकन होते हैं
* लंबे या असामान्य शब्द कई टोकन में विभाजित होते हैं
* उदाहरण:
  * `"hello"` = 1 टोकन
  * `"indescribable"` = 4 टोकन

#### 3. विशेष वर्ण
* रिक्त स्थान, विराम चिह्न आदि भी टोकन का उपयोग करते हैं
* न्यूलाइन वर्ण आमतौर पर 1 टोकन होता है

{% hint style="info" %}
विभिन्न सेवा प्रदाताओं के टोकनाइज़र भिन्न होते हैं, यहाँ तक कि एक ही प्रदाता के विभिन्न मॉडलों में भी अंतर हो सकता है। यह जानकारी केवल टोकन की अवधारणा को स्पष्ट करने के लिए है।
{% endhint %}

***

## टोकनाइज़र क्या है?

टोकनाइज़र (Tokenizer) AI मॉडल द्वारा टेक्स्ट को टोकन में परिवर्तित करने का उपकरण है। यह निर्धारित करता है कि इनपुट टेक्स्ट को मॉडल द्वारा समझे जा सकने वाली सबसे छोटी इकाइयों में कैसे विभाजित किया जाए।

### विभिन्न मॉडलों के टोकनाइज़र भिन्न क्यों होते हैं?

#### 1. प्रशिक्षण डेटा भिन्न होना
* विभिन्न कॉर्पोरा के कारण अनुकूलन दिशा भिन्न होती है
* बहुभाषी समर्थन स्तर में भिन्नता
* विशिष्ट डोमेन (चिकित्सा, कानून आदि) के लिए विशिष्ट अनुकूलन

#### 2. टोकनाइजेशन एल्गोरिदम भिन्न होना
* BPE (Byte Pair Encoding) - OpenAI GPT श्रृंखला
* WordPiece - Google BERT
* SentencePiece - बहुभाषी परिदृश्यों के लिए उपयुक्त

#### 3. अनुकूलन लक्ष्य भिन्न होना
* कुछ संपीड़न दक्षता पर ध्यान केंद्रित करते हैं
* कुछ अर्थ संरक्षण पर ध्यान देते हैं
* कुछ प्रसंस्करण गति पर ध्यान देते हैं

### व्यावहारिक प्रभाव
समान टेक्स्ट के विभिन्न मॉडलों में टोकन संख्या भिन्न हो सकती है:
```
输入："Hello, world!"
GPT-3: 4 tokens
BERT: 3 tokens
Claude: 3 tokens
```

***

## एम्बेडिंग मॉडल (Embedding Model) क्या है?

**मूल अवधारणा:** एम्बेडिंग मॉडल उच्च-आयामी असतत डेटा (टेक्स्ट, छवियाँ आदि) को निम्न-आयामी सतत वेक्टर में परिवर्तित करने की तकनीक है। यह रूपांतरण मशीनों को जटिल डेटा को बेहतर ढंग से समझने और प्रक्रिया करने में सक्षम बनाता है। इसे एक जटिल पहेली को सरल निर्देशांक बिंदु में सरलीकृत करने के समान समझें, जो पहेली की मुख्य विशेषताओं को बनाए रखता है। बड़े मॉडल पारिस्थितिकी तंत्र में, यह "दुभाषिया" के रूप में कार्य करता है जो मानव-समझने योग्य जानकारी को AI-गणनीय संख्यात्मक रूप में परिवर्तित करता है।

**कार्य सिद्धांत:** प्राकृतिक भाषा प्रसंस्करण के उदाहरण में, एम्बेडिंग मॉडल शब्दों को वेक्टर स्थान में विशिष्ट स्थानों पर मानचित्रित कर सकता है। इस स्थान में, शब्दार्थ रूप से समान शब्द स्वचालित रूप से समूहित हो जाते हैं। उदाहरण के लिए:
* "राजा" और "रानी" के वेक्टर अत्यंत निकट होंगे
* "बिल्ली" और "कुत्ता" जैसे पालतू शब्द भी निकट होंगे
* जबकि "कार" और "ब्रेड" जैसे असंबंधित शब्दार्थ वाले शब्द दूर होंगे

**मुख्य अनुप्रयोग परिदृश्य:**
* टेक्स्ट विश्लेषण: दस्तावेज़ वर्गीकरण, भावना विश्लेषण
* सिफारिश प्रणालियाँ: व्यक्तिगत सामग्री सुझाव
* छवि प्रसंस्करण: समान छवि खोज
* खोज इंजन: अर्थ-आधारित खोज अनुकूलन

**केंद्रीय लाभ:**
1. आयाम घटाने का प्रभाव: जटिल डेटा को प्रबंधनीय वेक्टर रूप में सरलीकृत करता है
2. अर्थ संरक्षण: मूल डेटा में महत्वपूर्ण अर्थपूर्ण जानकारी बनाए रखता है
3. गणनात्मक दक्षता: मशीन लर्निंग मॉडल के प्रशिक्षण और अनुमान में उल्लेखनीय सुधार करता है

**तकनीकी मूल्य:** एम्बेडिंग मॉडल आधुनिक AI प्रणालियों का एक मूलभूत घटक है, जो मशीन लर्निंग कार्यों को उच्च-गुणवत्ता वाला डेटा प्रतिनिधित्व प्रदान करता है और प्राकृतिक भाषा प्रसंस्करण, कंप्यूटर विज़न जैसे क्षेत्रों में विकास को आगे बढ़ाने के लिए एक प्रमुख तकनीक है।

***

## ज्ञान पुनर्प्राप्ति में एम्बेडिंग मॉडल का कार्य सिद्धांत

**मूल कार्य प्रवाह:**

1. **ज्ञान आधार पूर्व-प्रसंस्करण चरण**
   * दस्तावेज़ों को उपयुक्त आकार के चंक्स (पाठ खंडों) में विभाजित करें
   * प्रत्येक चंक को एम्बेडिंग मॉडल का उपयोग करके वेक्टर में परिवर्तित करें
   * वेक्टर और मूल पाठ को वेक्टर डेटाबेस में संग्रहीत करें

2. **क्वेरी प्रसंस्करण चरण**
   * उपयोगकर्ता प्रश्न को वेक्टर में परिवर्तित करें
   * वेक्टर डेटाबेस में समान सामग्री खोजें
   * पुनर्प्राप्त की गई प्रासंगिक सामग्री को LLM को संदर्भ के रूप में प्रदान करें

***

## **MCP (मॉडल संदर्भ प्रोटोकॉल) क्या है?**

MCP एक ओपन-सोर्स प्रोटोकॉल है जिसका उद्देश्य बड़े भाषा मॉडल (LLM) को मानकीकृत तरीके से संदर्भ जानकारी प्रदान करना है।

* **सादृश्य समझ:** MCP को AI क्षेत्र का "USB ड्राइव" समझा जा सकता है। जैसे USB ड्राइव विभिन्न फ़ाइलें संग्रहीत करता है और कंप्यूटर से कनेक्ट होने पर सीधे उपयोग में आता है, वैसे ही MCP सर्वर पर संदर्भ प्रदान करने वाले "प्लगइन्स" जोड़े जा सकते हैं। LLM आवश्यकतानुसार इन प्लगइन्स का उपयोग कर अधिक समृद्ध संदर्भ जानकारी प्राप्त कर अपनी क्षमताओं को बढ़ा सकते हैं।
* **फ़ंक्शन टूल से तुलना:** पारंपरिक फ़ंक्शन टूल भी LLM को बाहरी कार्यक्षमता प्रदान कर सकते हैं, लेकिन MCP एक उच्च-स्तरीय अमूर्तन है। फ़ंक्शन टूल विशिष्ट कार्यों के लिए अधिक होते हैं, जबकि MCP एक अधिक सामान्य, मॉड्यूलर संदर्भ प्राप्ति तंत्र प्रदान करता है।

### **MCP के मुख्य लाभ**

1. **मानकीकरण:** MCP एकीकृत इंटरफेस और डेटा प्रारूप प्रदान करता है, जिससे विभिन्न LLM और संदर्भ प्रदाता सहज सहयोग कर सकते हैं।
2. **मॉड्यूलरिटी:** डेवलपर्स संदर्भ जानकारी को स्वतंत्र मॉड्यूल (प्लगइन्स) में व्यवस्थित कर सकते हैं, जिससे प्रबंधन और पुन:उपयोग सुविधाजनक होता है।
3. **लचीलापन:** LLM अपनी आवश्यकताओं के अनुसार गतिशील रूप से संदर्भ प्लगइन्स चुन सकते हैं, जिससे अधिक बुद्धिमान और व्यक्तिगत इंटरैक्शन संभव होता है।
4. **विस्तारशीलता:** MCP का डिज़ाइन भविष्य में अधिक प्रकार के संदर्भ प्लगइन्स जोड़ने का समर्थन करता है, जो LLM क्षमताओं के विस्तार के लिए असीम संभावनाएँ प्रदान करता है।

***