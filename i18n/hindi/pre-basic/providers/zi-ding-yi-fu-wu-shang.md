
{% hint style="warning" %}
यह दस्तावेज़ AI द्वारा चीनी से अनुवादित किया गया है और अभी तक इसकी समीक्षा नहीं की गई है।
{% endhint %}

# कस्टम प्रदाता

Cherry Studio न केवल प्रमुख AI मॉडल सेवाओं को एकीकृत करता है, बल्कि आपको शक्तिशाली अनुकूलन क्षमता भी प्रदान करता है। **कस्टम AI सेवा प्रदाता** फीचर के माध्यम से, आप आसानी से किसी भी वांछित AI मॉडल को जोड़ सकते हैं।

## कस्टम AI प्रदाता की आवश्यकता क्यों है?

* **लचीलापन:** पूर्व-निर्धारित प्रदाता सूची से सीमित न रहें, अपनी आवश्यकताओं के लिए सबसे उपयुक्त AI मॉडल स्वतंत्र रूप से चुनें।
* **विविधता:** विभिन्न प्लेटफॉर्म्स पर उपलब्ध AI मॉडल्स को आज़माएँ और उनके अनूठे लाभों का पता लगाएँ।
* **नियंत्रण क्षमता:** अपनी API कुंजियाँ और एक्सेस एड्रेस का सीधे प्रबंधन करें, सुरक्षा और गोपनीयता सुनिश्चित करें।
* **अनुकूलन:** विशिष्ट व्यावसायिक आवश्यकताओं के लिए निजीकृत रूप से डिप्लॉय किए गए मॉडल्स को जोड़ें।

## कस्टम AI प्रदाता कैसे जोड़ें?

केवल कुछ सरल चरणों में, Cherry Studio में अपना कस्टम AI प्रदाता जोड़ें:

<figure><img src="../../.gitbook/assets/image (2) (5).png" alt=""><figcaption></figcaption></figure>

1. **सेटिंग खोलें:** Cherry Studio इंटरफ़ेस के लेफ्ट-साइड नेविगेशन बार में "सेटिंग्स" (गियर आइकन) पर क्लिक करें।
2. **मॉडल सेवाएँ पर जाएँ:** सेटिंग्स पेज में "मॉडल सेवाएँ" टैब चुनें।
3. **प्रदाता जोड़ें:** "मॉडल सेवाएँ" पेज पर, मौजूदा प्रदाताओं की सूची में "+ जोड़ें" बटन पर क्लिक करके "प्रदाता जोड़ें" पॉपअप खोलें।
4. **जानकारी भरें:** पॉपअप में निम्नलिखित विवरण प्रदान करें:
   * **प्रदाता नाम:** अपने कस्टम प्रदाता के लिए एक पहचानने योग्य नाम (जैसे: MyCustomOpenAI)
   * **प्रदाता प्रकार:** ड्रॉपडाउन से प्रदाता का प्रकार चुनें। वर्तमान में समर्थित हैं:
     * OpenAI
     * Gemini
     * Anthropic
     * Azure OpenAI
5. **कॉन्फ़िगरेशन सहेजें:** विवरण भरने के बाद "जोड़ें" बटन पर क्लिक करें।

## कस्टम AI प्रदाता कॉन्फ़िगर करना

<figure><img src="../../.gitbook/assets/image (3) (5) (1).png" alt=""><figcaption></figcaption></figure>

जोड़ने के बाद, सूची में अपने नए प्रदाता को खोजकर विस्तृत कॉन्फ़िगरेशन करें:

1. **सक्रिय स्थिति:** प्रदाता सूची के सबसे दाईं ओर टॉगल स्विच है - इसे चालू करने पर यह सेवा सक्रिय होगी।
2. **API कुंजी:**
   * अपने AI प्रदाता से प्राप्त API कुंजी भरें
   * कुंजी की वैधता जांचने के लिए दाईं ओर "जाँचें" बटन का उपयोग करें
3. **API एड्रेस:**
   * AI सेवा का आधार URL (Base URL) एंटर करें
   * सही API एड्रेस के लिए अपने AI प्रदाता की आधिकारिक डॉक्यूमेंटेशन देखना सुनिश्चित करें
4. **मॉडल प्रबंधन:**
   * "+ जोड़ें" बटन पर क्लिक करके इस प्रदाता के तहत उपयोग किए जाने वाले मॉडल ID मैन्युअल रूप से एंटर करें, जैसे `gpt-3.5-turbo`, `gemini-pro` आदि।
   
   <figure><img src="../../.gitbook/assets/image (4) (5).png" alt=""><figcaption></figcaption></figure>
   
   * सटीक मॉडल नाम के लिए अपने AI प्रदाता की आधिकारिक डॉक्यूमेंटेशन देखें
   * पहले से जोड़े गए मॉडल्स को संपादित या हटाने के लिए "प्रबंधित करें" बटन का उपयोग करें

## उपयोग शुरू करें

उपरोक्त कॉन्फ़िगरेशन पूरा करने के बाद, Cherry Studio के चैट इंटरफ़ेस में अपने कस्टम AI प्रदाता और मॉडल का चयन करके AI के साथ बातचीत शुरू कर सकते हैं!

## कस्टम AI प्रदाता के रूप में vLLM का उपयोग

vLLM एक तेज़ और उपयोग में आसान LLM इंफरेंस लाइब्रेरी है, जो Ollama के समान है। इसे Cherry Studio में इंटीग्रेट करने के चरण:

1. **vLLM स्थापित करें:** vLLM की आधिकारिक डॉक्यूमेंटेशन ([https://docs.vllm.ai/en/latest/getting_started/quickstart.html](https://docs.vllm.ai/en/latest/getting_started/quickstart.html)) के अनुसार इंस्टॉल करें

   ```sh
   pip install vllm # pip के लिए
   uv pip install vllm # uv के लिए
   ```
2. **vLLM सेवा शुरू करें:** vLLM के OpenAI-संगत इंटरफ़ेस का उपयोग करें। दो प्रमुख तरीके:
   
   * `vllm.entrypoints.openai.api_server` का उपयोग करके:
   ```sh
   python -m vllm.entrypoints.openai.api_server --model gpt2
   ```
   
   * `uvicorn` का उपयोग करके:
   ```sh
   vllm --model gpt2 --served-model-name gpt2
   ```
   
   सुनिश्चित करें कि सेवा सफलतापूर्वक डिफ़ॉल्ट पोर्ट `8000` पर चल रही हो। आप `--port` पैरामीटर से पोर्ट निर्दिष्ट कर सकते हैं।

3. **Cherry Studio में vLLM प्रदाता जोड़ें:**
   * ऊपर दिए गए चरणों का पालन करके एक नया कस्टम AI प्रदाता जोड़ें
   * **प्रदाता नाम:** `vLLM`
   * **प्रदाता प्रकार:** `OpenAI` चुनें
4. **vLLM प्रदाता कॉन्फ़िगर करें:**
   * **API कुंजी:** खाली छोड़ें या कोई मनचाहा टेक्स्ट एंटर करें (vLLM को API कुंजी की आवश्यकता नहीं)
   * **API एड्रेस:** vLLM सेवा का API एड्रेस, डिफ़ॉल्ट रूप से `http://localhost:8000/` (पोर्ट बदलने पर संबंधित URL दें)
   * **मॉडल प्रबंधन:** vLLM में लोड किए गए मॉडल का नाम दर्ज करें। उदाहरण के लिए, यदि आपने `python -m vllm.entrypoints.openai.api_server --model gpt2` चलाया है, तो `gpt2` एंटर करें
5. **बातचीत शुरू करें:** अब आप Cherry Studio में vLLM प्रदाता और `gpt2` मॉडल चुनकर vLLM-पावर्ड LLM के साथ बातचीत कर सकते हैं!

## सुझाव और टिप्स

* **डॉक्यूमेंटेशन ध्यान से पढ़ें:** कस्टम प्रदाता जोड़ने से पहले अपने AI प्रदाता की आधिकारिक डॉक्यूमेंटेशन में API कुंजी, एक्सेस एड्रेस, मॉडल नाम आदि जानकारी जाँचें।
* **API कुंजी जाँचें:** "जाँचें" बटन से कुंजी की वैधता का त्वरित सत्यापन करके त्रुटियों से बचें।
* **API एड्रेस पर ध्यान दें:** विभिन्न AI प्रदाताओं और मॉडल्स के लिए API एड्रेस अलग-अलग हो सकते हैं।
* **केवल ज़रूरी मॉडल जोड़ें:** केवल वास्तव में उपयोग किए जाने वाले मॉडल्स ही जोड़ें, अनावश्यक मॉडल्स जोड़ने से बचें।