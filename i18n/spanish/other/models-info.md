
{% hint style="warning" %}
Este documento ha sido traducido del chino por IA y aún no ha sido revisado.
{% endhint %}

# Información de Referencia de Modelos Comunes

{% hint style="info" %}
* La siguiente información es solo de referencia. Si se detectan errores, pueden reportarse para su corrección. Algunos modelos pueden variar en tamaño de contexto y detalles según el proveedor de servicio.
* Al introducir datos en el cliente, es necesario convertir "k" a valores reales (teóricamente 1k = 1024 tokens; 1m = 1024k tokens). Por ejemplo, 8k sería 8 × 1024 = 8192 tokens. Se recomienda multiplicar por 1000 en uso práctico para evitar errores (ej. 8k = 8 × 1000 = 8000, 1m = 1 × 1000000 = 1000000).
* Los modelos marcados con "–" en "Máxima Salida" indican que no se encontró información oficial explícita sobre este límite.
{% endhint %}

<table><thead><tr><th width="313">Nombre del Modelo</th><th width="158">Entrada Máxima</th><th width="72">Salida Máxima</th><th width="95">Llamada de Función</th><th width="142">Capacidad del Modelo</th><th width="540">Proveedor</th><th width="257">Descripción</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>No compatible</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo líder de billones de parámetros de la serie 360 Brain, ampliamente aplicable a escenarios complejos en diversos campos.</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>No compatible</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo de decenas de billones que equilibra rendimiento y eficacia, ideal para escenarios con altos requisitos de rendimiento/costo.</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>No compatible</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo de decenas de billones que equilibra rendimiento y eficacia, ideal para escenarios con altos requisitos de rendimiento/costo.</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>No compatible</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo líder de billones de parámetros de la serie 360 Brain, ampliamente aplicable a escenarios complejos en diversos campos.</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Anthropic_claude</td><td>Versión de snapshot lanzada el 20/06/2024. Claude 3.5 Sonnet es un modelo equilibrado en rendimiento y velocidad que ofrece máximo rendimiento manteniendo alta velocidad, compatible con entrada multimodal.</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>No compatible</td><td>Diálogo</td><td>Anthropic_claude</td><td>Versión de snapshot lanzada el 22/10/2024. Claude 3.5 Haiku muestra mejoras en habilidades como programación, uso de herramientas y razonamiento. Como modelo más rápido de Anthropic, ofrece tiempos de respuesta rápidos, ideal para aplicaciones de alta interacción como chatbots orientados al usuario y autocompletado de código. También sobresale en tareas especializadas como extracción de datos y moderación de contenido en tiempo real. No admite entrada de imágenes.</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Anthropic_claude</td><td>Versión de snapshot lanzada el 22/10/2024. Claude 3.5 Sonnet supera las capacidades de Opus con mayor velocidad que Sonnet, manteniendo mismo precio. Destaca especialmente en programación, ciencia de datos, procesamiento visual y tareas de agentes.</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Anthropic_claude</td><td>Apunta dinámicamente a la última versión Claude 3.5 Sonnet. Ofrece capacidades superiores a Opus con mayor velocidad que Sonnet, manteniendo mismo precio. Destaca en programación, ciencia de datos, procesamiento visual y tareas de agentes. Apunta a la última versión.</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Anthropic_claude</td><td>Claude 3 Haiku es el modelo más rápido y compacto de Anthropic, diseñado para respuestas casi instantáneas. Ofrece alto rendimiento dirigido con precisión.</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Anthropic_claude</td><td>Claude 3 Opus es el modelo más potente de Anthropic para tareas altamente complejas. Destaca en rendimiento, inteligencia, fluidez y comprensión.</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Anthropic_claude</td><td>Versión de snapshot lanzada el 29/02/2024. Sonnet destaca especialmente en:<br><br>- Programación: Capaz de escribir, editar y ejecutar código autónomamente con habilidades de razonamiento y solución de problemas<br>- Ciencia de datos: Mejora la experiencia humana en ciencia de datos; maneja datos no estructurados usando múltiples herramientas para obtener información<br>- Procesamiento visual: Excelente interpretando gráficos, diagramas e imágenes, transcribiendo texto para obtener información más allá del texto mismo<br>- Tareas de agente: Uso sobresaliente de herramientas, ideal para tareas de agente (resolución compleja de problemas de múltiples pasos que requieren interactuar con otros sistemas)</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>No compatible</td><td>Diálogo</td><td>Google_gamma</td><td>Gemma es una familia de modelos abiertos ligeros y de vanguardia desarrollada por Google, utilizando la misma investigación y tecnología que los modelos Gemini. Estos modelos decodificadores son grandes modelos de lenguaje que admiten inglés, con variantes de pesos abiertos preentrenados y ajustados por instrucciones. Los modelos Gemma son adecuados para varias tareas de generación de texto, incluyendo preguntas-respuestas, resúmenes y razonamiento.</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>No compatible</td><td>Diálogo</td><td>Google_gamma</td><td>Gemma es una de las familias de modelos abiertos ligeras y de vanguardia desarrolladas por Google. Es un modelo decodificador de gran lenguaje que admite inglés, con pesos abiertos, variantes preentrenadas y ajustadas por instrucciones. Los modelos Gemma son adecuados para varias tareas de generación de texto, incluyendo preguntas-respuestas, resúmenes y razonamiento. Este modelo de 9B se entrenó con 8 billones de tokens.</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>No compatible</td><td>Diálogo</td><td>Google_gemini</td><td>Última versión estable de Gemini 1.5 Pro. Modelo multimodal potente que maneja hasta 60k líneas de código o 2,000 páginas de texto. Ideal para tareas que requieren razonamiento complejo.</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>No compatible</td><td>Diálogo</td><td>Google_gemini</td><td>Versión estable de Gemini 1.0 Pro. Modelo NLP especializado en chats de texto/código multironda y generación de código. Se desactivará el 15/02/2025, se recomienda migrar a modelos de la serie 1.5.</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>No compatible</td><td>Diálogo</td><td>Google_gemini</td><td>Versión estable de Gemini 1.0 Pro. Modelo NLP especializado en chats de texto/código multironda y generación de código. Se desactivará el 15/02/2025, se recomienda migrar a modelos de la serie 1.5.</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>No compatible</td><td>Diálogo, Obsoleto o próximo a obsoleto</td><td>Google_gemini</td><td>Última versión de Gemini 1.0 Pro. Modelo NLP especializado en chats de texto/código multironda y generación de código. Se desactivará el 15/02/2025, se recomienda migrar a modelos de la serie 1.5.</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>No compatible</td><td>Diálogo</td><td>Google_gemini</td><td>Versión visual de Gemini 1.0 Pro. Se desactivará el 15/02/2025, se recomienda migrar a modelos de la serie 1.5.</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>No compatible</td><td>Reconocimiento visual</td><td>Google_gemini</td><td>Última versión visual de Gemini 1.0 Pro. Se desactivará el 15/02/2025, se recomienda migrar a modelos de la serie 1.5.</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Última versión estable de Gemini 1.5 Flash. Modelo multimodal equilibrado que maneja entradas de audio, imágenes, video y texto.</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión estable de Gemini 1.5 Flash. Ofrece las mismas funciones básicas que gemini-1.5-flash, pero con versión fija, ideal para entornos de producción.</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión estable de Gemini 1.5 Flash. Ofrece las mismas funciones básicas que gemini-1.5-flash, pero con versión fija, ideal para entornos de producción.</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Gemini 1.5 Flash-8B es el último modelo multimodal de IA de Google, diseñado para manejar tareas a gran escala de manera eficiente. Con 8 mil millones de parámetros, admite entrada de texto, imágenes, audio y video, aplicable en múltiples escenarios como chatbots, transcripción y traducción. Optimizado para velocidad y rentabilidad, ofrece el doble de límite de tasa, permitiendo a los desarrolladores procesar tareas a gran escala de manera eficiente. También utiliza técnicas de "distilación de conocimiento" para garantizar capacidades esenciales manteniendo ligereza y eficiencia.</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión experimental de Gemini 1.5 Flash que se actualiza periódicamente con las últimas mejoras. Ideal para pruebas exploratorias y desarrollo de prototipos, no recomendado para producción.</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión de vanguardia de Gemini 1.5 Flash que se actualiza periódicamente con las últimas mejoras. Ideal para pruebas exploratorias y desarrollo de prototipos, no recomendado para producción.</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión estable de Gemini 1.5 Pro con comportamiento y características fijas. Ideal para producción donde se requiere estabilidad.</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión estable de Gemini 1.5 Pro con comportamiento y características fijas. Ideal para producción donde se requiere estabilidad.</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión experimental de Gemini 1.5 Pro. Modelo multimodal potente que maneja hasta 60k líneas de código o 2,000 páginas de texto. Ideal para tareas que requieren razonamiento complejo.</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Versión experimental de Gemini 1.5 Pro. Modelo multimodal potente que maneja hasta 60k líneas de código o 2,000 páginas de texto. Ideal para tareas que requieren razonamiento complejo.</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Última versión de Gemini 1.5 Pro, apunta dinámicamente a la última snapshot</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>No compatible</td><td>Diálogo, Reconocimiento visual</td><td>Google_gemini</td><td>Gemini 2.0 Flash es el último modelo de Google, que ofrece mayor velocidad inicial que la versión 1.5 manteniendo calidad comparable; mejora en comprensión multimodal, habilidades de codificación, ejecución de instrucciones complejas y llamadas a funciones, proporcionando una experiencia de IA más fluida y potente.</td></tr><tr><td>