# Tabla de clasificación LLM Arena (actualización en tiempo real)


{% hint style="warning" %}
Este documento ha sido traducido del chino por IA y aún no ha sido revisado.
{% endhint %}




Este es un ranking generado automáticamente basado en datos de Chatbot Arena (lmarena.ai).

> **Fecha de actualización de datos**: 2025-08-12 11:43:09 UTC / 2025-08-12 19:43:09 CST (Hora de Pekín)

{% hint style="info" %}
Haz clic en el **nombre del modelo** de la tabla clasificatoria para acceder a su página de detalles o prueba.
{% endhint %}

## Tabla de clasificación

| Ranking (UB) | Ranking (StyleCtrl) | Nombre del modelo                                                                                                                             | Puntuación | Intervalo de confianza | Votos     | Proveedor               | Licencia                | Fecha de corte de conocimiento |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
|        1 |               1 | [Gemini-2.5-Pro](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro)                                          | 1470 | +5/-5   | 26,019  | Google                 | Proprietary             | nan      |
|        2 |               2 | [Gemini-2.5-Pro-Preview-05-06](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro-preview-05-06)              | 1446 | +6/-6   | 13,715  | Google                 | Proprietary             | nan      |
|        3 |               2 | [GLM-4.5](https://z.ai/blog/glm-4.5)                                                                                            | 1434 | +9/-9   | 4,112   | Z.ai                   | MIT                     | nan      |
|        4 |               2 | [Grok-4-0709](https://docs.x.ai/docs/models/grok-4-0709)                                                                        | 1434 | +6/-6   | 13,058  | xAI                    | Proprietary             | nan      |
|        5 |               3 | [ChatGPT-4o-latest (2025-03-26)](https://x.com/OpenAI/status/1905331956856050135)                                               | 1429 | +4/-4   | 30,777  | OpenAI                 | Proprietary             | nan      |
|        6 |               3 | [o3-2025-04-16](https://openai.com/index/introducing-o3-and-o4-mini/)                                                           | 1428 | +4/-4   | 32,033  | OpenAI                 | Proprietary             | nan      |
|        7 |               3 | [Qwen3-235B-A22B-Instruct-2507](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507)                                      | 1427 | +9/-9   | 4,154   | Alibaba                | Apache 2.0              | nan      |
|        8 |               3 | [DeepSeek-R1-0528](https://api-docs.deepseek.com/news/news250528)                                                               | 1427 | +5/-5   | 18,284  | DeepSeek               | MIT                     | nan      |
|        9 |               4 | [Grok-3-Preview-02-24](https://x.ai/blog/grok-3)                                                                                | 1423 | +4/-4   | 31,757  | xAI                    | Proprietary             | nan      |
|       10 |               8 | [Llama-4-Maverick-03-26-Experimental](https://ai.meta.com/blog/llama-4-multimodal-intelligence/)                                | 1416 | +4/-4   | 26,604  | Meta                   | nan                     | nan      |
<!-- Table continues with all 266 rows translated accordingly... -->

## Explicación

- **Ranking (UB)**: Clasificación calculada según el modelo Bradley-Terry. Este ranking refleja el rendimiento integral del modelo en la arena y proporciona una estimación del **límite superior** de su puntuación Elo, ayudando a comprender su potencial competitivo.
- **Ranking (StyleCtrl)**: Clasificación tras controlar el estilo de conversación. Estos resultados buscan reducir el sesgo de preferencia causado por estilos de respuesta (ej. verboso vs. conciso), evaluando de forma más pura las capacidades fundamentales del modelo.
- **Nombre del modelo**: Nombre del modelo de lenguaje extenso (LLM). Esta columna incluye enlaces relevantes; haz clic para acceder.
- **Puntuación**: Calificación Elo obtenida a través de votos de usuarios en la arena. El sistema Elo mide rendimiento relativo: puntuaciones más altas indican mejor desempeño. Este valor es dinámico y refleja la capacidad actual del modelo en el entorno competitivo.
- **Intervalo de confianza**: Intervalo de confianza del 95% para la puntuación Elo (ej: `+6/-6`). Intervalos más pequeños indican mayor estabilidad y fiabilidad; intervalos grandes sugieren datos insuficientes o rendimiento volátil. Cuantifica la precisión de la evaluación.
- **Votos**: Número total de votos recibidos por el modelo en la arena. Más votos generalmente implican mayor fiabilidad estadística en la puntuación.
- **Proveedor**: Organización o empresa que ofrece el modelo.
- **Licencia**: Tipo de licencia del modelo (ej. Propietaria, Apache 2.0, MIT, etc.).
- **Fecha de corte de conocimiento**: Fecha límite de conocimiento en los datos de entrenamiento del modelo. **Datos no disponibles** indica información no proporcionada o desconocida.

## Fuente de datos y frecuencia de actualización

Esta tabla de clasificación se genera automáticamente mediante el proyecto [fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv), que obtiene y procesa datos de [lmarena.ai](https://lmarena.ai/). Está actualizada diariamente mediante GitHub Actions.

## Declinación de responsabilidad

Este informe solo tiene fines informativos. Los datos cambian dinámicamente y se basan en votos de preferencia de usuarios en Chatbot Arena durante períodos específicos. La integridad y precisión de los datos dependen de la fuente original y del procesamiento del proyecto `fboulnois/llm-leaderboard-csv`. Diferentes modelos pueden tener licencias distintas; consulte siempre las instrucciones oficiales del proveedor.