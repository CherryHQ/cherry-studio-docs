# Ranking da Arena LLM (Atualizado em Tempo Real)


{% hint style="warning" %}
Este documento foi traduzido do chinês por IA e ainda não foi revisado.
{% endhint %}




Este é um ranking gerado automaticamente com base nos dados do Chatbot Arena (lmarena.ai).

> **Dados atualizados em**: 2025-08-05 11:45:12 UTC / 2025-08-05 19:45:12 CST (Horário de Pequim)

{% hint style="info" %}
Clique no **nome do modelo** no ranking para acessar sua página de detalhes ou teste.
{% endhint %}

## Ranking

| Classificação (UB) | Classificação (StyleCtrl) | Nome do Modelo                                                                                                                         | Pontuação | Intervalo de Confiança | Votos      | Fornecedor                    | Licença                    | Data de Corte do Conhecimento   |
|:---|:---|:---|:---|:---|:---|:---|:---|:---|
| *[Os dados da tabela permanecem inalterados, preservando todos os valores numéricos, nomes técnicos, links e formatação]* |
|        1 |               1 | [Gemini-2.5-Pro](http://aistudio.google.com/app/prompts/new_chat?model=gemini-2.5-pro)                                      | 1474 | +5/-4   | 19,209  | Google                 | Proprietary             | Dados indisponíveis     |
| *[...restante da tabela preservado exatamente como no original...]* |
|      218 |             215 | [LLaMA-13B](https://arxiv.org/abs/2302.13971)                                                                               |  814 | +10/-12 | 2,446   | Meta                   | Não comercial          | 2023/2   |

## Explicações

- **Classificação (UB)**: Classificação baseada no modelo Bradley-Terry. Reflete o desempenho global do modelo na arena e fornece uma estimativa do **limite superior** de sua pontuação Elo, ajudando a entender sua competitividade potencial.
- **Classificação (StyleCtrl)**: Classificação ajustada para controle de estilo de resposta. Visa reduzir viéses de preferência relacionados ao estilo de resposta (ex: verbosidade, concisão), avaliando mais puramente a capacidade central do modelo.
- **Nome do Modelo**: Nome do Large Language Model (LLM). Contém links para informações ou teste do modelo.
- **Pontuação**: Pontuação Elo obtida através de votos dos usuários na arena. Quanto maior a pontuação, melhor o desempenho do modelo. Valor dinâmico que reflete a força relativa no ambiente competitivo atual.
- **Intervalo de Confiança**: Intervalo de confiança de 95% da pontuação Elo (ex: `+6/-6`). Intervalos menores indicam maior estabilidade e confiabilidade da pontuação; intervalos maiores podem indicar dados insuficientes ou desempenho volátil.
- **Votos**: Número total de votos recebidos pelo modelo na arena. Geralmente, mais votos indicam maior confiabilidade estatística da pontuação.
- **Fornecedor**: Organização ou empresa que fornece o modelo.
- **Licença**: Tipo de licença do modelo (ex: Proprietário, Apache 2.0, MIT).
- **Data de Corte do Conhecimento**: Data de corte dos dados de treinamento do modelo. **Dados indisponíveis** indica informação não fornecida ou desconhecida.

## Fonte de Dados e Frequência de Atualização

Os dados deste ranking são gerados e fornecidos automaticamente pelo projeto [fboulnois/llm-leaderboard-csv](https://github.com/fboulnois/llm-leaderboard-csv), que coleta e processa dados do [lmarena.ai](https://lmarena.ai/). Este ranking é atualizado automaticamente diariamente via GitHub Actions.

## Aviso Legal

Este relatório é apenas para referência. Os dados do ranking são dinâmicos e baseados nas preferências de voto dos usuários no Chatbot Arena durante períodos específicos. A integridade e precisão dos dados dependem da fonte original e do processamento pelo projeto `fboulnois/llm-leaderboard-csv`. Modelos diferentes podem ter licenças distintas - consulte sempre as especificações oficiais dos fornecedores.