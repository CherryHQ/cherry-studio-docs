# Informações de Referência Comuns de Modelos


{% hint style="warning" %}
Este documento foi traduzido do chinês por IA e ainda não foi revisado.
{% endhint %}




{% hint style="info" %}
* As informações a seguir são apenas para referência; se houver erros, entre em contato para correção. Alguns modelos podem ter tamanho de contexto e informações diferentes dependendo do fornecedor.
* Ao inserir dados no cliente, é necessário converter "k" para valor real (teoricamente 1k = 1024 tokens; 1m = 1024k tokens). Exemplo: 8k = 8×1024 = 8192 tokens. Recomenda-se multiplicar por 1000 no uso prático para evitar erros, por exemplo: 8k = 8×1000 = 8000, 1m = 1×1000000 = 1000000.
* Os modelos marcados com "-" em "Saída Máxima" indicam que não foi encontrada informação oficial clara sobre o limite máximo de saída.
{% endhint %}

<table><thead><tr><th width="313">Nome do Modelo</th><th width="158">Entrada Máxima</th><th width="72">Saída Máxima</th><th width="95">Chamada de Função</th><th width="142">Capacidades do Modelo</th><th width="540">Fornecedor</th><th width="257">Descrição</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>Não suportado</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo principal de bilhões de parâmetros com melhor desempenho da série 360 Brain, amplamente aplicável em cenários complexos de diversas áreas.</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>Não suportado</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo de bilhões de parâmetros que equilibra desempenho e eficiência, adequado para cenários com altos requisitos de desempenho/custo.</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>Não suportado</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo de bilhões de parâmetros que equilibra desempenho e eficiência, adequado para cenários com altos requisitos de desempenho/custo.</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>Não suportado</td><td>Diálogo</td><td>360AI_360gpt</td><td>Modelo principal de bilhões de parâmetros com melhor desempenho da série 360 Brain, amplamente aplicável em cenários complexos de diversas áreas.</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Anthropic_claude</td><td>Versão snapshot lançada em 20/06/2024. Claude 3.5 Sonnet equilibra desempenho e velocidade, oferecendo desempenho de ponta enquanto mantém alta velocidade, com suporte a entrada multimodal.</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>Não suportado</td><td>Diálogo</td><td>Anthropic_claude</td><td>Versão snapshot lançada em 22/10/2024. Claude 3.5 Haiku apresenta melhorias em todas as habilidades, incluindo codificação, uso de ferramentas e raciocínio. Como o modelo mais rápido da série Anthropic, oferece tempos de resposta rápidos, adequado para aplicações de alta interatividade e baixa latência, como chatbots voltados para usuários e preenchimento de código em tempo real. Destaca-se em tarefas profissionais como extração de dados e moderação de conteúdo em tempo real. Não suporta entrada de imagens.</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Anthropic_claude</td><td>Versão snapshot lançada em 22/10/2024. Claude 3.5 Sonnet supera o Opus em capacidade e é mais rápido que o Sonnet, mantendo o mesmo preço. Excelente em programação, ciência de dados, processamento visual e tarefas de agente.</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Anthropic_claude</td><td>Versão mais recente do Claude 3.5 Sonnet. Oferece desempenho superior ao Opus com velocidade maior que o Sonnet, mantendo o mesmo preço. Excelente em programação, ciência de dados, processamento visual e tarefas de agente.</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Anthropic_claude</td><td>Claude 3 Haiku é o modelo mais rápido e compacto da Anthropic, projetado para respostas quase instantâneas. Possui desempenho direcionado rápido e preciso.</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Anthropic_claude</td><td>Claude 3 Opus é o modelo mais poderoso da Anthropic para tarefas altamente complexas. Excelente em desempenho, inteligência, fluência e compreensão.</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Anthropic_claude</td><td>Versão snapshot lançada em 29/02/2024. O Sonnet destaca-se especialmente em:<br><br>- Codificação: Capacidade autônoma de escrever, editar e executar código, com habilidades de raciocínio e solução de problemas<br>- Ciência de dados: Aprimora a expertise humana; processa dados não estruturados ao usar múltiplas ferramentas para insights<br>- Processamento visual: Excelente em interpretar gráficos, diagramas e imagens<br>- Tarefas de agente: Uso excepcional de ferramentas, ideal para tarefas de agente (problemas complexos em múltiplas etapas que exigem interação com outros sistemas)</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>Não suportado</td><td>Diálogo</td><td>Google_gamma</td><td>Gemma é uma família de modelos leves e de última geração desenvolvida pelo Google, construída com a mesma pesquisa e tecnologia usada nos modelos Gemini. Modelos de linguagem apenas decodificadores, suportam inglês e oferecem pesos abertos em variantes pré-treinadas e ajustadas por instrução. Adequados para várias tarefas de geração de texto.</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>Não suportado</td><td>Diálogo</td><td>Google_gamma</td><td>Família de modelos leves e de última geração do Google. Modelo de linguagem apenas decodificador com suporte a inglês e pesos abertos. Adequado para tarefas de geração de texto. Treinado com 8 trilhões de tokens.</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>Não suportado</td><td>Diálogo</td><td>Google_gemini</td><td>Versão estável mais recente do Gemini 1.5 Pro. Modelo multimodal poderoso que processa até 60k linhas de código ou 2k páginas de texto. Ideal para tarefas que exigem raciocínio complexo.</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>Não suportado</td><td>Diálogo</td><td>Google_gemini</td><td>Versão estável do Gemini 1.0 Pro. Modelo NLP especializado em bate-papo com texto/código e geração de código. Será desativado em 15/02/2025. Migre para série 1.5.</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>Não suportado</td><td>Diálogo</td><td>Google_gemini</td><td>Versão estável do Gemini 1.0 Pro. Modelo NLP especializado em bate-papo com texto/código e geração de código. Será desativado em 15/02/2025. Migre para série 1.5.</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>Não suportado</td><td>Diálogo, Obsoleto ou prestes a ser</td><td>Google_gemini</td><td>Versão mais recente do Gemini 1.0 Pro. Modelo NLP especializado em bate-papo com texto/código e geração de código. Será desativado em 15/02/2025. Migre para série 1.5.</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>Não suportado</td><td>Diálogo</td><td>Google_gemini</td><td>Versão visual do Gemini 1.0 Pro. Será desativado em 15/02/2025. Migre para série 1.5.</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>Não suportado</td><td>Reconhecimento visual</td><td>Google_gemini</td><td>Versão visual mais recente do Gemini 1.0 Pro. Será desativado em 15/02/2025. Migre para série 1.5.</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão estável mais recente do Gemini 1.5 Flash. Modelo multimodal equilibrado que processa entrada de áudio, imagem, vídeo e texto.</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão estável do Gemini 1.5 Flash. Oferece funcionalidade básica igual ao gemini-1.5-flash, mas com versão fixa, adequada para ambiente de produção.</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão estável do Gemini 1.5 Flash. Oferece funcionalidade básica igual ao gemini-1.5-flash, mas com versão fixa, adequada para ambiente de produção.</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Gemini 1.5 Flash-8B é modelo multimodal de IA mais recente do Google, projetado para processar tarefas em larga escala. Com 8 bilhões de parâmetros, suporta texto, imagem, áudio e vídeo. Otimizado para velocidade e custo-benefício. Limite de taxa duplicado para maior eficiência. Utiliza técnica de "distilação de conhecimento" para equilibrar capacidade e eficiência.</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão experimental do Gemini 1.5 Flash, atualizada periodicamente. Adequada para testes exploratórios e prototipagem, não recomendada para produção.</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão de ponta do Gemini 1.5 Flash, atualizada periodicamente. Adequada para testes exploratórios e prototipagem, não recomendada para produção.</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão estável do Gemini 1.5 Pro, com comportamento e desempenho fixos. Adequada para produção exigindo estabilidade.</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão estável do Gemini 1.5 Pro, com comportamento e desempenho fixos. Adequada para produção exigindo estabilidade.</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão experimental do Gemini 1.5 Pro. Modelo multimodal poderoso que processa até 60k linhas de código ou 2k páginas de texto. Ideal para tarefas que exigem raciocínio complexo.</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão experimental do Gemini 1.5 Pro. Modelo multimodal poderoso que processa até 60k linhas de código ou 2k páginas de texto. Ideal para tarefas que exigem raciocínio complexo.</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Versão mais recente do Gemini 1.5 Pro, apontando dinamicamente para a snapshot mais atual.</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>Não suportado</td><td>Diálogo, Reconhecimento visual</td><td>Google_gemini</td><td>Modelo mais recente do Google comparado à versão 1.5. Tem velocidade de geração inicial mais rápida (TTFT) enquanto mantém qualidade equivalente ao Gemini Pro 1.5; melhorias significativas em compreensão multimodal, capacidade de codificação, execução de instruções complexas e chamada de funções.</td></tr><tr><td>gemini-2.0-flash-exp</td><td>100k</td><td>8k</td>