
{% hint style="warning" %}
تمت ترجمة هذا المستند من الصينية بواسطة الذكاء الاصطناعي ولم تتم مراجعته بعد.
{% endhint %}

# Ollama

Ollama هو أداة مفتوحة المصدر ممتازة تتيح لك تشغيل وإدارة نماذج اللغة الكبيرة (LLMs) المختلفة بسهولة على جهازك المحلي. يدعم Cherry Studio الآن تكامل Ollama، مما يسمح لك بالتفاعل مباشرة مع نماذج LLM المثبتة محليًا في واجهة مألوفة، دون الحاجة إلى الاعتماد على خدمات السحابة!

## ما هو Ollama؟

Ollama هو أداة تبسط نشر واستخدام نماذج اللغة الكبيرة (LLM). ويتميز بما يلي:

* **التشغيل المحلي:** يعمل النموذج بالكامل على جهازك المحلي، دون الحاجة إلى اتصال بالإنترنت، مما يحمي خصوصيتك وأمان بياناتك.
* **سهولة الاستخدام:** يمكنك تنزيل وتشغيل وإدارة نماذج LLM المختلفة باستخدام أوامر بسيطة في سطر الأوامر.
* **تنوع النماذج:** يدعم العديد من النماذج المفتوحة المصدر الشهيرة مثل Llama 2 وDeepseek وMistral وGemma.
* **متعدد المنصات:** يعمل على أنظمة macOS وWindows وLinux.
* **واجهة برمجة تطبيقات مفتوحة:** يتوافق مع واجهة OpenAI ويمكن دمجه مع أدوات أخرى.

## لماذا تستخدم Ollama في Cherry Studio؟

* **بدون خدمات سحابية:** تخلص من قيود الحصص والتكاليف لواجهات برمجة التطبيقات السحابية، واستمتع بقوة نماذج LLM المحلية.
* **خصوصية البيانات:** تبقى جميع بيانات محادثاتك على جهازك المحلي، دون قلق بشأن تسريب الخصوصية.
* **العمل دون اتصال:** يمكنك الاستمرار في التفاعل مع نماذج LLM حتى بدون اتصال بالإنترنت.
* **التخصيص:** اختر وضبط نموذج LLM الأنسب لاحتياجاتك.

## تكوين Ollama في Cherry Studio

### **1. تثبيت وتشغيل Ollama**

أولاً، تحتاج إلى تثبيت وتشغيل Ollama على جهازك. اتبع هذه الخطوات:

*   **تنزيل Ollama:** قم بزيارة الموقع الرسمي لـ Ollama ([https://ollama.com/](https://ollama.com/))، وحمّل حزمة التثبيت المناسبة لنظام التشغيل الخاص بك.\
    على نظام Linux، يمكنك تثبيت ollama مباشرة عن طريق تشغيل الأمر:

    ```sh
    curl -fsSL https://ollama.com/install.sh | sh
    ```
* **تثبيت Ollama:** اتبع إرشادات المثبت لإكمال التثبيت.
*   **تنزيل النموذج:** افتح الطرفية (أو موجه الأوامر)، واستخدم أمر `ollama run` لتنزيل النموذج الذي تريد استخدامه. على سبيل المثال، لتنزيل نموذج Llama 2، يمكنك تشغيل:

    ```sh
    ollama run llama3.2
    ```

    سيقوم Ollama بتنزيل وتشغيل هذا النموذج تلقائيًا.
* **الحفاظ على تشغيل Ollama:** تأكد من بقاء Ollama قيد التشغيل أثناء استخدامك لـ Cherry Studio للتفاعل مع نماذج Ollama.

### **2. إضافة Ollama كموفر خدمات في Cherry Studio**

بعد ذلك، أضف Ollama كموفر خدمات ذكاء اصطناعي مخصص في Cherry Studio:

* **فتح الإعدادات:** في شريط التنقل الجانبي لواجهة Cherry Studio، انقر على "الإعدادات" (أيقونة الترس).
* **الدخول إلى خدمات النموذج:** في صفحة الإعدادات، اختر علامة التبويب "خدمات النموذج".
* **إضافة موفر:** انقر على Ollama في القائمة.

<figure><img src="../../.gitbook/assets/image (5) (3).png" alt=""><figcaption></figcaption></figure>

### **3. تكوين موفر خدمات Ollama**

ابحث عن موفر Ollama الذي أضفته حديثًا في قائمة الموفرين وقم بإعداد التكوين التفصيلي:

1. **حالة التفعيل:**
   * تأكد من تشغيل المفتاح الموجود على أقصى يمين موفر Ollama.
2. **مفتاح API:**
   * لا يحتاج Ollama افتراضيًا إلى مفتاح API. يمكنك ترك هذا الحقل فارغًا أو ملئه بأي محتوى.
3. **عنوان API:**
   *    املأ عنوان API المحلي الذي يوفره Ollama. عادةً ما يكون العنوان:

       ```
       http://localhost:11434/
       ```

       إذا قمت بتغيير المنفذ، فقم بتعديله حسب الحاجة.
4. **زمن النشاط:** هذا الخيار يحدد مدة بقاء الجلسة نشطة بالدقائق. إذا لم تحدث محادثة جديدة خلال الوقت المحدد، سيفصل Cherry Studio الاتصال بـ Ollama تلقائيًا لتحرير الموارد.
5. **إدارة النماذج:**
   * انقر على زر "+ إضافة" لإضافة أسماء النماذج التي قمت بتنزيلها في Ollama يدويًا.
   * على سبيل المثال، إذا قمت بتنزيل نموذج `llama3.2` عبر `ollama run llama3.2`، يمكنك إدخال `llama3.2` هنا.
   * انقر على زر "إدارة" لتحرير أو حذف النماذج المضافة.

## البدء في الاستخدام

بعد إكمال التكوين أعلاه، يمكنك في واجهة الدردشة في Cherry Studio اختيار موفر خدمات Ollama والنموذج الذي قمت بتنزيله، والبدء في الدردشة مع نموذج LLM المحلي!

## نصائح وإرشادات

* **التشغيل الأولي للنموذج:** عند تشغيل نموذج معين لأول مرة، يحتاج Ollama إلى تنزيل ملفات النموذج، مما قد يستغرق وقتًا طويلاً، لذا يرجى التحلي بالصبر.
* **عرض النماذج المتاحة:** تشغيل الأمر `ollama list` في الطرفية لعرض قائمة نماذج Ollama التي قمت بتنزيلها.
* **متطلبات الأجهزة:** يحتاج تشغيل نماذج اللغة الكبيرة إلى موارد حسابية كافية (وحدة المعالجة المركزية والذاكرة ومعالج الرسوميات)، لذا تأكد من أن تكوين جهازك يفي بمتطلبات النموذج.
* **وثائق Ollama:** يمكنك النقر على رابط `عرض وثائق ونماذج Ollama` في صفحة التكوين للانتقال مباشرة إلى الوثائق الرسمية لـ Ollama.