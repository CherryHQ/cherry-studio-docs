
{% hint style="warning" %}
تمت ترجمة هذا المستند من الصينية بواسطة الذكاء الاصطناعي ولم تتم مراجعته بعد.
{% endhint %}

# مقدمات الخدمات المخصصة

لا يدمج Cherry Studio خدمات نماذج الذكاء الاصطناعي الرئيسية فحسب، بل يمنحك أيضًا قوة كبيرة في التخصيص. من خلال ميزة **مقدمات خدمات الذكاء الاصطناعي المخصصة**، يمكنك بسهولة ربط أي نماذج ذكاء اصطناعي تحتاج إليها.

## لماذا تحتاج إلى مقدم خدمات ذكاء اصطناعي مخصص؟

* **المرونة:** التحرر من قائمة مزودي الخدمات المحددة مسبقًا، واختيار نموذج الذكاء الاصطناعي الأنسب لاحتياجاتك بحرية.
* **التنوع:** تجربة نماذج الذكاء الاصطناعي المختلفة من منصات متعددة، واستكشاف مزاياها الفريدة.
* **التحكم:** إدارة مفاتيح الوصول API وعناوين الاتصال مباشرة، لضمان الأمن والخصوصية.
* **التخصيص:** ربط النماذج المنشورة بشكل خاص، لتلبية احتياجات سيناريوهات العمل الخاصة.

## كيفية إضافة مقدم خدمات ذكاء اصطناعي مخصص؟

بخطوات بسيطة فقط، يمكنك إضافة مقدم خدمات الذكاء الاصطناعي المخصص الخاص بك في Cherry Studio:

<figure><img src="../../.gitbook/assets/image (2) (5).png" alt=""><figcaption></figcaption></figure>

1. **افتح الإعدادات:** في شريط التنقل الأيسر لـ Cherry Studio، انقر على "الإعدادات" (أيقونة الترس).
2. **انتقل إلى خدمات النماذج:** في صفحة الإعدادات، اختر علامة التبويب "خدمات النماذج".
3. **أضف مزودًا:** في صفحة "خدمات النماذج"، سترى قائمة موفري الخدمات الحاليين. انقر على زر "+ إضافة" أسفل القائمة لفتح نافذة "إضافة موفر".
4. **املأ المعلومات:** في النافذة المنبثقة، يجب عليك ملء المعلومات التالية:
   * **اسم المزود:** اختر اسمًا سهل التعرف عليه لمقدم الخدمات المخصص (على سبيل المثال: MyCustomOpenAI).
   * **نوع المزود:** اختر نوع مزود الخدمة من القائمة المنسدلة. حاليًا يدعم الأنواع التالية:
     * OpenAI
     * Gemini
     * Anthropic
     * Azure OpenAI
5. **احفظ التكوين:** بعد اكتمال التعبئة، انقر على زر "إضافة" لحفظ التكوين.

## تكوين مقدم خدمات الذكاء الاصطناعي المخصص

<figure><img src="../../.gitbook/assets/image (3) (5) (1).png" alt=""><figcaption></figcaption></figure>

بعد الإضافة، يجب عليك العثور على مزود الخدمة الذي أضفته في القائمة وإجراء التكوين التفصيلي:

1. **حالة التفعيل** يوجد على يمين قائمة مزودي الخدمات المخصصين زر مفاتيح، يرمز تشغيله إلى تفعيل هذه الخدمة المخصصة.
2. **مفتاح API:**
   * املأ مفتاح API (API Key) الذي يوفره مزود خدمات الذكاء الاصطناعي الخاص بك.
   * انقر على زر "التحقق" على اليمين للتحقق من صحة المفتاح.
3. **عنوان API:**
   * املأ عنوان واجهة برمجة التطبيقات لخدمات الذكاء الاصطناعي (Base URL).
   * تأكد من الرجوع إلى الوثائق الرسمية التي يوفرها مزود خدمة الذكاء الاصطناعي الخاص بك للحصول على عنوان API الصحيح.
4. **إدارة النماذج:**

    * انقر على زر "+ إضافة" لإضافة معرف النموذج الذي ترغب في استخدامه تحت هذا المزود يدويًا. على سبيل المثال `gpt-3.5-turbo`، `gemini-pro`، إلخ.

    <figure><img src="../../.gitbook/assets/image (4) (5).png" alt=""><figcaption></figcaption></figure>

    * إذا لم تكن متأكدًا من اسم النموذج المحدد، فراجع الوثائق الرسمية التي يوفرها مزود خدمة الذكاء الاصطناعي الخاص بك.
    * انقر على زر "إدارة" لتعديل أو حذف النماذج المضافة بالفعل.

## البدء في الاستخدام

بعد إكمال التكوين أعلاه، يمكنك الآن في واجهة الدردشة بـ Cherry Studio اختيار مزود خدمات الذكاء الاصطناعي المخصص والنموذج والبدء في الدردشة مع الذكاء الاصطناعي!

## استخدام vLLM كمزود خدمات ذكاء اصطناعي مخصص

vLLM هي مكتبة استدلال للغة الطبيعية (LLM) تشبه Ollama، تتميز بالسرعة وسهولة الاستخدام. إليك خطوات دمج vLLM في Cherry Studio:

1. **تثبيت vLLM:** ثبّت vLLM وفقًا للوثائق الرسمية (https://docs.vllm.ai/en/latest/getting_started/quickstart.html).

    ```sh
    pip install vllm # إذا كنت تستخدم pip
    uv pip install vllm # إذا كنت تستخدم uv
    ```
2. **تشغيل خدمة vLLM:** شغّل الخدمة باستخدام واجهة API المتوافقة مع OpenAI التي يوفرها vLLM. هناك طريقتان رئيسيتان:

    * استخدام `vllm.entrypoints.openai.api_server` للتشغيل

    ```sh
    python -m vllm.entrypoints.openai.api_server --model gpt2
    ```

    * استخدام `uvicorn` للتشغيل

    ```sh
    vllm --model gpt2 --served-model-name gpt2
    ```

تأكد من تشغيل الخدمة بنجاح والاستماع على المنفذ الافتراضي `8000`. بالطبع، يمكنك أيضًا تحديد منفذ خدمة vLLم باستخدام معلمة `--port`.

3. **إضافة مزود خدمة vLLM في Cherry Studio:**
   * اتبع الخطوات المذكورة سابقًا لإضافة مزود خدمات ذكاء اصطناعي مخصص جديد في Cherry Studio.
   * **اسم المزود:** `vLLM`
   * **نوع المزود:** اختر `OpenAI`.
4. **تكوين مزود خدمة vLLM:**
   * **مفتاح API:** بما أن vLLM لا يحتاج إلى مفتاح API، يمكنك ترك هذا الحقل فارغًا أو ملؤه بأي محتوى.
   * **عنوان API:** املأ عنوان API لخدمة vLLM. افتراضيًا، يكون العنوان: `http://localhost:8000/` (إذا تم استخدام منفذ مختلف، قم بتعديله وفقًا لذلك).
   * **إدارة النماذج:** أضف اسم النموذج الذي تم تحميله في vLLM. في المثال أعلاه حيث يتم تشغيل `python -m vllm.entrypoints.openai.api_server --model gpt2`، يجب هنا إدخال `gpt2`
5. **بدء المحادثة:** الآن يمكنك اختيار مزود خدمة vLLM ونموذج `gpt2` في Cherry Studio والبدء في الدردشة مع الذكاء الاصطناعي الذي يعمل بـ vLLM!

## نصائح وإرشادات

* **اقرأ الوثائق بعناية:** قبل إضافة أي مزود خدمات مخصص، تأكد من قراءة الوثائق الرسمية لمزود خدمة الذكاء الاصطناعي الذي تستخدمه، لمعرفة المعلومات الأساسية مثل مفتاح API وعنوان الاتصال وأسماء النماذج.
* **تحقق من مفتاح API:** استخدم زر "التحقق" للتحقق بسرعة من صحة مفتاح API، لتجنب العوائق الناجمة عن أخطاء المفتاح.
* **انتبه لعنوان API:** قد تختلف عناوين API بين موفري خدمات الذكاء الاصطناعي والنماذج المختلفة، تأكد من ملئها بشكل صحيح.
* **إضافة النماذج حسب الحاجة:** أضف فقط النماذج التي ستستخدمها فعليًا، وتجنب إضافة نماذج كثيرة غير ضرورية.