
{% hint style="warning" %}
Dieses Dokument wurde von einer KI aus dem Chinesischen übersetzt und ist noch nicht überprüft worden.
{% endhint %}

# Häufig verwendete Modellreferenzinformationen

{% hint style="info" %}
* Die folgenden Informationen dienen nur als Referenz. Bei Fehlern können Sie uns gerne kontaktieren, um diese zu korrigieren. Einige Modelle können je nach Anbieter unterschiedliche Kontextgrößen und Spezifikationen aufweisen.
* Bei der Dateneingabe im Client muss "k" in einen tatsächlichen Wert umgerechnet werden (theoretisch entspricht 1k = 1024 Tokens; 1m = 1024k Tokens). Beispiel: 8k = 8×1024 = 8192 Tokens. Für die praktische Verwendung wird empfohlen, mit 1000 zu multiplizieren, um Fehler zu vermeiden, z.B. 8k = 8×1000=8000, 1m=1×1000000=1000000.
* Modelle mit "–" in der Spalte "Maximale Ausgabe" haben keine offiziell veröffentlichte maximale Ausgabelänge.
{% endhint %}

<table><thead><tr><th width="313">Modellname</th><th width="158">Maximale Eingabe</th><th width="72">Maximale Ausgabe</th><th width="95">Funktionsaufruf</th><th width="142">Modellfähigkeiten</th><th width="540">Anbieter</th><th width="257">Beschreibung</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>Nicht unterstützt</td><td>Dialog</td><td>360AI_360gpt</td><td>360 Zhinaos leistungsstärkstes Hauptmodell der Milliarden-Klasse, geeignet für komplexe Aufgaben in verschiedenen Bereichen.</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>Nicht unterstützt</td><td>Dialog</td><td>360AI_360gpt</td><td>Hunderte-Millionen-Klasse-Modell mit ausgewogenem Leistungsverhältnis, ideal für Szenarien mit hohen Leistungs-/Kostenanforderungen.</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>Nicht unterstützt</td><td>Dialog</td><td>360AI_360gpt</td><td>Hunderte-Millionen-Klasse-Modell mit ausgewogenem Leistungsverhältnis, ideal für Szenarien mit hohen Leistungs-/Kostenanforderungen.</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>Nicht unterstützt</td><td>Dialog</td><td>360AI_360gpt</td><td>360 Zhinaos leistungsstärkstes Hauptmodell der Milliarden-Klasse, geeignet für komplexe Aufgaben in verschiedenen Bereichen.</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Anthropic_claude</td><td>Version vom 20. Juni 2024. Claude 3.5 Sonnet bietet Top-Leistung bei hoher Geschwindigkeit und unterstützt multimodale Eingabe.</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>Nicht unterstützt</td><td>Dialog</td><td>Anthropic_claude</td><td>Version vom 22. Oktober 2024. Claude 3.5 Haiku verbessert Codierung, Tool-Nutzung und Logikfähigkeiten. Als schnellstes Anthropic-Modell bietet es niedrige Latenz für benutzerorientierte Chatbots und Echtzeit-Code-Vervollständigung. Besonders effektiv für Datenanalyse und Inhaltsmoderation. Unterstützt keine Bildeingabe.</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Anthropic_claude</td><td>Version vom 22. Oktober 2024. Claude 3.5 Sonnet übertrifft Opus bei gleichem Preis, besonders stark in Programmierung, Data Science, Bildverarbeitung und Agenten-Aufgaben.</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Anthropic_claude</td><td>Dynamisch aktualisierte Claude 3.5 Sonnet Version. Übertrifft Opus bei Programmierung, Data Science, Bildverarbeitung und Agenten-Aufgaben.</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Anthropic_claude</td><td>Anthropics schnellstes und kompaktestes Modell für nahezu sofortige Antworten bei präziser Orientierungsleistung.</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Anthropic_claude</td><td>Anthropics leistungsstärkstes Modell für hochkomplexe Aufgaben, herausragend in Intelligenz, Sprachgewandtheit und Verständnis.</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Anthropic_claude</td><td>Version vom 29. Februar 2024. Besonders stark in:<br><br>- Codierung: Autonomes Schreiben, Bearbeiten und Ausführen von Code<br>- Data Science: Verbesserte menschliche Expertise; Verarbeitung unstrukturierter Daten<br>- Bildverarbeitung: Interpretation von Diagrammen, Grafiken und Bildern<br>- Agenten-Aufgaben: Herausragende Werkzeugnutzung für mehrstufige Problemstellungen</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>Nicht unterstützt</td><td>Dialog</td><td>Google_gamma</td><td>Von Google entwickelte leichte Open-Modelle basierend auf Gemini-Forschung. Nur-Decoder-Architektur für Textgenerierung, geeignet für Frage-Antwort, Zusammenfassung und Logik.</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>Nicht unterstützt</td><td>Dialog</td><td>Google_gamma</td><td>Leichtes Open-Modell von Google für Textgenerierung. Trainiert mit 8 Billionen Tokens.</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog</td><td>Google_gemini</td><td>Aktuelle stabile Version. Leistungsstarkes multimodales Modell für komplexe Logik, verarbeitet 60k Codezeilen oder 2000 Textseiten.</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog</td><td>Google_gemini</td><td>Stabile NLP-Version für mehrfache Text/Code-Chats. Wird am 15.02.2025 eingestellt - Migration zur 1.5-Serie empfohlen.</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog</td><td>Google_gemini</td><td>Stabile NLP-Version für mehrfache Text/Code-Chats. Wird am 15.02.2025 eingestellt.</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, veraltet/bald veraltet</td><td>Google_gemini</td><td>Aktuelle NLP-Version für Chat- und Codegenerierung. Wird am 15.02.2025 eingestellt.</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>Nicht unterstützt</td><td>Dialog</td><td>Google_gemini</td><td>Visuelle Gemini 1.0 Pro Version. Wird am 15.02.2025 eingestellt.</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>Nicht unterstützt</td><td>Bilderfassung</td><td>Google_gemini</td><td>Aktuelle visuelle Gemini 1.0 Pro Version. Wird am 15.02.2025 eingestellt.</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Aktuelle stabile Version. Ausgewogenes multimodales Modell verarbeitet Audio, Bilder, Video und Text.</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Stabile Version mit festen Funktionen für Produktionsumgebungen.</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Stabile Version mit festen Funktionen für Produktionsumgebungen.</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Googles multimodales 8-Milliarden-Parameter-Modell für große Aufgaben. Optimiert für Geschwindigkeit und Kosteneffizienz mit doppelter Ratenbegrenzung. Nutzt "Wissensdestillation".</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Experimentelle Version für Tests und Prototyping, nicht für Produktion.</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Fortschrittliche Version mit kontinuierlichen Updates für Tests.</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Stabile Version mit konsistentem Verhalten für Produktionsumgebungen.</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Stabile Version mit konsistentem Verhalten für Produktionsumgebungen.</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Experimentelle Gemini 1.5 Pro Version für komplexe Logik, verarbeitet 60k Codezeilen.</td></tr><tr><td>gemini-1.5-pro-exp-0827</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Experimentelle Version für komplexe Logik, verarbeitet 60k Codezeilen.</td></tr><tr><td>gemini-1.5-pro-latest</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Dynamisch aktualisierte Version</td></tr><tr><td>gemini-2.0-flash</td><td>1m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Googles aktuellstes Modell mit schnellerer TTFT bei GPT-4-Pro-1.5-Qualität. Verbesserte Multimodalität und Funktionsausführung.</td></tr><tr><td>gemini-2.0-flash-exp</td><td>100k</td><td>8k</td><td>Unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Führt multimodale Echtzeit-APIs, verbesserte Geschwindigkeit, Bildgenerierung und Sprachumwandlung ein.</td></tr><tr><td>gemini-2.0-flash-lite-preview-02-05</td><td>1M</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Kosteneffizientes Modell mit 1M Token-Kontext und Multimodalität. Optimiert für große Skalierung.</td></tr><tr><td>gemini-2.0-flash-thinking-exp</td><td>40k</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Logik</td><td>Google_gemini</td><td>Experimentelles Modell zeigt "Denkprozesse" für bessere Schlussfolgerungen gegenüber Standard-Gemini 2.0 Flash.</td></tr><tr><td>gemini-2.0-flash-thinking-exp-01-21</td><td>1m</td><td>64k</td><td>Nicht unterstützt</td><td>Dialog, Logik</td><td>Google_gemini</td><td>Verbessert mathematische und programmatische Logikfähigkeiten bei 1M Token-Kontext. Bietet natives Code-Execution und reduzierte logische Widersprüche.</td></tr><tr><td>gemini-2.0-flash-thinking-exp-1219</td><td>40k</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Logik, Bilderfassung</td><td>Google_gemini</td><td>Zeigt "Denkprozesse" für verbesserte Schlussfolgerungen.</td></tr><tr><td>gemini-2.0-pro-exp-01-28</td><td>2m</td><td>64k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Vorgehaltenes Modell, noch nicht live</td></tr><tr><td>gemini-2.0-pro-exp-02-05</td><td>2m</td><td>8k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Experimentelles Modell (02/2024) mit verbesserter Weltkenntnis, Codelogik und 2M-Token-Kontext. Nutzt "Flash Thinking"-Training für top-LLM-Bewertungen.</td></tr><tr><td>gemini-exp-1114</td><td>8k</td><td>4k</td><td>Nicht unterstützt</td><td>Dialog, Bilderfassung</td><td>Google_gemini</td><td>Experimentelles Modell vom 14.11