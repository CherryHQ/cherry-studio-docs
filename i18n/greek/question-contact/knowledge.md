---
icon: book-bookmark
---
# Γενικές Γνώσεις


{% hint style="warning" %}
Αυτό το έγγραφο μεταφράστηκε από τα Κινεζικά με AI και δεν έχει ακόμη ελεγχθεί.
{% endhint %}




## Τι είναι tokens;

Τα tokens είναι η βασική μονάδα επεξεργασίας κειμένου από τα μοντέλα ΤΝ. Μπορούν να θεωρηθούν ως η μικρότερη μονάδα "σκέψης" του μοντέλου. Δεν αντιστοιχούν ακριβώς σε χαρακτήρες ή λέξεις όπως τα αντιλαμβανόμαστε εμείς, αλλά αποτελούν έναν ειδικό τρόπο κατατμήσεως κειμένου που χρησιμοποιεί το ίδιο το μοντέλο.

#### 1. Κινεζική κατατμήση

* Ένας κινέζικος χαρακτήρας συνήθως κωδικοποιείται σε 1-2 tokens
* Παράδειγμα: `"你好"` ≈ 2-4 tokens

#### 2. Αγγλική κατατμήση

* Οι κοινές λέξεις είναι συνήθως 1 token
* Μακριές ή σπάνιες λέξεις διασπώνται σε πολλαπλά tokens
* Παραδείγματα:
  * `"hello"` = 1 token
  * `"indescribable"` = 4 tokens

#### 3. Ειδικοί χαρακτήρες

* Τα κενά, τα σημεία στίξης κ.ά. καταλαμβάνουν tokens
* Η αλλαγή γραμμής είναι συνήθως 1 token

{% hint style="info" %}
Ο Tokenizer διαφέρει ανάμεσα σε διαφορετικούς παρόχους υπηρεσιών και ακόμα και μεταξύ διαφορετικών μοντέλων του ίδιου παρόχου. Αυτή η γνώση χρησιμεύει μόνο για την κατανόηση της έννοιας του token.
{% endhint %}

***

## Τι είναι Tokenizer;

Ο Tokenizer (κατακερματιστής) είναι το εργαλείο με το οποίο ένα μοντέλο ΤΝ μετατρέπει το κείμενο σε tokens. Καθορίζει πώς θα διασπαστεί το εισαγόμενο κείμενο στις μικρότερες ενότητες που μπορεί να κατανοήσει το μοντέλο.

### Γιατί διαφέρει ο Tokenizer ανάμεσα σε μοντέλα;

#### 1. Διαφορετικά δεδομένα εκπαίδευσης

* Διαφορετικά σώματα κειμένων οδηγούν σε διαφορετικές βελτιστοποιήσεις
* Διαφορετικό επίπεδο υποστήριξης πολλαπλών γλωσσών
* Εξειδικευμένη βελτιστοποίηση για συγκεκριμένους τομείς (ιατρική, νομική κ.ά.)

#### 2. Διαφορετικοί αλγόριθμοι κατατμήσεως

* BPE (Byte Pair Encoding) - OpenAI GPT σειρά
* WordPiece - Google BERT
* SentencePiece - Κατάλληλο για πολυγλωσσικά σενάρια

#### 3. Διαφορετικοί στόχοι βελτιστοποίησης

* Μερικοί εστιάζουν στην αποδοτικότητα συμπίεσης
* Άλλοι στη διατήρηση σημασιολογικού περιεχομένου
* Άλλοι στην ταχύτητα επεξεργασίας

### Πρακτικές επιπτώσεις

Το ίδιο κείμενο μπορεί να έχει διαφορετικό αριθμό tokens σε διαφορετικά μοντέλα:

```
输入："Hello, world!"
GPT-3: 4 tokens
BERT: 3 tokens
Claude: 3 tokens
```

***

## Τι είναι τα ενσωματωσιακά μοντέλα (Embedding Models);

**Βασική έννοια:** Τα ενσωματωσιακά μοντέλα είναι μια τεχνική που μετατρέπει υψηλών διαστάσεων διακριτά δεδομένα (κείμενο, εικόνες κ.ά.) σε χαμηλών διαστάσεων συνεχείς διανύσματα. Αυτή η μετατροπή επιτρέπει στις μηχανές να κατανοούν και να επεξεργάζονται καλύτερα πολύπλοκα δεδομένα. Φανταστείτε το σαν να απλοποιείτε ένα πολύπλοκο παζλ σε ένα απλό σημείο συντεταγμένων που διατηρεί τα κύρια χαρακτηριστικά του. Οικοσύστημα των μεγάλων μοντέλων, λειτουργεί ως "μεταφραστής", μετατρέποντας πληροφορίες κατανοητές από τον άνθρωπο σε αριθμητική μορφή υπολογίσιμη από την ΤΝ.

**Αρχή λειτουργίας:** Στη φυσική γλώσσα, τα ενσωματωσιακά μοντέλα αντιστοιχίζουν λέξεις σε συγκεκριμένες θέσεις σε ένα διανυσματικό χώρο. Σε αυτόν τον χώρο, οι σημασιολογικά παρόμοιες λέξεις ομαδοποιούνται αυτόματα. Για παράδειγμα:

* Τα διανύσματα για "βασιλιάς" και "βασίλισσα" είναι πολύ κοντά
* Λέξεις όπως "γάτα" και "σκύλος" θα έχουν παρόμοια απόσταση
* Ενώ "αυτοκίνητο" και "ψωμί" θα έχουν μεγάλη απόσταση λόγω έλλειψης σημασιολογικής σχέσης

**Κύριες εφαρμογές:**

* Ανάλυση κειμένου: ταξινόμηση εγγράφων, συναισθηματική ανάλυση
* Συστήματα συστάσεων: προσωποποιημένες προτάσεις περιεχομένου
* Επεξεργασία εικόνας: αναζήτηση παρόμοιων εικόνων
* Μηχανές αναζήτησης: σημασιολογική βελτιστοποίηση αναζήτησης

**Κύρια πλεονεκτήματα:**

1. Μείωση διαστάσεων: απλοποίηση πολύπλοκων δεδομένων σε εύχρηστη διανυσματική μορφή
2. Διατήρηση σημασιολογίας: διατήρηση κρίσιμων σημασιολογικών πληροφοριών από τα αρχικά δεδομένα
3. Υπολογιστική αποδοτικότητα: σημαντική βελτίωση στην εκπαίδευση και συμπερασματολογία μοντέλων μηχανικής μάθησης

**Τεχνολογική αξία:** Τα ενσωματωσιακά μοντέλα αποτελούν βασικά συστατικά των σύγχρονων συστημάτων ΤΝ, παρέχοντας υψηλής ποιότητας αναπαραστάσεις δεδομένων για εργασίες μηχανικής μάθησης και είναι κρίσιμη τεχνολογία για την πρόοδο στον τομέα της επεξεργασίας φυσικής γλώσσας και της υπολογιστικής όρασης.

***

## Αρχή λειτουργίας των Embedding μοντέλων στην ανάκτηση γνώσης

**Βασική διαδικασία:**

1. **Προεπεξεργασία βάσης γνώσης**

* Διαχωρισμός εγγράφων σε κατάλληλου μεγέθους τμήματα (chunks)
* Μετατροπή κάθε τμήματος σε διάνυσμα χρησιμοποιώντας ένα ενσωματωσιακό μοντέλο
* Αποθήκευση διανυσμάτων και αρχικού κειμένου σε διανυσματική βάση δεδομένων

2. **Φάση επεξεργασίας ερωτήματος**

* Μετατροπή της ερώτησης του χρήστη σε διάνυσμα
* Αναζήτηση παρόμοιου περιεχομένου στη διανυσματική βάση
* Παροχή του ανακτηθέντος σχετικού περιεχομένου ως πλαισίου στο Μεγάλο Γλωσσικό Μοντέλο (LLM)

***

## Τι είναι το MCP (Model Context Protocol);

To MCP είναι ένα ανοιχτού κώδικα πρωτόκολλο που στοχεύει στην τυποποιημένη παροχή πλαισίου πληροφοριών στα Μεγάλα Γλωσσικά Μοντέλα (LLM).

* **Αντιμεταφορική κατανόηση:** Φανταστείτε το MCP ως "USB stick" στον τομέα της ΤΝ.  Όπως ένα USB stick αποθηκεύει διάφορα αρχεία και μετά από σύνδεση στον υπολογιστή είναι άμεσα χρησιμοποιήσιμο, το MCP Server μπορεί να "συνδέσει" διάφορα "πρόσθετα" που παρέχουν πλαίσιο. Το LLM μπορεί να ζητήσει αυτά τα πρόσθετα από τον MCP Server ανάλογα με τις ανάγκες του, αποκτώντας εμπλουτισμένο πλαίσιο πληροφοριών για ενίσχυση των δυνατοτήτων του.
* **Σύγκριση με τα Function Tool:** Τα παραδοσιακά Function Tool (εργαλεία λειτουργιών) προσφέρουν επίσης εξωτερικές λειτουργίες στα LLM, αλλά το MCP είναι μια υψηλότερης διάστασης αφαίρεση. Τα Function Tool εστιάζουν περισσότερο σε εργαλεία για συγκεκριμένες εργασίες, ενώ το MCP παρέχει έναν πιο καθολικό, αρθρωτό μηχανισμό απόκτησης πλαισίου.

### Βασικά πλεονεκτήματα του MCP

1. **Τυποποίηση:** Παρέχει ενοποιημένη διεπαφή και μορφή δεδομένων για απρόσκοπτη συνεργασία μεταξύ διαφορετικών LLM και παρόχων πλαισίου
2. **Αρθρωτότητα:** Επιτρέπει την αποσύνθεση πληροφοριών πλαισίου σε ανεξάρτητες ενότητες (πρόσθετα) για εύκολη διαχείριση και επαναχρησιμοποίηση
3. **Ευελιξία:** Τα LLM μπορούν να επιλέγουν δυναμικά τα απαραίτητα πρόσθετα πλαισίου για πιο έξυπνη και προσωποποιημένη αλληλεπίδραση
4. **Επεκτασιμότητα:** Ο σχεδιασμός υποστηρίζει την προσθήκη περισσότερων τύπων πρόσθετων πλαισίου στο μέλλον, προσφέροντας απεριόριστες δυνατότητες επέκτασης για τα LLM

***