
{% hint style="warning" %}
เอกสารนี้ได้รับการแปลจากภาษาจีนโดย AI และยังไม่ได้รับการตรวจสอบ
{% endhint %}

```
---
icon: cherries
---

# ผู้ให้บริการที่กำหนดเอง

Cherry Studio ไม่เพียงผสานรวมบริการโมเดล AI หลักเท่านั้น แต่ยังมอบความสามารถในการปรับแต่งอันทรงพลังให้คุณด้วย ผ่านฟีเจอร์ **ผู้ให้บริการ AI ที่กำหนดเอง** คุณสามารถเชื่อมต่อกับโมเดล AI ใดก็ได้ที่คุณต้องการอย่างง่ายดาย

## เหตุใดจึงต้องมีผู้ให้บริการ AI ที่กำหนดเอง?

* **ความยืดหยุ่น:** ไม่ถูกจำกัดด้วยรายการผู้ให้บริการที่กำหนดไว้ล่วงหน้าอีกต่อไป เลือกโมเดล AI ที่ตรงกับความต้องการของคุณได้อย่างอิสระ
* **ความหลากหลาย:** ลองใช้โมเดล AI จากแพลตฟอร์มต่างๆ เพื่อค้นพบจุดเด่นเฉพาะตัวของพวกมัน
* **ความสามารถในการควบคุม:** จัดการคีย์ API และที่อยู่การเข้าถึงของคุณโดยตรง เพื่อความปลอดภัยและความเป็นส่วนตัว
* **การปรับแต่ง:** เชื่อมต่อกับโมเดลที่ปรับใช้แบบส่วนตัว เพื่อตอบสนองความต้องการของธุรกิจเฉพาะทาง

## จะเพิ่มผู้ให้บริการ AI ที่กำหนดเองได้อย่างไร?

เพียงไม่กี่ขั้นตอน คุณก็สามารถเพิ่มผู้ให้บริการ AI ที่กำหนดเองใน Cherry Studio:

<figure><img src="../../.gitbook/assets/image (2) (5).png" alt=""><figcaption></figcaption></figure>

1. **เปิดการตั้งค่า:** ในแถบนำทางด้านซ้ายของอินเทอร์เฟซ Cherry Studio คลิกที่ "การตั้งค่า" (ไอคอนเฟือง)
2. **เข้าสู่บริการโมเดล:** ในหน้า การตั้งค่า ให้เลือกแท็บ "บริการโมเดล"
3. **เพิ่มผู้ให้บริการ:** ในหน้า "บริการโมเดล" คุณจะเห็นรายการผู้ให้บริการที่มีอยู่ คลิกปุ่ม "+ เพิ่ม" ด้านล่างรายการเพื่อเปิดป๊อปอัป "เพิ่มผู้ให้บริการ"
4. **กรอกข้อมูล:** ในป๊อปอัป คุณจำเป็นต้องกรอกข้อมูลดังต่อไปนี้:
   * **ชื่อผู้ให้บริการ:** ตั้งชื่อสำหรับผู้ให้บริการที่กำหนดเองของคุณให้เป็นชื่อที่จำง่าย (ตัวอย่างเช่น: MyCustomOpenAI)
   * **ประเภทผู้ให้บริการ:** เลือกประเภทผู้ให้บริการของคุณจากรายการแบบดร็อปดาวน์ ขณะนี้รองรับ:
     * OpenAI
     * Gemini
     * Anthropic
     * Azure OpenAI
5. **บันทึกการตั้งค่า:** หลังจากกรอกข้อมูลเสร็จ ให้คลิกปุ่ม "เพิ่ม" เพื่อบันทึกการตั้งค่าของคุณ

## ตั้งค่าผู้ให้บริการ AI ที่กำหนดเอง

<figure><img src="../../.gitbook/assets/image (3) (5) (1).png" alt=""><figcaption></figcaption></figure>

หลังเพิ่มเสร็จ คุณต้องค้นหาผู้ให้บริการที่เพิ่งเพิ่มในรายการและกำหนดค่าอย่างละเอียด:

1. **สถานะการเปิดใช้งาน** ทางด้านขวาสุดของรายการผู้ให้บริการที่กำหนดเองจะมีสวิตช์เปิด/ปิด เปิดเพื่อเปิดใช้งานบริการที่กำหนดเองนั้น
2. **คีย์ API:**
   * กรอกคีย์ API (API Key) ที่ผู้ให้บริการ AI ของคุณให้มา
   * คลิกปุ่ม "ตรวจสอบ" ด้านขวาเพื่อยืนยันความถูกต้องของคีย์
3. **ที่อยู่ API:**
   * กรอกที่อยู่การเข้าถึง API (Base URL) ของบริการ AI
   * อย่าลืมอ้างอิงเอกสารทางการจากผู้ให้บริการ AI ของคุณเพื่อรับที่อยู่ API ที่ถูกต้อง
4. **การจัดการโมเดล:**
   * คลิกปุ่ม "+ เพิ่ม" เพื่อเพิ่มรหัสโมเดลที่คุณต้องการใช้ภายใต้ผู้ให้บริการนี้ด้วยตนเอง ตัวอย่างเช่น `gpt-3.5-turbo`, `gemini-pro` เป็นต้น

    <figure><img src="../../.gitbook/assets/image (4) (5).png" alt=""><figcaption></figcaption></figure>

   * หากคุณไม่แน่ใจชื่อโมเดลที่แน่นอน โปรดอ้างอิงเอกสารทางการจากผู้ให้บริการ AI ของคุณ
   * คลิกปุ่ม "จัดการ" เพื่อแก้ไขหรือลบโมเดลที่เพิ่มแล้ว

## เริ่มต้นการใช้งาน

หลังจากตั้งค่าข้างต้นเสร็จสิ้น คุณก็สามารถเลือกผู้ให้บริการ AI และโมเดลที่กำหนดเองของคุณในอินเทอร์เฟซแชทของ Cherry Studio และเริ่มสนทนากับ AI ได้เลย!

## ใช้ vLLM เป็นผู้ให้บริการ AI ที่กำหนดเอง

vLLM เป็นไลบรารีการอนุมาน LLM ที่รวดเร็วและใช้งานง่าย คล้ายกับ Ollama ต่อไปนี้คือขั้นตอนในการรวม vLLM เข้าสู่ Cherry Studio:

1. **ติดตั้ง vLLM:** ติดตั้ง vLLM ตามเอกสารทางการของ vLLM ([https://docs.vllm.ai/en/latest/getting_started/quickstart.html](https://docs.vllm.ai/en/latest/getting_started/quickstart.html))

    ```sh
    pip install vllm # ถ้าคุณใช้ pip
    uv pip install vllm # ถ้าคุณใช้ uv
    ```
2. **เริ่มต้นบริการ vLLM:** ใช้ส่วนต่อประสานที่เข้ากันได้กับ OpenAI ที่ vLLM ให้มาเพื่อเริ่มต้นบริการ โดยมีสองวิธีหลักดังนี้:

    * ใช้ `vllm.entrypoints.openai.api_server` เริ่ม

    ```sh
    python -m vllm.entrypoints.openai.api_server --model gpt2
    ```

    * ใช้ `uvicorn` เริ่ม

    ```sh
    vllm --model gpt2 --served-model-name gpt2
    ```

ตรวจสอบให้แน่ใจว่าบริการเริ่มต้นสำเร็จ และกำลังฟังที่พอร์ตเริ่มต้น `8000` แน่นอน คุณยังสามารถระบุหมายเลขพอร์ตของบริการ vLLM ได้ผ่านพารามิเตอร์ `--port`

3. **เพิ่มผู้ให้บริการ vLLM ใน Cherry Studio:**
   * ทำตามขั้นตอนที่อธิบายไว้ก่อนหน้านี้เพื่อเพิ่มผู้ให้บริการ AI ที่กำหนดเองใหม่ใน Cherry Studio
   * **ชื่อผู้ให้บริการ:** `vLLM`
   * **ประเภทผู้ให้บริการ:** เลือก `OpenAI`
4. **ตั้งค่าผู้ให้บริการ vLLM:**
   * **คีย์ API:** เนื่องจาก vLLM ไม่ต้องการคีย์ API คุณสามารถปล่อยฟิลด์นี้ว่างไว้ หรือกรอกอะไรก็ได้
   * **ที่อยู่ API:** กรอกที่อยู่ API ของบริการ vLLM โดยค่าเริ่มต้นคือ: `http://localhost:8000/` (หากใช้พอร์ตต่างไป โปรดแก้ไขให้สอดคล้อง)
   * **การจัดการโมเดล:** เพิ่มชื่อโมเดลที่คุณโหลดใน vLLM ในตัวอย่างด้านบนที่รัน `python -m vllm.entrypoints.openai.api_server --model gpt2` คุณควรกรอก `gpt2` ที่นี่
5. **เริ่มการสนทนา:** ตอนนี้ คุณสามารถเลือกผู้ให้บริการ vLLM และโมเดล `gpt2` ใน Cherry Studio และเริ่มสนทนากับ LLM ที่ขับเคลื่อนโดย vLLM ได้แล้ว!

## เคล็ดลับและเทคนิค

* **อ่านเอกสารอย่างละเอียด:** ก่อนเพิ่มผู้ให้บริการที่กำหนดเอง อย่าลืมอ่านเอกสารทางการของ AI service provider ที่คุณใช้ให้ละเอียด เพื่อทำความเข้าใจคีย์ API, ที่อยู่การเข้าถึง, ชื่อโมเดล และข้อมูลสำคัญอื่นๆ
* **ตรวจสอบคีย์ API:** ใช้ปุ่ม "ตรวจสอบ" เพื่อยืนยันความถูกต้องของคีย์ API อย่างรวดเร็ว และหลีกเลี่ยงปัญหาการใช้งานไม่ได้เนื่องจากคีย์ผิดพลาด
* **ใส่ใจที่อยู่ API:** ที่อยู่ API อาจแตกต่างกันไปตามผู้ให้บริการ AI และโมเดล อย่าลืมกรอกที่อยู่ที่ถูกต้อง
* **เพิ่มโมเดลตามความต้องการ:** โปรดเพิ่มเฉพาะโมเดลที่คุณจะใช้จริง หลีกเลี่ยงการเพิ่มโมเดลที่ไม่จำเป็นจำนวนมาก
```