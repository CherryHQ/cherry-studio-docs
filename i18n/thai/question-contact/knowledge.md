---
icon: book-bookmark
---

{% hint style="warning" %}
เอกสารนี้ได้รับการแปลจากภาษาจีนโดย AI และยังไม่ได้รับการตรวจสอบ
{% endhint %}

# ความรู้ทางวิทยาศาสตร์

## โทเคน (Tokens) คืออะไร

โทเคนคือหน่วยพื้นฐานที่โมเดล AI ใช้ประมวลผลข้อความ คุณสามารถเข้าใจได้ว่าเป็นหน่วยย่อยที่สุดที่โมเดล "คิด" โทเคนไม่เท่ากับตัวอักษรหรือคำตามความเข้าใจของเรา แต่เป็นการแบ่งข้อความพิเศษของโมเดลเอง

#### 1. การแบ่งคำภาษาจีน
* อักษรจีนหนึ่งตัวมักถูกเข้ารหัสเป็น 1-2 โทเคน
* เช่น: `"你好"` ≈ 2-4 โทเคน

#### 2. การแบ่งคำภาษาอังกฤษ
* คำทั่วไปมักเป็น 1 โทเคน
* คำที่ยาวหรือไม่ธรรมดาจะถูกแยกเป็นหลายโทเคน
* เช่น:
  * `"hello"` = 1 โทเคน
  * `"indescribable"` = 4 โทเคน

#### 3. อักขระพิเศษ
* ช่องว่าง เครื่องหมายวรรคตอน ฯลฯ ใช้โทเคน
* อักขระขึ้นบรรทัดใหม่มักเป็น 1 โทเคน

{% hint style="info" %}
Tokenizer ของผู้ให้บริการแต่ละรายแตกต่างกัน แม้แต่โมเดลต่างกันของผู้ให้บริการเดียวกันก็อาจมี Tokenizer ต่างกัน ความรู้นี้มีไว้เพื่อทำความเข้าใจแนวคิดของโทเคนเท่านั้น
{% endhint %}

***

## Tokenizer คืออะไร

Tokenizer (ตัวแบ่งคำ) เป็นเครื่องมือที่โมเดล AI ใช้แปลงข้อความเป็นโทเคน มันกำหนดวิธีแบ่งข้อความอินพุตออกเป็นหน่วยย่อยที่สุดที่โมเดลเข้าใจได้

### ทำไม Tokenizer ของโมเดลต่างกันถึงแตกต่าง

#### 1. ข้อมูลการฝึกแตกต่าง
* คลังข้อความต่างกันทำให้ทิศทางการปรับแต่งต่างกัน
* ระดับการสนับสนุนหลายภาษาแตกต่าง
* การปรับแต่งเฉพาะด้าน (การแพทย์ กฎหมาย ฯลฯ)

#### 2. อัลกอริทึมการแบ่งคำต่างกัน
* BPE (Byte Pair Encoding) - OpenAI GPT series
* WordPiece - Google BERT
* SentencePiece - เหมาะกับสถานการณ์หลายภาษา

#### 3. เป้าหมายการปรับแต่งต่างกัน
* บางตัวเน้นประสิทธิภาพการบีบอัด
* บางตัวเน้นรักษาความหมาย
* บางตัวเน้นความเร็วในการประมวลผล

### ผลกระทบในทางปฏิบัติ

ข้อความเดียวกันอาจมีจำนวนโทเคนต่างกันในโมเดลต่างกัน:

```
อินพุต: "Hello, world!"
GPT-3: 4 โทเคน
BERT: 3 โทเคน
Claude: 3 โทเคน
```

***

## โมเดลเอมเบดดิง (Embedding Model) คืออะไร

**แนวคิดพื้นฐาน:** โมเดลเอมเบดดิงเป็นเทคนิคการแปลงข้อมูลไม่ต่อเนื่องมิติสูง (ข้อความ ภาพ ฯลฯ) ให้เป็นเวกเตอร์ต่อเนื่องมิติต่ำ การแปลงนี้ทำให้เครื่องจักรเข้าใจและประมวลผลข้อมูลซับซ้อนได้ดีขึ้น เหมือนเปลี่ยนจิ๊กซอว์ซับซ้อนให้เป็นจุดพิกัดง่ายๆ ที่ยังคงคุณลักษณะสำคัญของจิ๊กซอว์ ในระบบนิเวศโมเดลขนาดใหญ่ มันทำหน้าที่เป็น "ล่าม" แปลงข้อมูลที่มนุษย์เข้าใจให้เป็นรูปแบบตัวเลขที่ AI คำนวณได้

**หลักการทำงาน:** ในตัวอย่างการประมวลผลภาษาธรรมชาติ โมเดลเอมเบดดิงสามารถแมปคำไปยังตำแหน่งเฉพาะในสเปซเวกเตอร์ คำที่มีความหมายคล้ายกันจะถูกจัดกลุ่มใกล้กันโดยอัตโนมัติ เช่น:
* เวกเตอร์ของ "国王" (กษัตริย์) และ "王后" (ราชินี) จะอยู่ใกล้กัน
* คำสัตว์เลี้ยงอย่าง "猫" (แมว) และ "狗" (หมา) จะอยู่ใกล้กัน
* ส่วนคำที่ไม่เกี่ยวข้องกันเช่น "汽车" (รถยนต์) และ "面包" (ขนมปัง) จะอยู่ห่างกัน

**สถานการณ์การใช้งานหลัก:**
* การวิเคราะห์ข้อความ: การจัดประเภทเอกสาร การวิเคราะห์ความรู้สึก
* ระบบแนะนำ: การแนะนำเนื้อหาเฉพาะบุคคล
* การประมวลผลภาพ: การค้นหาภาพที่คล้ายกัน
* เครื่องมือค้นหา: การปรับแต่งการค้นหาความหมาย

**ข้อได้เปรียบหลัก:**
1. ผลการลดมิติ: ลดความซับซ้อนของข้อมูลเป็นรูปแบบเวกเตอร์ที่จัดการง่าย
2. รักษาความหมาย: รักษาข้อมูลความหมายสำคัญจากข้อมูลต้นฉบับ
3. ประสิทธิภาพการคำนวณ: เพิ่มประสิทธิภาพการฝึกและการอนุมานของโมเดลการเรียนรู้ของเครื่อง

**คุณค่าทางเทคนิค:** โมเดลเอมเบดดิงเป็นส่วนประกอบพื้นฐานของระบบ AI สมัยใหม่ ให้การแสดงข้อมูลคุณภาพสูงสำหรับงานการเรียนรู้ของเครื่อง และเป็นเทคโนโลยีหลักที่ขับเคลื่อนการพัฒนาด้านการประมวลผลภาษาธรรมชาติ การมองเห็นด้วยคอมพิวเตอร์ และสาขาอื่นๆ

***

## หลักการทำงานของ Embedding Model ในการค้นหาความรู้

**ขั้นตอนการทำงานพื้นฐาน:**
1. **ขั้นเตรียมฐานความรู้**
* แบ่งเอกความเป็น chunk (ส่วนข้อความ) ขนาดเหมาะสม
* ใช้ embedding model แปลงแต่ละ chunk เป็นเวกเตอร์
* บันทึกเวกเตอร์และข้อความต้นฉบับในฐานข้อมูลเวกเตอร์

2. **ขั้นประมวลผลคำถาม**
* แปลงคำถามผู้ใช้เป็นเวกเตอร์
* ค้นหาข้อมูลที่คล้ายกันในฐานข้อมูลเวกเตอร์
* ให้ข้อมูลที่เกี่ยวข้องที่พบเป็นบริบทแก่ LLM

***

## **MCP (Model Context Protocol) คืออะไร**

MCP เป็นโปรโตคอลโอเพนซอร์ซที่มุ่งให้ข้อมูลบริบทแก่โมเดลภาษาขนาดใหญ่ (LLM) ในรูปแบบมาตรฐาน

* **การเปรียบเทียบ:** MCP เปรียบเสมือน "USB ไดรฟ์" ในวงการ AI เรารู้ว่า USB สามารถเก็บไฟล์ต่างๆ และเมื่อเสียบเข้ากับคอมพิวเตอร์ก็ใช้งานได้ทันที เช่นเดียวกัน MCP Server สามารถ "เสียบ" "ปลั๊กอิน" ที่ให้บริบทหลากหลายได้ LLM สามารถขอปลั๊กอินเหล่านี้จาก MCP Server ตามต้องการ เพื่อรับข้อมูลบริบทที่สมบูรณ์ขึ้นและเสริมความสามารถของตนเอง
* **การเปรียบเทียบกับ Function Tool:** Function Tool (เครื่องมือฟังก์ชัน) แบบดั้งเดิมสามารถให้ฟังก์ชันภายนอกแก่ LLM ได้ แต่ MCP เป็นการกำหนดระดับสูงกว่า Function Tool เป็นเครื่องมือสำหรับงานเฉพาะทาง ในขณะที่ MCP ให้กลไกการรับบริบทที่ครอบคลุมกว่าและเป็นแบบโมดูลาร์

### **ข้อได้เปรียบหลักของ MCP**

1. **มาตรฐาน:** MCP ให้อินเทอร์เฟซและรูปแบบข้อมูลที่เป็นเอกภาพ ทำให้ LLM และผู้ให้บริบทต่างกันทำงานร่วมกันได้อย่างราบรื่น
2. **โมดูลาร์:** MCP ให้นักพัฒนาสามารถแยกข้อมูลบริบทเป็นโมดูลอิสระ (ปลั๊กอิน) จัดการและนำกลับมาใช้ได้ง่าย
3. **ความยืดหยุ่น:** LLM สามารถเลือกปลั๊กอินบริบทที่ต้องการแบบไดนามิกตามความต้องการ ทำให้การโต้ตอบชาญฉลาดและเป็นส่วนตัวมากขึ้น
4. **ความสามารถในการขยาย:** การออกแบบ MCP รองรับการเพิ่มปลั๊กอินบริบทประเภทใหม่ในอนาคต เพิ่มขีดความสามารถให้กับ LLM อย่างไม่จำกัด

***