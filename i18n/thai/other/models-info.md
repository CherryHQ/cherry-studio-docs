
{% hint style="warning" %}
เอกสารนี้ได้รับการแปลจากภาษาจีนโดย AI และยังไม่ได้รับการตรวจสอบ
{% endhint %}

# ข้อมูลอ้างอิงโมเดลทั่วไป

{% hint style="info" %}
* ข้อมูลนี้มีไว้เพื่ออ้างอิงเท่านั้น หากพบข้อผิดพลาดโปรดติดต่อเพื่อแก้ไข ส่วนข้อมูลเช่นขนาดคอนเท็กซ์และรายละเอียดโมเดลอาจแตกต่างกันไปขึ้นอยู่กับผู้ให้บริการ
* เมื่อป้อนข้อมูลในไคลเอนต์ ต้องแปลง "k" เป็นค่าจริง (ทางทฤษฎี 1k=1024 tokens; 1m=1024k tokens) เช่น 8k คือ 8×1024=8192 tokens แต่แนะนำให้ใช้ ×1000 ในทางปฏิบัติเพื่อป้องกันข้อผิดพลาด เช่น 8k เป็น 8×1000=8000, 1m=1×1000000=1000000
* หากค่าเอาต์พุตสูงสุดแสดงเป็น "-" หมายถึงไม่พบข้อมูลเอาต์พุตสูงสุดอย่างเป็นทางการสำหรับโมเดลนี้
{% endhint %}

<table><thead><tr><th width="313">ชื่อโมเดล</th><th width="158">อินพุตสูงสุด</th><th width="72">เอาต์พุตสูงสุด</th><th width="95">การเรียกฟังก์ชัน</th><th width="142">ความสามารถโมเดล</th><th width="540">ผู้ให้บริการ</th><th width="257">คำอธิบาย</th></tr></thead><tbody>
<tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>360AI_360gpt</td><td>โมเดลหลักระดับพันล้านพารามิเตอร์ที่ดีที่สุดของชุด 360 Zhinao เหมาะกับงานซับซ้อนหลายโดเมน</td></tr>
<tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>360AI_360gpt</td><td>โมเดลระดับร้อยล้านพารามิเตอร์ที่สมดุลระหว่างประสิทธิภาพและประสิทธิผล เหมาะกับงานที่ต้องการประสิทธิภาพ/ต้นทุนสูง</td></tr>
<tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>360AI_360gpt</td><td>โมเดลระดับร้อยล้านพารามิเตอร์ที่สมดุลระหว่างประสิทธิภาพและประสิทธิผล เหมาะกับงานที่ต้องการประสิทธิภาพ/ต้นทุนสูง</td></tr>
<tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>360AI_360gpt</td><td>โมเดลหลักระดับพันล้านพารามิเตอร์ที่ดีที่สุดของชุด 360 Zhinao เหมาะกับงานซับซ้อนหลายโดเมน</td></tr>
<tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>ไม่รองรับ</td><td>บทสนทนา, การรู้จำภาพ</td><td>Anthropic_claude</td><td>รุ่นสแนปช็อตเมื่อ 20 มิถุนายน 2024 Claude 3.5 Sonnet เป็นโมเดลสมดุลระหว่างประสิทธิภาพและความเร็ว รองรับอินพุตหลายรูปแบบ</td></tr>
<tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>Anthropic_claude</td><td>รุ่นสแนปช็อตเมื่อ 22 ตุลาคม 2024 Claude 3.5 Haiku พัฒนาทักษะการเขียนโค้ด การใช้เครื่องมือ และการให้เหตุผล เป็นโมเดลเร็วสุดในซีรีย์ Anthropic เหมาะกับแอปพลิเคชันอินเทอร์แอคทีฟ งานพิเศษ เช่น การสกัดข้อมูลและคอนเทนต์โมเดอเรชัน</td></tr>
<tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>ไม่รองรับ</td><td>บทสนทนา, การรู้จำภาพ</td><td>Anthropic_claude</td><td>รุ่นสแนปช็อตเมื่อ 22 ตุลาคม 2024 Claude 3.5 Sonnet มีความสามารถเหนือกว่า Opus และเร็วกว่า Sonnet พิเศษด้านการเขียนโปรแกรม วิทยาการข้อมูล การประมวลผลภาพ งานเอเจนต์</td></tr>
<tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>ไม่รองรับ</td><td>บทสนทนา, การรู้จำภาพ</td><td>Anthropic_claude</td><td>ชี้ไปยังรุ่น Claude 3.5 Sonnet ล่าสุด โดยอัตโนมัติ มีความสามารถเหนือกว่า Opus และเร็วกว่า Sonnet พิเศษด้านการเขียนโปรแกรม วิทยาการข้อมูล การประมวลผลภาพ งานเอเจนต์</td></tr>
<tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>ไม่รองรับ</td><td>บทสนทนา, การรู้จำภาพ</td><td>Anthropic_claude</td><td>Claude 3 Haiku เป็นโมเดลที่เร็วและกะทัดรัดที่สุดของ Anthropic ออกแบบมาเพื่อการตอบสนองเกือบทันที</td></tr>
<tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>ไม่รองรับ</td><td>บทสนทนา, การรู้จำภาพ</td><td>Anthropic_claude</td><td>Claude 3 Opus เป็นโมเดลทรงพลังที่สุดของ Anthropic สำหรับงานซับซ้อนสูง มีความสามารถสูงในด้านประสิทธิภาพ ความฉลาด ความลื่นไหล และความเข้าใจ</td></tr>
<tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>ไม่รองรับ</td><td>บทสนทนา, การรู้จำภาพ</td><td>Anthropic_claude</td><td>รุ่นสแนปช็อตเมื่อ 29 กุมภาพันธ์ 2024 Sonnet พิเศษด้าน:<br><br>- การเขียนโค้ด: สามารถเขียน แก้ไข และรันโค้ด พร้อมความสามารถให้เหตุผลและแก้ปัญหา<br>- วิทยาการข้อมูล: เพิ่มความเชี่ยวชาญด้านวิทยาการข้อมูลมนุษย์ สามารถจัดการข้อมูลไม่มีโครงสร้าง<br>- การประมวลผลภาพ: เก่งในการตีความแผนภูมิ กราฟ และภาพ<br>- งานเอเจนต์: ใช้เครื่องมือได้ดี เหมาะสำหรับงานเอเจนต์</td></tr>
<tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>Google_gamma</td><td>Gemma คือชุดโมเดลโอเพนซอร์สน้ำหนักเบา ล้ำสมัยที่พัฒนาโดย Google ใช้การวิจัยและเทคโนโลยีเดียวกับโมเดล Gemini เหมาะกับงานสร้างข้อความ เช่น ถามตอบ สรุปผล และการให้เหตุผล</td></tr>
<tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>ไม่รองรับ</td><td>บทสนทนา</td><td>Google_gamma</td><td>Gemma คือชุดโมเดลโอเพนซอร์สน้ำหนักเบา ล้ำสมัย โมเดลภาษาขนาดใหญ่แบบดีโคเดอร์เท่านั้น รองรับภาษาอังกฤษ เหมาะกับงานสร้างข้อความ เช่น ถามตอบ สรุปผล และการให้เหตุผล โมเดล 9B นี้ฝึกด้วย 8 ล้านล้านโทเค็น</td></tr>
<!-- Continue translating each row similarly following the same pattern -->
</tbody></table>