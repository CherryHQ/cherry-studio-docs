---
icon: book-bookmark
---

{% hint style="warning" %}
此文件由 AI 從中文翻譯而來，尚未經過審閱。
{% endhint %}

# 知識科普

## 什麼是 tokens？

Tokens 是 AI 模型處理文本的基本單位，可以理解為模型"思考"的最小單元。它不完全等同於我們理解的字符或單詞，而是模型自己的一種特殊的文本分割方式。

#### 1. 中文分詞

* 一個漢字通常會被編碼為 1-2 個 tokens
* 例如：`"你好"` ≈ 2-4 tokens

#### 2. 英文分詞

* 常見單詞通常是 1 個 token
* 較長或不常見的單詞會被分解成多個 tokens
* 例如：
  * `"hello"` = 1 token
  * `"indescribable"` = 4 tokens

#### 3. 特殊字符

* 空格、標點符號等也會佔用 tokens
* 換行符通常是 1 個 token

{% hint style="info" %}
不同服務商的 Tokenizer 都不一樣，甚至同服務商不同模型的 Tokenizer 也有所差別，該知識僅用於明確 token 的概念。
{% endhint %}

***

## 什麼是 Tokenizer？

Tokenizer（分詞器）是 AI 模型將文本轉換為 tokens 的工具。它決定了如何把輸入文本切分成模型可以理解的最小單位。

### 為什麼不同模型的 Tokenizer 不一樣？

#### 1. 訓練數據不同

* 不同的語料庫導致優化方向不同
* 多語言支援程度差異
* 特定領域（醫療、法律等）的專門優化

#### 2. 分詞算法不同

* BPE (Byte Pair Encoding) - OpenAI GPT 系列
* WordPiece - Google BERT
* SentencePiece - 適合多語言場景

#### 3. 優化目標不同

* 有的注重壓縮效率
* 有的注重語意保留
* 有的注重處理速度

### 實際影響

同樣的文本在不同模型中的 token 數量可能不同：

```
輸入："Hello, world!"
GPT-3: 4 tokens
BERT: 3 tokens
Claude: 3 tokens
```

***

## 什麼是嵌入模型 (Embedding Model)?

**基本概念：** 嵌入模型是一種將高維離散數據（文本、圖像等）轉換為低維連續向量的技術，這種轉換讓機器能更好地理解和處理複雜數據。想像一下，就像把複雜的拼圖簡化成一個簡單的座標點，但這個點仍然保留了拼圖的關鍵特徵。在大模型生態中，它作為"翻譯官"，將人類可理解的信息轉換為 AI 可計算的數字形式。

**工作原理：** 以自然語言處理為例，嵌入模型可以將詞語映射到向量空間中的特定位置。在這個空間裡，語義相近的詞會自動聚集在一起。比如：

* "國王"和"王后"的向量會很接近
* "貓"和"狗"這樣的寵物詞也會距離相近
* 而"汽車"和"麵包"這樣語義無關的詞則會距離較遠

**主要應用場景：**

* 文本分析：文件分類、情感分析
* 推薦系統：個性化內容推薦
* 圖像處理：相似圖片檢索
* 搜索引擎：語義搜索優化

**核心優勢：**

1. 降維效果：將複雜數據簡化為易處理的向量形式
2. 語義保持：保留原始數據中的關鍵語義信息
3. 計算效率：顯著提升機器學習模型的訓練和推理效率

**技術價值：** 嵌入模型是現代 AI 系統的基礎組件，為機器學習任務提供了高質量的數據表示，是推動自然語言處理、計算機視覺等領域發展的關鍵技術。

***

## Embedding 模型在知識檢索中的工作原理

**基本工作流程：**

1. **知識庫預處理階段**

* 將文件分割成適當大小的 chunk（文本塊）
* 使用 embedding 模型將每個 chunk 轉換為向量
* 將向量和原文存儲到向量數據庫中

2. **查詢處理階段**

* 將用戶問題轉換為向量
* 在向量庫中檢索相似內容
* 將檢索到的相關內容作為上下文提供給 LLM

***

## **什麼是 MCP（Model Context Protocol）？**

MCP 是一種開源協議，旨在以標準化的方式向大型語言模型（LLM）提供上下文信息。

* **類比理解：** 可以把 MCP 想像成 AI 領域的「U盤」。我們知道，U盤可以存儲各種文件，插入電腦後就能直接使用。類似地，MCP Server 上可以「插」上各種提供上下文的「插件」，LLM 可以根據需要向 MCP Server 請求這些插件，從而獲取更豐富的上下文信息，增強自身能力。
* **與 Function Tool 的對比：** 傳統的 Function Tool（函數工具）也可以為 LLM 提供外部功能，但 MCP 更像是一種更高維度的抽象。Function Tool 更多的是針對具體任務的工具，而 MCP 則提供了一種更通用的、模塊化的上下文獲取機制。

### **MCP 的核心優勢**

1. **標準化：** MCP 提供了統一的接口和數據格式，使得不同的 LLM 和上下文提供者可以無縫協作。
2. **模塊化：** MCP 允許開發者將上下文信息分解為獨立的模塊（插件），方便管理和複用。
3. **靈活性：** LLM 可以根據自身需求動態選擇所需的上下文插件，實現更智能、更個性化的互動。
4. **可擴展性：** MCP 的設計支援未來添加更多類型的上下文插件，為 LLM 的能力拓展提供了無限可能。