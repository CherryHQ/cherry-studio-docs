---
icon: message
---

{% hint style="warning" %}
This document was translated from Chinese by AI and has not yet been reviewed.
{% endhint %}

# Chat Interface

## Assistants and Topics

### Assistants

An `Assistant` is a personalized configuration for the selected model, such as preset prompts and parameters. These settings help the model better align with your expected workflow.

The `System Default Assistant` comes with relatively universal parameters (without prompts). You can use it directly or find the presets you need on the [Agents page](agents.md).

### Topics

The `Assistant` is the parent set of `Topics`. A single assistant can create multiple topics (i.e., conversations). All `Topics` share the parameter settings and preset prompts (prompt) of the `Assistant`.

<figure><img src="../../.gitbook/assets/image (4) (1) (1).png" alt=""><figcaption></figcaption></figure>

<figure><img src="../../.gitbook/assets/image (5) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>

## Chat Buttons

<figure><img src="../../.gitbook/assets/对话界面/对话框.png" alt=""><figcaption></figcaption></figure>

![](../../.gitbook/assets/对话界面/新话题.png) `New Topic` Creates a new topic under the current assistant.

![](../../.gitbook/assets/对话界面/上传图片或文档.png) `Upload Image or Document` Image upload requires model support. Uploading documents will automatically parse text as context for the model.

![](../../.gitbook/assets/对话界面/网络搜索.png) `Web Search` Requires configuration of web search information in settings. Search results are provided as context to the LLM. See [Web Search Mode](../../websearch/).

![](../../.gitbook/assets/对话界面/知识库.png) `Knowledge Base` Enables the knowledge base. See [Knowledge Base Tutorial](../../knowledge-base/knowledge-base.md).

![](<../../.gitbook/assets/对话界面/MCP 服务器.png>) `MCP Server` Enables MCP server functionality. See [MCP Usage Tutorial](../../advanced-basic/mcp/).

![](../../.gitbook/assets/对话界面/生成图片.png) `Generate Image` Hidden by default. For models that support image generation (e.g., Gemini), manually enable this button to generate images.

{% hint style="info" %}
Due to technical reasons, you must manually enable this button to generate images. This button will be removed after optimization.
{% endhint %}

![](../../.gitbook/assets/对话界面/选择模型.png) `Select Model` Switches to the specified model for subsequent conversations while preserving context.

![](../../.gitbook/assets/对话界面/快捷短语.png) `Quick Phrases` Requires predefined common phrases in settings. Invoke them here for direct input, supporting variables.

![](../../.gitbook/assets/对话界面/清空消息.png) `Clear Messages` Deletes all content in this topic.

![](../../.gitbook/assets/对话界面/展开.png) `Expand` Enlarges the dialog box for long text input.

![](../../.gitbook/assets/对话界面/清除上下文.png) `Clear Context` Truncates the context available to the model without deleting content—the model "forgets" previous conversation content.

![](<../../.gitbook/assets/对话界面/预估 Token 数.png>) `Estimated Token Count` Shows estimated token usage: `Current Context`, `Max Context` (∞ indicates unlimited context), `Current Message Word Count`, and `Estimated Tokens`.

{% hint style="info" %}
This function is for estimation only. Actual token counts vary by model—refer to model provider data.
{% endhint %}

![](../../.gitbook/assets/对话界面/翻译.png) `Translate` Translates the current input box content into English.

## Chat Settings

<figure><img src="../../.gitbook/assets/image (7) (1) (1).png" alt=""><figcaption></figcaption></figure>

### Model Settings

Model settings synchronize with the `Model Settings` parameters in assistant settings. See [Edit Assistant](chat.md#bian-ji-zhu-shou).

{% hint style="info" %}
In chat settings, only the model settings apply to the current assistant. Other settings apply globally. For example, setting the message style to bubbles applies to all topics under all assistants.
{% endhint %}

### Message Settings

#### <mark style="color:blue;">**`Message Separator`**</mark>:

Uses a divider to separate message content from the action bar.

{% tabs %}
{% tab title="Enabled" %}
<figure><img src="../../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>
{% endtab %}

{% tab title="Disabled" %}
<figure><img src="../../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>
{% endtab %}
{% endtabs %}

#### <mark style="color:blue;">**`Use Serif Font`**</mark>:

Switches font style. You can also change fonts via [Custom CSS](../../personalization-settings/).

#### <mark style="color:blue;">**`Show Line Numbers for Code`**</mark>:

Displays line numbers in code blocks generated by the model.

{% tabs %}
{% tab title="Disabled" %}
<figure><img src="../../.gitbook/assets/image (2) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>
{% endtab %}

{% tab title="Enabled" %}
<figure><img src="../../.gitbook/assets/image (3) (1).png" alt=""><figcaption></figcaption></figure>
{% endtab %}
{% endtabs %}

#### <mark style="color:blue;">**`Collapsible Code Blocks`**</mark>:

Automatically collapses code blocks when code snippets are long.

#### <mark style="color:blue;">**`Wrap Lines in Code Blocks`**</mark>:

Enables automatic line wrapping when single-line code exceeds window width.

#### <mark style="color:blue;">**`Auto-Collapse Reasoning Content`**</mark>:

Automatically collapses reasoning processes for models that support step-by-step thinking.

#### <mark style="color:blue;">**`Message Style`**</mark>:

Switches chat interface to bubble style or list style.

#### <mark style="color:blue;">**`Code Style`**</mark>:

Changes display style for code snippets.

#### <mark style="color:blue;">**`Math Formula Engine`**</mark>:

* KaTeX: Faster rendering with performance optimization
* MathJax: Slower rendering with comprehensive symbol and command support

#### <mark style="color:blue;">**`Message Font Size`**</mark>:

Adjusts font size in the chat interface.

### Input Settings

#### <mark style="color:blue;">**`Show Estimated Token Count`**</mark>:

Displays estimated token consumption for input text in the input box (reference only, not actual context tokens).

#### <mark style="color:blue;">**`Paste Long Text as File`**</mark>:

Long text pasted into the input box automatically appears as files to reduce input interference.

#### <mark style="color:blue;">**`Render Input Messages with Markdown`**</mark>:

When disabled, only renders model responses, not sent messages.

{% tabs %}
{% tab title="Disabled" %}
<figure><img src="../../.gitbook/assets/image (4) (1).png" alt="" width="563"><figcaption></figcaption></figure>
{% endtab %}

{% tab title="Enabled" %}
<figure><img src="../../.gitbook/assets/image (7) (1).png" alt="" width="563"><figcaption></figcaption></figure>
{% endtab %}
{% endtabs %}

#### <mark style="color:blue;">**`Triple-Space Translation`**</mark>:

Tap spacebar three times to translate input content to English after typing a message.

{% hint style="warning" %}
Note: This action overwrites the original text.
{% endhint %}

#### <mark style="color:blue;">**`Target Language`**</mark>:

Sets target language for both translation button and triple-space translation.

## Assistant Settings

In the assistant interface, select the <mark style="background-color:yellow;">assistant name</mark> → choose corresponding settings in the <mark style="background-color:yellow;">right-click menu</mark>

### Edit Assistant

{% hint style="info" %}
Assistant settings apply to all topics under that assistant.
{% endhint %}

<figure><img src="../../.gitbook/assets/image (6) (1) (1).png" alt=""><figcaption></figcaption></figure>

#### Prompt Settings

#### <mark style="color:blue;">**`Name`**</mark>:

Customizable assistant name for easy identification.

#### <mark style="color:blue;">**`Prompt`**</mark>:

i.e., prompt. Edit content following prompt writing examples on the Agents page.

#### Model Settings

#### <mark style="color:blue;">**`Default Model`**</mark>:

Sets a fixed default model for the assistant. When adding from Agents page or copying assistant, initial model uses this setting. If unset, initial model = global default model (see [Default Assistant Model](settings/default-models.md#mo-ren-zhu-shou-mo-xing)).

{% hint style="info" %}
Two default models exist: [Global Default Chat Model](settings/default-models.md#mo-ren-zhu-shou-mo-xing) and Assistant Default Model. The assistant's model has higher priority. When unset: Assistant Default Model = Global Default Chat Model.
{% endhint %}

#### <mark style="color:blue;">**`Auto-Reset Model`**</mark>:

When enabled: After switching models during conversation, creating a new topic resets to assistant's default model. When disabled: New topics inherit the previous topic's model.

> Example: Assistant default model = gpt-3.5-turbo. Create Topic 1 → switch to gpt-4o during conversation.
> - Enabled Auto-Reset: Topic 2 uses gpt-3.5-turbo
> - Disabled Auto-Reset: Topic 2 uses gpt-4o

#### <mark style="color:blue;">**`Temperature`**</mark>:

Controls randomness/creativity of text generation (default=0.7):
* Low (0-0.3): More deterministic output. Ideal for code generation, data analysis
* Medium (0.4-0.7): Balanced creativity/coherence. Recommended for chatbots (~0.5)
* High (0.8-1.0): High creativity/diversity. Ideal for creative writing, but reduces coherence

#### <mark style="color:blue;">**`Top P (Nucleus Sampling)`**</mark>:

Default=1. Lower values → more focused/comprehensible responses. Higher values → wider vocabulary diversity.

Sampling controls token probability thresholds:
* Low (0.1-0.3): Conservative output. Ideal for code comments/tech docs
* Medium (0.4-0.6): Balanced diversity/accuracy. General dialogue/writing
* High (0.7-1.0): Diverse expression. Creative writing scenarios

{% hint style="info" %}
- Parameters work independently or combined
- Choose values based on task type
- Experiment to find optimal combinations
- Ranges are illustrative—consult model documentation for specifics
{% endhint %}

#### <mark style="color:blue;">**`Context Window`**</mark>

Number of messages to retain in context. Higher values → longer context → higher token usage:
* 5-10: Normal conversations
* \>10: Complex tasks requiring longer memory (e.g., multi-step content generation)
* Note: More messages = higher token consumption

#### <mark style="color:blue;">**`Enable Message Length Limit (MaxToken)`**</mark>

Sets maximum [tokens](https://docs.cherry-ai.com/question-contact/knowledge#shen-me-shi-tokens) per response. Directly impacts answer quality/length.

> Example: When testing model connectivity, set MaxToken=1 to confirm response without specific content.

Most models support up to 32k tokens (some 64k+—check model documentation).

{% hint style="success" %}
Suggestions:
* Normal chat: 500-800
* Short text gen: 800-2000
* Code gen: 2000-3600
* Long text gen: 4000+ (requires model support)
{% endhint %}

{% hint style="warning" %}
Responses are truncated at MaxToken limit. Incomplete expressions or truncation (e.g., long code) may occur—adjust as needed.
{% endhint %}

#### <mark style="color:blue;">**`Stream Output`**</mark>

Enables continuous data stream processing instead of batch transmission. Provides real-time response generation (typing effect) in clients like CherryStudio.

* Disabled: Full response delivered at once (like WeChat messages)
* Enabled: Character-by-character output (generates → transmits each token immediately)

{% hint style="info" %}
Disable for models without streaming support (e.g., initial o1-mini versions).
{% endhint %}

#### <mark style="color:blue;">**`Custom Parameters`**</mark>

Adds extra request parameters to the body (e.g., `presence_penalty`). Generally not needed for regular use.

> Parameters like top-p, max_tokens, and stream belong to this category.

Format: Parameter name—Parameter type (text/number/etc.)—Value. See documentation: [Click here](https://openai.apifox.cn/doc-3222739)

{% hint style="info" %}
Model providers often have unique parameters—consult their documentation.
{% endhint %}

{% hint style="info" %}
* Custom parameters override built-in parameters when names conflict.
> Example: Setting `model: gpt-4o` forces all conversations to use gpt-4o regardless of selection.
* Use <kbd>parameter_name: undefined</kbd> to exclude parameters.
{% endhint %}