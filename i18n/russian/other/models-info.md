
{% hint style="warning" %}
Этот документ переведен с китайского языка с помощью ИИ и еще не был проверен.
{% endhint %}

# Общие сведения о моделях

{% hint style="info" %}
* Следующая информация предоставлена для справки; при обнаружении ошибок вы можете связаться для исправления. Некоторые модели от разных поставщиков могут иметь различия в размере контекста и характеристиках;
* При вводе данных в клиент необходимо преобразовать "k" в фактическое значение (теоретически 1k = 1024 токенов; 1m = 1024k токенов). Например, 8k равно 8×1024=8192 токенов. Рекомендуется при практическом использовании умножать на 1000, чтобы избежать ошибок: 8k = 8×1000=8000, 1m=1×1000000=1000000;
* Модели со значением "—" в поле "Максимальный вывод" не имеют официально подтверждённой информации об этом параметре.
{% endhint %}

<table><thead><tr><th width="313">Название модели</th><th width="158">Максимальный ввод</th><th width="72">Максимальный вывод</th><th width="95">Вызов функций</th><th width="142">Возможности модели</th><th width="540">Провайдер</th><th width="257">Описание</th></tr></thead><tbody><tr><td>360gpt-pro</td><td>8k</td><td>-</td><td>Не поддерживается</td><td>Диалог</td><td>360AI_360gpt</td><td>Флагманская модель серии 360 Brain мощностью в миллиарды параметров, широко применяемая для решения сложных задач в различных областях.</td></tr><tr><td>360gpt-turbo</td><td>7k</td><td>-</td><td>Не поддерживается</td><td>Диалог</td><td>360AI_360gpt</td><td>Модель мощностью в миллиарды параметров, сочетающая производительность и эффективность, подходит для сценариев с высокими требованиями к производительности/стоимости.</td></tr><tr><td>360gpt-turbo-responsibility-8k</td><td>8k</td><td>-</td><td>Не поддерживается</td><td>Диалог</td><td>360AI_360gpt</td><td>Модель мощностью в миллиарды параметров, сочетающая производительность и эффективность, подходит для сценариев с высокими требованиями к производительности/стоимости.</td></tr><tr><td>360gpt2-pro</td><td>8k</td><td>-</td><td>Не поддерживается</td><td>Диалог</td><td>360AI_360gpt</td><td>Флагманская модель серии 360 Brain мощностью в миллиарды параметров, широко применяемая для решения сложных задач в различных областях.</td></tr><tr><td>claude-3-5-sonnet-20240620</td><td>200k</td><td>16k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Anthropic_claude</td><td>Снимок версии от 20 июня 2024 года. Claude 3.5 Sonnet — сбалансированная модель, сочетающая высокую производительность и скорость, поддерживающая многомодальный ввод.</td></tr><tr><td>claude-3-5-haiku-20241022</td><td>200k</td><td>16k</td><td>Не поддерживается</td><td>Диалог</td><td>Anthropic_claude</td><td>Снимок версии от 22 октября 2024 года. Claude 3.5 Haiku улучшен по всем направлениям, включая кодирование, использование инструментов и рассуждение. Будучи самой быстрой моделью в серии Anthropic, обеспечивает быстрое время отклика, подходит для интерактивных приложений, таких как пользовательские чат-боты и мгновенное дополнение кода. Также отлично справляется со специализированными задачами: извлечение данных и модерация контента в реальном времени. Многофункциональный инструмент для широкого применения в различных отраслях. Не поддерживает ввод изображений.</td></tr><tr><td>claude-3-5-sonnet-20241022</td><td>200k</td><td>8K</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Anthropic_claude</td><td>Снимок версии от 22 октября 2024 года. Claude 3.5 Sonnet превосходит Opus по возможностям и работает быстрее, чем Sonnet, сохраняя ту же цену. Sonnet особенно сильна в программировании, data science, обработке изображений и агентских задачах.</td></tr><tr><td>claude-3-5-sonnet-latest</td><td>200K</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Anthropic_claude</td><td>Динамически обновляется до последней версии Claude 3.5 Sonnet. Claude 3.5 Sonnet превосходит Opus по возможностям и работает быстрее, чем Sonnet, сохраняя ту же цену. Sonnet особенно сильна в программировании, data science, обработке изображений и агентских задачах. Эта модель всегда указывает на последнюю версию.</td></tr><tr><td>claude-3-haiku-20240307</td><td>200k</td><td>4k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Anthropic_claude</td><td>Claude 3 Haiku — самая быстрая и компактная модель от Anthropic, обеспечивающая почти мгновенный отклик. Отличается быстрыми и точными возможностями целевой обработки.</td></tr><tr><td>claude-3-opus-20240229</td><td>200k</td><td>4k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Anthropic_claude</td><td>Claude 3 Opus — самая мощная модель от Anthropic для решения сложных задач. Выдаётся производительностью, интеллектом, беглостью и пониманием.</td></tr><tr><td>claude-3-sonnet-20240229</td><td>200k</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Anthropic_claude</td><td>Снимок версии от 29 февраля 2024 года. Sonnet особенно хороша в:<br><br>- Кодировании: способна самостоятельно писать, редактировать и запускать код, обладает способностью рассуждать и устранять неполадки<br>- Data Science: расширяет экспертные знания в data science; может обрабатывать неструктурированные данные с помощью различных инструментов для получения аналитики<br>- Обработке изображений: отлично интерпретирует схемы, графики и изображения, точно преобразует текст для получения аналитики за пределами самого текста<br>- Агентских задачах: превосходна в использовании инструментов, идеальна для агентских задач (сложное многоступенчатое решение задач, требующее взаимодействия с другими системами)</td></tr><tr><td>google/gemma-2-27b-it</td><td>8k</td><td>-</td><td>Не поддерживается</td><td>Диалог</td><td>Google_gamma</td><td>Gemma — серия современных легковесных открытых моделей, разработанных Google с использованием тех же исследований и технологий, что и модели Gemini. Это большие языковые модели только с декодером, поддерживающие английский язык, доступны в виде открытых весов с предобученными и настроенными вариантами. Модели Gemma подходят для различных задач генерации текста, включая ответы на вопросы, суммирование и рассуждения.</td></tr><tr><td>google/gemma-2-9b-it</td><td>8k</td><td>-</td><td>Не поддерживается</td><td>Диалог</td><td>Google_gamma</td><td>Gemma — одна из серий современных легковесных открытых моделей, разработанных Google. Это большая языковая модель только с декодером, поддерживающая английский язык, доступна с открытыми весами, предобученными и настроенными вариантами. Модели Gemma подходят для различных задач генерации текста, включая ответы на вопросы, суммирование и рассуждения. Эта 9B-модель обучена на 8 триллионах токенов.</td></tr><tr><td>gemini-1.5-pro</td><td>2m</td><td>8k</td><td>Не поддерживается</td><td>Диалог</td><td>Google_gemini</td><td>Последняя стабильная версия Gemini 1.5 Pro. Мощная многомодальная модель, способная обрабатывать до 60 тысяч строк кода или 2000 страниц текста. Особенно подходит для задач, требующих сложных рассуждений.</td></tr><tr><td>gemini-1.0-pro-001</td><td>33k</td><td>8k</td><td>Не поддерживается</td><td>Диалог</td><td>Google_gemini</td><td>Это стабильная версия Gemini 1.0 Pro. Как NLP-модель, она специализируется на задачах многораундового чата с текстом и кодом, а также генерации кода. Модель будет отключена 15 февраля 2025 года, рекомендуется перейти на серию 1.5.</td></tr><tr><td>gemini-1.0-pro-002</td><td>32k</td><td>8k</td><td>Не поддерживается</td><td>Диалог</td><td>Google_gemini</td><td>Это стабильная версия Gemini 1.0 Pro. Как NLP-модель, она специализируется на задачах многораундового чата с текстом и кодом, а также генерации кода. Модель будет отключена 15 февраля 2025 года, рекомендуется перейти на серию 1.5.</td></tr><tr><td>gemini-1.0-pro-latest</td><td>33k</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Устаревший или скоро устареет</td><td>Google_gemini</td><td>Последняя версия Gemini 1.0 Pro. Как NLP-модель, она специализируется на задачах многораундового чата с текстом и кодом, а также генерации кода. Модель будет отключена 15 февраля 2025 года, рекомендуется перейти на серию 1.5.</td></tr><tr><td>gemini-1.0-pro-vision-001</td><td>16k</td><td>2k</td><td>Не поддерживается</td><td>Диалог</td><td>Google_gemini</td><td>Это визуальная версия Gemini 1.0 Pro. Модель будет отключена 15 февраля 2025 года, рекомендуется перейти на серию 1.5.</td></tr><tr><td>gemini-1.0-pro-vision-latest</td><td>16k</td><td>2k</td><td>Не поддерживается</td><td>Распознавание изображений</td><td>Google_gemini</td><td>Последняя визуальная версия Gemini 1.0 Pro. Модель будет отключена 15 февраля 2025 года, рекомендуется перейти на серию 1.5.</td></tr><tr><td>gemini-1.5-flash</td><td>1m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Последняя стабильная версия Gemini 1.5 Flash. Сбалансированная многомодальная модель, способная обрабатывать аудио, изображения, видео и текстовый ввод.</td></tr><tr><td>gemini-1.5-flash-001</td><td>1m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Стабильная версия Gemini 1.5 Flash. Они предоставляют те же базовые функции, что и gemini-1.5-flash, но имеют фиксированную версию, подходящую для производственной среды.</td></tr><tr><td>gemini-1.5-flash-002</td><td>1m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Стабильная версия Gemini 1.5 Flash. Они предоставляют те же базовые функции, что и gemini-1.5-flash, но имеют фиксированную версию, подходящую для производственной среды.</td></tr><tr><td>gemini-1.5-flash-8b</td><td>1m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Gemini 1.5 Flash-8B — это новейшая многомодальная модель искусственного интеллекта от Google, разработанная для эффективной обработки крупномасштабных задач. Модель с 8 миллиардами параметров поддерживает ввод текста, изображений, аудио и видео, что делает её применимой в различных сценариях, таких как чат, транскрибирование и перевод. По сравнению с другими моделями Gemini, Flash-8B оптимизирован по скорости и экономической эффективности, особенно привлекателен для пользователей, чувствительных к стоимости. Его скоростные ограничения увеличены вдвое, что позволяет разработчикам эффективно обрабатывать крупномасштабные задачи. Кроме того, Flash-8B использует технологию "дистилляции знаний", извлекая ключевые знания из более крупной модели, гарантируя легковесность и эффективность при сохранении основных возможностей</td></tr><tr><td>gemini-1.5-flash-exp-0827</td><td>1m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Экспериментальная версия Gemini 1.5 Flash, регулярно обновляемая с последними улучшениями. Подходит для исследовательского тестирования и разработки прототипов, не рекомендуется для производственной среды.</td></tr><tr><td>gemini-1.5-flash-latest</td><td>1m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Передовая версия Gemini 1.5 Flash, регулярно обновляемая с последними улучшениями. Подходит для исследовательского тестирования и разработки прототипов, не рекомендуется для производственной среды.</td></tr><tr><td>gemini-1.5-pro-001</td><td>2m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Стабильная версия Gemini 1.5 Pro с фиксированным поведением модели и характеристиками производительности. Подходит для производственной среды, требующей стабильности.</td></tr><tr><td>gemini-1.5-pro-002</td><td>2m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Стабильная версия Gemini 1.5 Pro с фиксированным поведением модели и характеристиками производительности. Подходит для производственной среды, требующей стабильности.</td></tr><tr><td>gemini-1.5-pro-exp-0801</td><td>2m</td><td>8k</td><td>Не поддерживается</td><td>Диалог,Распознавание изображений</td><td>Google_gemini</td><td>Экспериментальная версия Gemini 1.5 Pro.