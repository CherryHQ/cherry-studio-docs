---
icon: book-bookmark
---

{% hint style="warning" %}
Этот документ переведен с китайского языка с помощью ИИ и еще не был проверен.
{% endhint %}

# Научные знания

## Что такое токены?

Токены — это базовые единицы обработки текста в AI-моделях, которые можно рассматривать как минимальные "мыслительные" элементы модели. Они не полностью эквивалентны символам или словам в человеческом понимании, а представляют собой особый способ разделения текста, используемый самой моделью.

#### 1. Токенизация китайского языка
* Один иероглиф обычно кодируется в 1-2 токена
* Например: `"你好"` ≈ 2-4 токена

#### 2. Токенизация английского языка
* Распространенные слова обычно составляют 1 токен
* Длинные или редкие слова разбиваются на несколько токенов
* Например:
  * `"hello"` = 1 токен
  * `"indescribable"` = 4 токена

#### 3. Специальные символы
* Пробелы, пунктуация и другие символы также занимают токены
* Символ новой строки обычно составляет 1 токен

{% hint style="info" %}
У разных провайдеров токенизаторы разные, и даже у разных моделей одного провайдера могут быть различия. Эта информация предназначена только для понимания концепции токенов.
{% endhint %}

***

## Что такое токенизатор?

Токенизатор (Tokenizer) — это инструмент AI-модели для преобразования текста в токены. Он определяет, как входной текст разбивается на минимальные единицы, понятные модели.

### Почему токенизаторы различаются у разных моделей?

#### 1. Разные обучающие данные
* Разные корпуса данных приводят к разным оптимизациям
* Разный уровень поддержки многоязычности
* Специальная оптимизация для конкретных областей (медицина, юриспруденция и т.д.)

#### 2. Разные алгоритмы токенизации
* BPE (Byte Pair Encoding) - OpenAI GPT series
* WordPiece - Google BERT
* SentencePiece - оптимален для многоязычных сценариев

#### 3. Разные цели оптимизации
* Одни фокусируются на эффективности сжатия
* Другие на сохранении семантики
* Третьи на скорости обработки

### Практическое влияние
Один и тот же текст может иметь разное количество токенов в разных моделях:

```
Ввод: "Hello, world!"
GPT-3: 4 токена
BERT: 3 токена
Claude: 3 токена
```

***

## Что такое модели эмбеддингов (Embedding Model)?

**Базовое понятие:** Модель эмбеддингов — это технология преобразования высокоразмерных дискретных данных (текст, изображения и т.д.) в низкоразмерные непрерывные векторы. Этот процесс позволяет машинам лучше понимать и обрабатывать сложные данные. Представьте, что сложный пазл упрощается до простой координатной точки, сохраняющей ключевые характеристики оригинала. В экосистеме больших моделей эмбеддинги выступают "переводчиками", преобразующими информацию, понятную человеку, в числовую форму, понятную ИИ.

**Принцип работы:** В обработке естественного языка модели эмбеддингов сопоставляют слова с определенными позициями в векторном пространстве. В этом пространстве семантически близкие слова автоматически группируются. Например:
* Векторы "король" и "королева" будут близки
* Слова для домашних животных, такие как "кот" и "собака", также окажутся рядом
* Семантически несвязанные слова, например "автомобиль" и "хлеб", будут далеки друг от друга

**Основные сценарии применения:**
* Анализ текста: классификация документов, анализ тональности
* Рекомендательные системы: персонализированные предложения контента
* Обработка изображений: поиск похожих изображений
* Поисковые системы: оптимизация семантического поиска

**Ключевые преимущества:**
1. Снижение размерности: упрощение сложных данных до управляемой векторной формы
2. Сохранение семантики: сохранение ключевой смысловой информации исходных данных
3. Вычислительная эффективность: значительное ускорение обучения и вывода моделей машинного обучения

**Технологическая ценность:** Модели эмбеддингов являются фундаментальным компонентом современных AI-систем, обеспечивая высококачественное представление данных для задач машинного обучения, и служат ключевой технологией для развития обработки естественного языка и компьютерного зрения.

***

## Принцип работы моделей эмбеддингов при поиске знаний

**Базовый рабочий процесс:**

1. **Этап предобработки базы знаний**
* Разделение документов на фрагменты (chunks) подходящего размера
* Преобразование каждого фрагмента в вектор с помощью модели эмбеддингов
* Сохранение векторов и исходного текста в векторной базе данных

2. **Этап обработки запроса**
* Преобразование пользовательского вопроса в вектор
* Поиск похожего контента в векторной базе
* Передача найденного релевантного контента LLM в качестве контекста

***

## Что такое MCP (Model Context Protocol)?

MCP — это открытый протокол, предназначенный для стандартизированной передачи контекстной информации крупным языковым моделям (LLM).

* **Аналогия:** MCP можно представить как "USB-флешку" для мира ИИ. Мы знаем, что флешка хранит различные файлы и при подключении к компьютеру сразу готова к использованию. Аналогично, на MCP Server можно "подключать" различные "плагины", предоставляющие контекст. LLM могут запрашивать эти плагины при необходимости, получая более богатый контекст для усиления своих возможностей.
* **Сравнение с Function Tool:** Традиционные Function Tools (функциональные инструменты) также предоставляют LLM внешние функции, но MCP представляет собой более высокоуровневую абстракцию. Function Tools в основном ориентированы на конкретные задачи, тогда как MCP предлагает универсальный модульный механизм получения контекста.

### Ключевые преимущества MCP

1. **Стандартизация:** MCP предоставляет унифицированный интерфейс и формат данных, обеспечивая бесшовное взаимодействие между различными LLM и поставщиками контекста.
2. **Модульность:** Позволяет разработчикам разбивать контекстную информацию на независимые модули (плагины), упрощая управление и повторное использование.
3. **Гибкость:** LLM могут динамически выбирать нужные контекстные плагины, обеспечивая более интеллектуальное и персонализированное взаимодействие.
4. **Масштабируемость:** Конструкция MCP поддерживает добавление новых типов контекстных плагинов, открывая безграничные возможности для расширения функциональности LLM.

***