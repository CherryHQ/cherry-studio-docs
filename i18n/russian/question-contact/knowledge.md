---
icon: book-bookmark
---

{% hint style="warning" %}
Этот документ переведен с китайского языка с помощью ИИ и еще не был проверен.
{% endhint %}

# Научно-популярная информация

## Что такое токены?

Токены — это базовые единицы обработки текста в AI-моделях, которые можно понимать как минимальные "мыслительные" элементы модели. Они не полностью эквивалентны символам или словам в человеческом понимании, а представляют собой особый способ сегментации текста самой моделью.

#### 1. Токенизация китайского языка

* Один иероглиф обычно кодируется в 1-2 токена
* Пример: `"你好"` ≈ 2-4 токена

#### 2. Токенизация английского языка

* Распространённые слова обычно занимают 1 токен
* Длинные или редкие слова разбиваются на несколько токенов
* Пример:
  * `"hello"` = 1 токен
  * `"indescribable"` = 4 токена

#### 3. Специальные символы

* Пробелы, пунктуация и т.д. также занимают токены
* Перевод строки обычно занимает 1 токен

{% hint style="info" %}
Токенизаторы у разных провайдеров отличаются, и даже у разных моделей одного провайдера могут быть различия. Эта информация предназначена только для понимания концепции токена.
{% endhint %}

***

## Что такое токенизатор (Tokenizer)?

Токенизатор — это инструмент в AI-моделях, который преобразует текст в токены. Он определяет, как разбивать входной текст на минимальные единицы, понятные модели.

### Почему токенизаторы различаются у разных моделей?

#### 1. Разные обучающие данные

* Разные корпуса текстов приводят к разным оптимизациям
* Различия в поддержке многоязычности
* Специализированные оптимизации для определённых доменов (медицина, юриспруденция и т.д.)

#### 2. Разные алгоритмы сегментации

* BPE (Byte Pair Encoding) — серия GPT от OpenAI
* WordPiece — Google BERT
* SentencePiece — подходит для многоязычных сценариев

#### 3. Разные цели оптимизации

* Одни фокусируются на эффективности сжатия
* Другие на сохранении семантики
* Третьи на скорости обработки

### Практическое влияние

Один и тот же текст в разных моделях может иметь разное количество токенов:

```
Ввод: "Hello, world!"
GPT-3: 4 токена
BERT: 3 токена
Claude: 3 токена
```

***

## Что такое модели эмбеддингов (Embedding Model)?

**Основная концепция:** Модели эмбеддингов — это технология преобразования высокоразмерных дискретных данных (текст, изображения и т.д.) в низкоразмерные непрерывные векторы. Это позволяет машинам лучше понимать и обрабатывать сложные данные. Представьте упрощение сложного пазла до простой координатной точки, сохраняющей ключевые характеристики. В экосистеме больших моделей они выступают "переводчиками", преобразующими информацию в численную форму, понятную ИИ.

**Принцип работы:** В обработке естественного языка модели эмбеддингов отображают слова в определённые точки векторного пространства, где семантически близкие слова автоматически группируются. Например:

* Векторы "король" и "королева" будут близки
* Такие слова как "кот" и "собака" также будут близки
* А семантически несвязанные слова вроде "автомобиль" и "хлеб" будут далеки

**Основные сценарии применения:**

* Анализ текста: классификация документов, анализ тональности
* Рекомендательные системы: персонализированный контент
* Обработка изображений: поиск похожих картинок
* Поисковые системы: оптимизация семантического поиска

**Ключевые преимущества:**

1. Снижение размерности: упрощение сложных данных до векторов
2. Сохранение семантики: удержание ключевой смысловой информации
3. Вычислительная эффективность: ускорение обучения и вывода моделей

**Технологическая ценность:** Модели эмбеддингов — фундаментальные компоненты современных ИИ-систем, обеспечивающие качественное представление данных для машинного обучения и движущие развитие обработки естественного языка и компьютерного зрения.

***

## Принцип работы моделей Embedding в поиске знаний

**Базовый рабочий процесс:**

1. **Предобработка базы знаний**

* Разделение документов на фрагменты подходящего размера (chunk)
* Преобразование каждого фрагмента в вектор с помощью модели embedding
* Сохранение векторов и оригинальных текстов в векторной БД

2. **Обработка запроса**

* Преобразование пользовательского вопроса в вектор
* Поиск похожего контента в векторной БД
* Предоставление найденного контекста LLM

***

## Что такое MCP (Model Context Protocol)?

MCP — это открытый протокол, стандартизирующий предоставление контекстной информации большим языковым моделям (LLM).

* **Аналогия:** MCP можно представить как "флешку" для ИИ. Флешка хранит файлы и вставляется в компьютер для использования. Аналогично, MCP Server позволяет "подключать" различные контекстные "плагины", которые LLM могут запрашивать по мере необходимости для получения более богатого контекста и расширения возможностей.
* **Сравнение с Function Tool:** Традиционные Function Tools предоставляют внешние функции для LLM, но MCP — это более высокоуровневая абстракция. Function Tools ориентированы на конкретные задачи, а MCP предлагает универсальный модульный механизм получения контекста.

### Ключевые преимущества MCP

1. **Стандартизация:** Единый интерфейс и формат данных для взаимодействия LLM и контекстных провайдеров
2. **Модульность:** Разработчики могут структурировать контекст в независимые модули для лёгкого управления и повторного использования
3. **Гибкость:** LLM динамически выбирают нужные контекстные плагины для персонализированных взаимодействий
4. **Расширяемость:** Дизайн MCP позволяет добавлять новые типы контекстных плагинов, открывая неограниченные возможности для расширения LLM

***